nohup: 忽略输入
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_171531-q6m7assq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-flower-1
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q6m7assq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<1:56:58, 14.06s/it]  0%|          | 2/500 [00:25<1:43:58, 12.53s/it]  1%|          | 3/500 [00:38<1:44:42, 12.64s/it]  1%|          | 4/500 [00:51<1:45:17, 12.74s/it]  1%|          | 5/500 [01:03<1:45:06, 12.74s/it]  1%|          | 6/500 [01:16<1:44:51, 12.74s/it]  1%|▏         | 7/500 [01:28<1:43:05, 12.55s/it]  2%|▏         | 8/500 [01:41<1:42:19, 12.48s/it]  2%|▏         | 9/500 [01:54<1:44:04, 12.72s/it]  2%|▏         | 10/500 [02:07<1:44:39, 12.82s/it]  2%|▏         | 11/500 [02:20<1:45:48, 12.98s/it]  2%|▏         | 12/500 [02:33<1:45:35, 12.98s/it]  3%|▎         | 13/500 [02:46<1:45:08, 12.95s/it]  3%|▎         | 14/500 [03:00<1:46:06, 13.10s/it]  3%|▎         | 15/500 [03:11<1:42:54, 12.73s/it]  3%|▎         | 16/500 [03:24<1:43:03, 12.78s/it]  3%|▎         | 17/500 [03:38<1:44:02, 12.93s/it]  4%|▎         | 18/500 [03:51<1:45:12, 13.10s/it]  4%|▍         | 19/500 [04:04<1:44:11, 13.00s/it]  4%|▍         | 20/500 [04:18<1:47:45, 13.47s/it]  4%|▍         | 21/500 [04:30<1:44:03, 13.03s/it]  4%|▍         | 22/500 [04:44<1:44:28, 13.11s/it]  5%|▍         | 23/500 [04:55<1:39:48, 12.56s/it]  5%|▍         | 24/500 [05:06<1:35:54, 12.09s/it]  5%|▌         | 25/500 [05:20<1:40:55, 12.75s/it]  5%|▌         | 26/500 [05:32<1:38:46, 12.50s/it]  5%|▌         | 27/500 [05:44<1:35:45, 12.15s/it]  6%|▌         | 28/500 [05:55<1:33:01, 11.83s/it]  6%|▌         | 29/500 [06:08<1:35:42, 12.19s/it]  6%|▌         | 30/500 [06:20<1:34:58, 12.12s/it]  6%|▌         | 31/500 [06:35<1:41:22, 12.97s/it]  6%|▋         | 32/500 [06:47<1:40:08, 12.84s/it]  7%|▋         | 33/500 [07:00<1:40:02, 12.85s/it]  7%|▋         | 34/500 [07:12<1:36:45, 12.46s/it]  7%|▋         | 35/500 [07:22<1:33:02, 12.01s/it]  7%|▋         | 36/500 [07:37<1:38:44, 12.77s/it]  7%|▋         | 37/500 [07:51<1:42:04, 13.23s/it]  8%|▊         | 38/500 [08:04<1:40:44, 13.08s/it]  8%|▊         | 39/500 [08:16<1:37:38, 12.71s/it]  8%|▊         | 40/500 [08:29<1:37:15, 12.69s/it]  8%|▊         | 41/500 [08:41<1:35:50, 12.53s/it]  8%|▊         | 41/500 [08:41<1:37:15, 12.71s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.208 MB of 0.226 MB uploadedwandb: | 0.226 MB of 0.508 MB uploadedwandb: / 0.508 MB of 0.508 MB uploadedwandb: - 0.508 MB of 0.508 MB uploadedwandb: \ 0.508 MB of 0.508 MB uploadedwandb: | 0.508 MB of 0.508 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▄▆█▁▁▃▁█▃▆█▁▅▁█▁██▃████▂█▃█▂█
wandb:     train_loss ▁▃▁▂▃▆▂▄▁█▁▁▁▁▅▄▁▃▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁▃▁▁▁▂▁
wandb:   val_accuracy ▁▁▁▁▁▁▁▁▁▁▂▃█▆▁▁▄▁█▂▇▆▂▄▂█▂█▆▂█▆██▂█▂▇▃█
wandb:       val_loss ▁▃▃▂▂▃▂▂█▄▂▂▁▁▃▃▁▂▁▂▁▁▂▁▁▁▃▁▁▁▁▂▁▁▁▁▂▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.04898
wandb:   val_accuracy 0.78444
wandb:       val_loss 0.07625
wandb: 
wandb: 🚀 View run colorful-flower-1 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q6m7assq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_171531-q6m7assq/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_172517-49n95xic
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-thunder-2
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/49n95xic
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<2:01:09, 14.57s/it]  0%|          | 2/500 [00:27<1:53:13, 13.64s/it]  1%|          | 3/500 [00:40<1:48:44, 13.13s/it]  1%|          | 4/500 [00:52<1:46:38, 12.90s/it]  1%|          | 5/500 [01:05<1:45:40, 12.81s/it]  1%|          | 6/500 [01:17<1:43:08, 12.53s/it]  1%|▏         | 7/500 [01:29<1:41:04, 12.30s/it]  2%|▏         | 8/500 [01:43<1:45:50, 12.91s/it]  2%|▏         | 9/500 [01:56<1:45:30, 12.89s/it]  2%|▏         | 10/500 [02:08<1:43:56, 12.73s/it]  2%|▏         | 11/500 [02:22<1:45:52, 12.99s/it]  2%|▏         | 12/500 [02:34<1:43:37, 12.74s/it]  3%|▎         | 13/500 [02:47<1:43:49, 12.79s/it]  3%|▎         | 14/500 [03:00<1:44:43, 12.93s/it]  3%|▎         | 15/500 [03:12<1:43:17, 12.78s/it]  3%|▎         | 16/500 [03:25<1:42:13, 12.67s/it]  3%|▎         | 17/500 [03:37<1:40:55, 12.54s/it]  4%|▎         | 18/500 [03:49<1:38:27, 12.26s/it]  4%|▍         | 19/500 [04:02<1:40:52, 12.58s/it]  4%|▍         | 20/500 [04:15<1:41:04, 12.63s/it]  4%|▍         | 21/500 [04:28<1:41:52, 12.76s/it]  4%|▍         | 22/500 [04:41<1:41:52, 12.79s/it]  5%|▍         | 23/500 [04:53<1:40:31, 12.64s/it]  5%|▍         | 24/500 [05:10<1:50:15, 13.90s/it]  5%|▌         | 25/500 [05:22<1:46:09, 13.41s/it]  5%|▌         | 26/500 [05:35<1:44:54, 13.28s/it]  5%|▌         | 27/500 [05:48<1:43:38, 13.15s/it]  5%|▌         | 27/500 [05:48<1:41:42, 12.90s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.315 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▄▄▆▅▇▇▇▇███▆████████████
wandb:     train_loss ██▇█▄▇▅▄▇▅▂▇▆▇▄▃▄▃▃▂▃▃▂▇▁▃▂
wandb:   val_accuracy ▁▁▁▄▄▆▆▇█▆▇█▇▇▅█▇▇███▇██▆▇█
wandb:       val_loss ▇▆▅▅█▆▄▅▂▅▁▂▃▇▄▂▄▃▂▆▅▂▆▃▄▄▅
wandb: 
wandb: Run summary:
wandb:          epoch 26
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.84398
wandb:     train_loss 0.31419
wandb:   val_accuracy 0.62667
wandb:       val_loss 0.96671
wandb: 
wandb: 🚀 View run bright-thunder-2 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/49n95xic
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_172517-49n95xic/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_173205-aoddb0us
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-blaze-3
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aoddb0us
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:55:48, 13.92s/it]  0%|          | 2/500 [00:26<1:50:57, 13.37s/it]  1%|          | 3/500 [00:38<1:44:36, 12.63s/it]  1%|          | 4/500 [00:50<1:43:02, 12.46s/it]  1%|          | 5/500 [01:02<1:41:06, 12.26s/it]  1%|          | 6/500 [01:14<1:40:13, 12.17s/it]  1%|▏         | 7/500 [01:26<1:39:54, 12.16s/it]  2%|▏         | 8/500 [01:39<1:40:23, 12.24s/it]  2%|▏         | 9/500 [01:51<1:40:19, 12.26s/it]  2%|▏         | 10/500 [02:03<1:40:05, 12.26s/it]  2%|▏         | 11/500 [02:15<1:37:36, 11.98s/it]  2%|▏         | 12/500 [02:27<1:38:53, 12.16s/it]  3%|▎         | 13/500 [02:40<1:39:05, 12.21s/it]  3%|▎         | 14/500 [02:53<1:42:02, 12.60s/it]  3%|▎         | 15/500 [03:05<1:39:43, 12.34s/it]  3%|▎         | 16/500 [03:17<1:38:20, 12.19s/it]  3%|▎         | 17/500 [03:28<1:36:26, 11.98s/it]  4%|▎         | 18/500 [03:40<1:35:12, 11.85s/it]  4%|▍         | 19/500 [03:53<1:37:32, 12.17s/it]  4%|▍         | 20/500 [04:05<1:36:38, 12.08s/it]  4%|▍         | 21/500 [04:17<1:36:29, 12.09s/it]  4%|▍         | 22/500 [04:29<1:36:01, 12.05s/it]  5%|▍         | 23/500 [04:41<1:36:53, 12.19s/it]  5%|▍         | 24/500 [04:53<1:36:22, 12.15s/it]  5%|▌         | 25/500 [05:05<1:35:18, 12.04s/it]  5%|▌         | 26/500 [05:16<1:32:35, 11.72s/it]  5%|▌         | 27/500 [05:27<1:31:20, 11.59s/it]  6%|▌         | 28/500 [05:39<1:30:54, 11.56s/it]  6%|▌         | 29/500 [05:50<1:31:21, 11.64s/it]  6%|▌         | 30/500 [06:03<1:33:08, 11.89s/it]  6%|▌         | 31/500 [06:15<1:32:25, 11.82s/it]  6%|▋         | 32/500 [06:27<1:33:38, 12.00s/it]  6%|▋         | 32/500 [06:27<1:34:28, 12.11s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.311 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.231 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▁▁▁▁▁▆▁▆▁▁▁▁▁▁▁▁▁▁▂▁▄▆▁▁▄▆▅▂▅▁▆█
wandb:     train_loss ▁▁▁▃▂▁▅▁▁▃▂▃▁▃▃▅▄█▁▁▁▁▁▂▁▁▁▁▁▂▁▁
wandb:   val_accuracy ▁▁▁▁▁▇▁▇▁▁▁▁▁▁▁▁▁▁▃▁▇▃▂▂▃▄▃▄█▁█▇
wandb:       val_loss ▁▁▁▂▂▁▃▁▂▂▃▂▂▃▂▁▅█▁▃▁▂▁▁▁▁▂▂▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.97474
wandb:     train_loss 0.01032
wandb:   val_accuracy 0.74222
wandb:       val_loss 0.11102
wandb: 
wandb: 🚀 View run lively-blaze-3 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aoddb0us
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_173205-aoddb0us/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_173920-52y63y9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-gorge-4
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/52y63y9t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:48:32, 13.05s/it]  0%|          | 2/500 [00:25<1:43:36, 12.48s/it]  1%|          | 3/500 [00:41<1:58:38, 14.32s/it]  1%|          | 4/500 [00:53<1:50:06, 13.32s/it]  1%|          | 5/500 [01:05<1:46:54, 12.96s/it]  1%|          | 6/500 [01:17<1:43:58, 12.63s/it]  1%|▏         | 7/500 [01:30<1:43:22, 12.58s/it]  2%|▏         | 8/500 [01:42<1:42:26, 12.49s/it]  2%|▏         | 9/500 [01:55<1:42:44, 12.55s/it]  2%|▏         | 10/500 [02:08<1:43:35, 12.68s/it]  2%|▏         | 11/500 [02:20<1:42:10, 12.54s/it]  2%|▏         | 12/500 [02:32<1:40:45, 12.39s/it]  3%|▎         | 13/500 [02:44<1:40:38, 12.40s/it]  3%|▎         | 14/500 [02:57<1:42:08, 12.61s/it]  3%|▎         | 15/500 [03:10<1:42:13, 12.65s/it]  3%|▎         | 16/500 [03:22<1:39:29, 12.33s/it]  3%|▎         | 17/500 [03:34<1:39:46, 12.39s/it]  4%|▎         | 18/500 [03:46<1:37:42, 12.16s/it]  4%|▍         | 19/500 [03:58<1:37:50, 12.20s/it]  4%|▍         | 20/500 [04:10<1:36:57, 12.12s/it]  4%|▍         | 21/500 [04:22<1:35:49, 12.00s/it]  4%|▍         | 22/500 [04:35<1:37:14, 12.21s/it]  5%|▍         | 23/500 [04:47<1:36:58, 12.20s/it]  5%|▍         | 24/500 [04:59<1:37:27, 12.28s/it]  5%|▌         | 25/500 [05:11<1:36:08, 12.14s/it]  5%|▌         | 26/500 [05:23<1:36:07, 12.17s/it]  5%|▌         | 27/500 [05:35<1:35:09, 12.07s/it]  6%|▌         | 28/500 [05:47<1:35:13, 12.10s/it]  6%|▌         | 29/500 [06:00<1:35:31, 12.17s/it]  6%|▌         | 30/500 [06:12<1:35:15, 12.16s/it]  6%|▌         | 31/500 [06:25<1:36:53, 12.39s/it]  6%|▋         | 32/500 [06:38<1:38:21, 12.61s/it]  7%|▋         | 33/500 [06:49<1:35:51, 12.32s/it]  7%|▋         | 34/500 [07:01<1:34:53, 12.22s/it]  7%|▋         | 35/500 [07:13<1:32:51, 11.98s/it]  7%|▋         | 36/500 [07:25<1:32:15, 11.93s/it]  7%|▋         | 37/500 [07:37<1:32:27, 11.98s/it]  8%|▊         | 38/500 [07:49<1:32:07, 11.96s/it]  8%|▊         | 39/500 [08:01<1:31:56, 11.97s/it]  8%|▊         | 40/500 [08:13<1:31:43, 11.96s/it]  8%|▊         | 41/500 [08:27<1:36:03, 12.56s/it]  8%|▊         | 42/500 [08:42<1:41:25, 13.29s/it]  9%|▊         | 43/500 [08:54<1:39:39, 13.09s/it]  9%|▉         | 44/500 [09:06<1:36:34, 12.71s/it]  9%|▉         | 45/500 [09:18<1:34:48, 12.50s/it]  9%|▉         | 45/500 [09:18<1:34:07, 12.41s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.010 MB of 0.310 MB uploadedwandb: - 0.232 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▁▄▁▁▁▃▁▅▄▂▁▂▆▅▇▄▁██▅▃▄███▆▇▄▃█▁▅████
wandb:     train_loss ▁▂▁▆█▁▇▅▆▁▁▁▁▂▃▁▁▁▁▁▃▁▁▁▁▂▁▁▁▁▁▂▁▁▃▁▁▁▁▁
wandb:   val_accuracy ▁▁▁▁▁▄▁▁▁▂▁▅▃▂▂▃▇▄▇▃▁██▅▂▃▇▇▇▆▆▃▃▇▁▄▇██▇
wandb:       val_loss ▁▂▆▅█▁▇▄▆▃▆▁▁▂▄▂▁▃▁▁▃▂▁▂▃▁▁▃▁▁▂▁▂▁▄▃▁▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 44
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99851
wandb:     train_loss 0.00042
wandb:   val_accuracy 0.71333
wandb:       val_loss 1.39736
wandb: 
wandb: 🚀 View run iconic-gorge-4 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/52y63y9t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_173920-52y63y9t/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_174923-10tz25ct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-deluge-5
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/10tz25ct
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:06:57, 15.27s/it]  0%|          | 2/500 [00:33<2:22:31, 17.17s/it]  1%|          | 3/500 [00:46<2:04:43, 15.06s/it]  1%|          | 4/500 [00:58<1:55:58, 14.03s/it]  1%|          | 5/500 [01:10<1:49:00, 13.21s/it]  1%|          | 6/500 [01:23<1:49:16, 13.27s/it]  1%|▏         | 7/500 [01:36<1:47:36, 13.10s/it]  2%|▏         | 8/500 [01:49<1:46:37, 13.00s/it]  2%|▏         | 9/500 [02:01<1:43:32, 12.65s/it]  2%|▏         | 10/500 [02:13<1:42:09, 12.51s/it]  2%|▏         | 11/500 [02:25<1:40:41, 12.36s/it]  2%|▏         | 12/500 [02:38<1:41:10, 12.44s/it]  3%|▎         | 13/500 [02:49<1:38:59, 12.20s/it]  3%|▎         | 14/500 [03:02<1:39:43, 12.31s/it]  3%|▎         | 15/500 [03:14<1:38:10, 12.15s/it]  3%|▎         | 16/500 [03:26<1:37:17, 12.06s/it]  3%|▎         | 17/500 [03:37<1:35:09, 11.82s/it]  4%|▎         | 18/500 [03:47<1:32:04, 11.46s/it]  4%|▍         | 19/500 [03:58<1:30:49, 11.33s/it]  4%|▍         | 20/500 [04:10<1:31:09, 11.40s/it]  4%|▍         | 21/500 [04:22<1:32:01, 11.53s/it]  4%|▍         | 22/500 [04:33<1:31:52, 11.53s/it]  5%|▍         | 23/500 [04:45<1:32:42, 11.66s/it]  5%|▍         | 24/500 [04:57<1:32:06, 11.61s/it]  5%|▌         | 25/500 [05:08<1:31:54, 11.61s/it]  5%|▌         | 26/500 [05:20<1:32:08, 11.66s/it]  5%|▌         | 27/500 [05:32<1:32:51, 11.78s/it]  6%|▌         | 28/500 [05:44<1:32:18, 11.73s/it]  6%|▌         | 29/500 [05:56<1:32:30, 11.78s/it]  6%|▌         | 30/500 [06:07<1:32:05, 11.76s/it]  6%|▌         | 31/500 [06:19<1:31:52, 11.75s/it]  6%|▋         | 32/500 [06:31<1:31:00, 11.67s/it]  6%|▋         | 32/500 [06:31<1:35:21, 12.22s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.021 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▁▁▂▂▂▂▂▂▄▂▃▇▂▂█▂▂▂▆▂▂▂▂▄▅▂▅▁▂▂▂▂
wandb:     train_loss ▂▂▂▂▂▂▂▂▁▃▂▁▆▂▁▂▂█▁▁▁▃▁▂▁▂▂▁▁▃▂▂
wandb:   val_accuracy ▁▁▁▁▁▁▁▁▂▁▁▇▁▂█▁▂▁▅▄▁▁▁▃▃▂▄▁▁▁▂▃
wandb:       val_loss ▂▂▂▂▂▂▂▂▂▂▂▁▄▂▂▁▂█▂▂▃▂▂▂▁▂▂▂▄▃▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.38187
wandb:     train_loss 1.55308
wandb:   val_accuracy 0.43778
wandb:       val_loss 0.02254
wandb: 
wandb: 🚀 View run glowing-deluge-5 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/10tz25ct
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_174923-10tz25ct/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_175645-cojzcbay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-star-6
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cojzcbay
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<2:03:45, 14.88s/it]  0%|          | 2/500 [00:26<1:48:20, 13.05s/it]  1%|          | 3/500 [00:38<1:43:08, 12.45s/it]  1%|          | 4/500 [00:49<1:39:16, 12.01s/it]  1%|          | 5/500 [01:01<1:38:10, 11.90s/it]  1%|          | 6/500 [01:13<1:37:08, 11.80s/it]  1%|▏         | 7/500 [01:24<1:37:04, 11.81s/it]  2%|▏         | 8/500 [01:36<1:37:29, 11.89s/it]  2%|▏         | 9/500 [01:49<1:38:33, 12.04s/it]  2%|▏         | 10/500 [02:05<1:48:34, 13.29s/it]  2%|▏         | 11/500 [02:18<1:47:58, 13.25s/it]  2%|▏         | 12/500 [02:29<1:43:17, 12.70s/it]  3%|▎         | 13/500 [02:42<1:41:55, 12.56s/it]  3%|▎         | 14/500 [02:54<1:40:54, 12.46s/it]  3%|▎         | 15/500 [03:06<1:40:30, 12.43s/it]  3%|▎         | 16/500 [03:18<1:38:24, 12.20s/it]  3%|▎         | 17/500 [03:30<1:38:24, 12.22s/it]  4%|▎         | 18/500 [03:41<1:35:43, 11.92s/it]  4%|▍         | 19/500 [03:54<1:36:15, 12.01s/it]  4%|▍         | 20/500 [04:06<1:37:27, 12.18s/it]  4%|▍         | 21/500 [04:19<1:38:33, 12.35s/it]  4%|▍         | 22/500 [04:31<1:38:27, 12.36s/it]  5%|▍         | 23/500 [04:44<1:38:12, 12.35s/it]  5%|▍         | 24/500 [04:56<1:38:28, 12.41s/it]  5%|▌         | 25/500 [05:08<1:36:43, 12.22s/it]  5%|▌         | 26/500 [05:20<1:35:03, 12.03s/it]  5%|▌         | 27/500 [05:32<1:35:28, 12.11s/it]  6%|▌         | 28/500 [05:44<1:35:44, 12.17s/it]  6%|▌         | 29/500 [05:56<1:34:38, 12.06s/it]  6%|▌         | 30/500 [06:08<1:35:01, 12.13s/it]  6%|▌         | 30/500 [06:08<1:36:18, 12.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.010 MB of 0.312 MB uploadedwandb: - 0.133 MB of 0.312 MB uploadedwandb: \ 0.133 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▂▃▄▁▁▁▁▁▁█▂▁▂▃▁▂▂▆▁▃▅▅█▄▃▁▁▇▅▁
wandb:     train_loss ▁▁▁▂▄▁█▃▁▁▁▃▂▁▃▃▁▁▂▁▁▂▁▂▁▃▁▁▁▄
wandb:   val_accuracy ▁▁▂▁▁▁▁▁▁▅▂▁▃▂▂▂▂▄▂▄▆▆▆▂▄▁▃█▃▁
wandb:       val_loss ▂▂▂▂▄▃█▂▄▁▂▃▂▁▄▄▄▃▃▂▁▁▃▃▃▂▃▁▁▃
wandb: 
wandb: Run summary:
wandb:          epoch 29
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.31055
wandb:     train_loss 11.81418
wandb:   val_accuracy 0.34667
wandb:       val_loss 3.16227
wandb: 
wandb: 🚀 View run noble-star-6 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cojzcbay
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_175645-cojzcbay/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_180334-5ylkjatq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-plasma-7
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5ylkjatq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<1:56:40, 14.03s/it]  0%|          | 2/500 [00:26<1:49:31, 13.20s/it]  1%|          | 3/500 [00:38<1:46:05, 12.81s/it]  1%|          | 4/500 [00:51<1:44:42, 12.67s/it]  1%|          | 5/500 [01:04<1:45:12, 12.75s/it]  1%|          | 6/500 [01:17<1:44:48, 12.73s/it]  1%|▏         | 7/500 [01:29<1:44:39, 12.74s/it]  2%|▏         | 8/500 [01:42<1:45:16, 12.84s/it]  2%|▏         | 9/500 [01:55<1:44:47, 12.80s/it]  2%|▏         | 10/500 [02:07<1:43:36, 12.69s/it]  2%|▏         | 11/500 [02:21<1:44:21, 12.80s/it]  2%|▏         | 12/500 [02:33<1:42:52, 12.65s/it]  3%|▎         | 13/500 [02:45<1:42:36, 12.64s/it]  3%|▎         | 14/500 [02:58<1:41:39, 12.55s/it]  3%|▎         | 15/500 [03:10<1:40:48, 12.47s/it]  3%|▎         | 16/500 [03:22<1:40:23, 12.45s/it]  3%|▎         | 17/500 [03:35<1:39:57, 12.42s/it]  4%|▎         | 18/500 [03:48<1:40:54, 12.56s/it]  4%|▍         | 19/500 [04:00<1:39:55, 12.47s/it]  4%|▍         | 20/500 [04:12<1:38:45, 12.34s/it]  4%|▍         | 21/500 [04:24<1:38:42, 12.37s/it]  4%|▍         | 22/500 [04:37<1:39:19, 12.47s/it]  5%|▍         | 23/500 [04:50<1:39:04, 12.46s/it]  5%|▍         | 24/500 [05:03<1:40:08, 12.62s/it]  5%|▌         | 25/500 [05:15<1:39:24, 12.56s/it]  5%|▌         | 25/500 [05:15<1:39:56, 12.62s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.307 MB uploadedwandb: | 0.027 MB of 0.307 MB uploadedwandb: / 0.307 MB of 0.307 MB uploadedwandb: - 0.307 MB of 0.307 MB uploadedwandb: \ 0.307 MB of 0.307 MB uploadedwandb: | 0.307 MB of 0.307 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▁▁▁▁▁▁▁▂▆▂▅▁▁▁▂█▇▁█▂█
wandb:     train_loss ▁▂▁▃▅▇▃▄██▃▂▁▁▁▃▁▄▁▁▁▃▁▂▁
wandb:   val_accuracy ▁▁▁▁▁▁▁▁▁▁▁▂█▂▆▂▁▁▃█▇▂▇▃▇
wandb:       val_loss ▂▂▃▃▅█▂▄▁█▆▂▁▁▃▄▅▅▁▃▁▃▁▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.9896
wandb:     train_loss 2e-05
wandb:   val_accuracy 0.72222
wandb:       val_loss 0.00405
wandb: 
wandb: 🚀 View run daily-plasma-7 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5ylkjatq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_180334-5ylkjatq/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_180945-8iipnmb1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-yogurt-8
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8iipnmb1
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:20<2:49:36, 20.39s/it]  0%|          | 2/500 [00:38<2:36:15, 18.83s/it]  1%|          | 3/500 [00:50<2:11:05, 15.83s/it]  1%|          | 4/500 [01:02<1:57:42, 14.24s/it]  1%|          | 5/500 [01:13<1:49:47, 13.31s/it]  1%|          | 6/500 [01:26<1:48:02, 13.12s/it]  1%|▏         | 7/500 [01:39<1:46:59, 13.02s/it]  2%|▏         | 8/500 [01:51<1:43:51, 12.67s/it]  2%|▏         | 9/500 [02:04<1:45:11, 12.85s/it]  2%|▏         | 10/500 [02:17<1:44:43, 12.82s/it]  2%|▏         | 11/500 [02:29<1:43:45, 12.73s/it]  2%|▏         | 12/500 [02:42<1:42:21, 12.58s/it]  3%|▎         | 13/500 [02:54<1:41:50, 12.55s/it]  3%|▎         | 14/500 [03:07<1:43:00, 12.72s/it]  3%|▎         | 15/500 [03:19<1:41:32, 12.56s/it]  3%|▎         | 16/500 [03:32<1:42:19, 12.69s/it]  3%|▎         | 17/500 [03:46<1:45:30, 13.11s/it]  4%|▎         | 18/500 [03:59<1:43:24, 12.87s/it]  4%|▍         | 19/500 [04:12<1:43:56, 12.97s/it]  4%|▍         | 20/500 [04:25<1:43:58, 13.00s/it]  4%|▍         | 21/500 [04:38<1:44:41, 13.11s/it]  4%|▍         | 22/500 [04:51<1:43:23, 12.98s/it]  5%|▍         | 23/500 [05:03<1:40:16, 12.61s/it]  5%|▍         | 24/500 [05:16<1:41:14, 12.76s/it]  5%|▌         | 25/500 [05:28<1:39:08, 12.52s/it]  5%|▌         | 26/500 [05:41<1:40:10, 12.68s/it]  5%|▌         | 27/500 [05:55<1:42:24, 12.99s/it]  6%|▌         | 28/500 [06:08<1:42:44, 13.06s/it]  6%|▌         | 28/500 [06:08<1:43:30, 13.16s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.010 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▄▆▆▅▇▇█▅████▅█▇▇██████████
wandb:     train_loss ▇▆▆▇▅█▆▅▆▃▁▇▅▆▄▆▄▁▃▁▂▄▂▆▂▂▂▄
wandb:   val_accuracy ▁▁▄▇▇▆▇█▆▂▇▆▇▆▂▇▄▄▆▆█▆▇▆▅▇▆▇
wandb:       val_loss ▅▅▄▄▄▄▃▄▃▅▁▁▂█▄▃▄▃▃▅▅▃▅▂▃▂▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 27
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.83061
wandb:     train_loss 0.81241
wandb:   val_accuracy 0.62444
wandb:       val_loss 1.03045
wandb: 
wandb: 🚀 View run rural-yogurt-8 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8iipnmb1
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_180945-8iipnmb1/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_181644-gaz81prv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sound-9
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/gaz81prv
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:20<2:46:37, 20.03s/it]  0%|          | 2/500 [00:33<2:13:48, 16.12s/it]  1%|          | 3/500 [00:46<2:01:30, 14.67s/it]  1%|          | 4/500 [00:58<1:52:55, 13.66s/it]  1%|          | 5/500 [01:10<1:48:25, 13.14s/it]  1%|          | 6/500 [01:21<1:42:20, 12.43s/it]  1%|▏         | 7/500 [01:32<1:38:51, 12.03s/it]  2%|▏         | 8/500 [01:45<1:40:39, 12.27s/it]  2%|▏         | 9/500 [01:58<1:40:24, 12.27s/it]  2%|▏         | 10/500 [02:10<1:41:43, 12.46s/it]  2%|▏         | 11/500 [02:22<1:39:25, 12.20s/it]  2%|▏         | 12/500 [02:34<1:37:38, 12.00s/it]  3%|▎         | 13/500 [02:45<1:36:59, 11.95s/it]  3%|▎         | 14/500 [02:57<1:35:04, 11.74s/it]  3%|▎         | 15/500 [03:08<1:34:04, 11.64s/it]  3%|▎         | 16/500 [03:20<1:34:38, 11.73s/it]  3%|▎         | 17/500 [03:31<1:32:33, 11.50s/it]  4%|▎         | 18/500 [03:42<1:30:31, 11.27s/it]  4%|▍         | 19/500 [03:53<1:31:10, 11.37s/it]  4%|▍         | 20/500 [04:05<1:32:20, 11.54s/it]  4%|▍         | 21/500 [04:18<1:34:55, 11.89s/it]  4%|▍         | 22/500 [04:30<1:35:10, 11.95s/it]  5%|▍         | 23/500 [04:42<1:33:53, 11.81s/it]  5%|▍         | 24/500 [04:54<1:34:39, 11.93s/it]  5%|▌         | 25/500 [05:06<1:34:58, 12.00s/it]  5%|▌         | 25/500 [05:06<1:37:01, 12.26s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.311 MB uploadedwandb: \ 0.010 MB of 0.311 MB uploadedwandb: | 0.168 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▁▁▁▃▁▁▁▁▂▁▁█▂▁▅▁▁▁▁▃▇
wandb:     train_loss ▁▁▁▂▄▁▆▁▂▄▁▁▂▂▃▁▁█▁▁▁▃▂▂▁
wandb:   val_accuracy ▁▁▁▁▁▁▁▂▂▁▂▁▄▃▁█▅▁▇▁▂▁▂▂▅
wandb:       val_loss ▁▂▃▂▄▂▅▂▁▄▂▅▂▃▃▁▁█▁▆▃▃▂▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.87816
wandb:     train_loss 5e-05
wandb:   val_accuracy 0.55111
wandb:       val_loss 0.0044
wandb: 
wandb: 🚀 View run jolly-sound-9 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/gaz81prv
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_181644-gaz81prv/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_182246-fwk7qi1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-disco-10
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fwk7qi1t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:22:44, 17.16s/it]  0%|          | 2/500 [00:33<2:20:11, 16.89s/it]  1%|          | 3/500 [00:46<2:04:40, 15.05s/it]  1%|          | 4/500 [00:58<1:52:49, 13.65s/it]  1%|          | 5/500 [01:09<1:45:40, 12.81s/it]  1%|          | 6/500 [01:20<1:40:53, 12.25s/it]  1%|▏         | 7/500 [01:32<1:39:13, 12.08s/it]  2%|▏         | 8/500 [01:44<1:39:53, 12.18s/it]  2%|▏         | 9/500 [01:58<1:42:52, 12.57s/it]  2%|▏         | 10/500 [02:10<1:40:38, 12.32s/it]  2%|▏         | 11/500 [02:21<1:38:09, 12.04s/it]  2%|▏         | 12/500 [02:32<1:35:45, 11.77s/it]  3%|▎         | 13/500 [02:44<1:35:17, 11.74s/it]  3%|▎         | 14/500 [02:56<1:35:20, 11.77s/it]  3%|▎         | 15/500 [03:07<1:34:45, 11.72s/it]  3%|▎         | 16/500 [03:20<1:37:49, 12.13s/it]  3%|▎         | 17/500 [03:32<1:36:08, 11.94s/it]  4%|▎         | 18/500 [03:43<1:34:56, 11.82s/it]  4%|▍         | 19/500 [03:56<1:36:03, 11.98s/it]  4%|▍         | 20/500 [04:07<1:34:34, 11.82s/it]  4%|▍         | 21/500 [04:19<1:34:21, 11.82s/it]  4%|▍         | 22/500 [04:31<1:33:50, 11.78s/it]  5%|▍         | 23/500 [04:43<1:34:12, 11.85s/it]  5%|▍         | 24/500 [04:54<1:32:06, 11.61s/it]  5%|▌         | 25/500 [05:06<1:33:33, 11.82s/it]  5%|▌         | 25/500 [05:06<1:37:03, 12.26s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.308 MB uploadedwandb: | 0.010 MB of 0.308 MB uploadedwandb: / 0.137 MB of 0.308 MB uploadedwandb: - 0.308 MB of 0.308 MB uploadedwandb: \ 0.308 MB of 0.308 MB uploadedwandb: | 0.308 MB of 0.308 MB uploadedwandb: / 0.308 MB of 0.308 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▃▂▂▁▁▁▁▇▆▁▁▁▇▅▁█▄▁████▄██
wandb:     train_loss ▁▁▁▁▇▁▂▁▁▂▁▁▁▁█▁▁▃▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▂▁▁▁▁▆▆▂▁▁▆▅▁█▃▁█▇▇▆▄▇▇
wandb:       val_loss ▁▁▁▁▄▂▂▁▁▂▂▃▁▁█▁▂▂▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.9584
wandb:     train_loss 0.0
wandb:   val_accuracy 0.73778
wandb:       val_loss 0.1382
wandb: 
wandb: 🚀 View run toasty-disco-10 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fwk7qi1t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_182246-fwk7qi1t/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_182838-5nixwv20
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-bird-11
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5nixwv20
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:54:22, 13.75s/it]  0%|          | 2/500 [00:26<1:51:25, 13.42s/it]  1%|          | 3/500 [00:40<1:49:53, 13.27s/it]  1%|          | 4/500 [00:53<1:49:22, 13.23s/it]  1%|          | 5/500 [01:05<1:46:17, 12.88s/it]  1%|          | 6/500 [01:17<1:43:16, 12.54s/it]  1%|▏         | 7/500 [01:29<1:41:26, 12.35s/it]  2%|▏         | 8/500 [01:41<1:40:05, 12.21s/it]  2%|▏         | 9/500 [01:53<1:38:59, 12.10s/it]  2%|▏         | 10/500 [02:04<1:37:34, 11.95s/it]  2%|▏         | 11/500 [02:16<1:38:08, 12.04s/it]  2%|▏         | 12/500 [02:28<1:37:28, 11.99s/it]  3%|▎         | 13/500 [02:40<1:36:53, 11.94s/it]  3%|▎         | 14/500 [02:52<1:35:56, 11.84s/it]  3%|▎         | 15/500 [03:04<1:35:58, 11.87s/it]  3%|▎         | 16/500 [03:15<1:35:21, 11.82s/it]  3%|▎         | 17/500 [03:28<1:37:45, 12.14s/it]  4%|▎         | 18/500 [03:41<1:38:07, 12.21s/it]  4%|▍         | 19/500 [03:53<1:38:21, 12.27s/it]  4%|▍         | 20/500 [04:06<1:40:12, 12.53s/it]  4%|▍         | 21/500 [04:19<1:40:27, 12.58s/it]  4%|▍         | 22/500 [04:31<1:40:00, 12.55s/it]  5%|▍         | 23/500 [04:44<1:39:38, 12.53s/it]  5%|▍         | 24/500 [04:57<1:41:51, 12.84s/it]  5%|▌         | 25/500 [05:09<1:38:40, 12.46s/it]  5%|▌         | 25/500 [05:09<1:38:00, 12.38s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.021 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▆▂▂▃▅▂▃▂▂▃▃▄█▂▃▄▃▄▆▄▂▄
wandb:     train_loss ▄▄▄▄▃▅▃▃▅▃▂▇▄▄▃▃▁▃▄▄▄▃▄█▄
wandb:   val_accuracy ▃▃▄▆▂▃▄▃▃▃▄▃▃▂▃█▃▃▃▁▃▄▃▃▃
wandb:       val_loss ▆▆▆▅▆▇▄▆▁▆▁▅▅▆▅▃█▇▆▆▅▇▆▆▅
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.48886
wandb:     train_loss 1.2146
wandb:   val_accuracy 0.32222
wandb:       val_loss 0.92286
wandb: 
wandb: 🚀 View run fiery-bird-11 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5nixwv20
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_182838-5nixwv20/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_183441-b05ibaxk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-lion-12
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/b05ibaxk
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:11:04, 15.76s/it]  0%|          | 2/500 [00:28<1:56:31, 14.04s/it]  1%|          | 3/500 [00:41<1:52:23, 13.57s/it]  1%|          | 4/500 [00:54<1:49:26, 13.24s/it]  1%|          | 5/500 [01:07<1:48:42, 13.18s/it]  1%|          | 6/500 [01:20<1:47:02, 13.00s/it]  1%|▏         | 7/500 [01:34<1:49:44, 13.36s/it]  2%|▏         | 8/500 [01:47<1:48:50, 13.27s/it]  2%|▏         | 9/500 [02:04<1:59:11, 14.57s/it]  2%|▏         | 10/500 [02:17<1:54:09, 13.98s/it]  2%|▏         | 11/500 [02:30<1:51:13, 13.65s/it]  2%|▏         | 12/500 [02:43<1:49:39, 13.48s/it]  3%|▎         | 13/500 [02:55<1:46:41, 13.14s/it]  3%|▎         | 14/500 [03:08<1:46:52, 13.19s/it]  3%|▎         | 15/500 [03:21<1:45:18, 13.03s/it]  3%|▎         | 16/500 [03:34<1:44:52, 13.00s/it]  3%|▎         | 17/500 [03:47<1:43:54, 12.91s/it]  4%|▎         | 18/500 [03:59<1:43:13, 12.85s/it]  4%|▍         | 19/500 [04:13<1:43:40, 12.93s/it]  4%|▍         | 20/500 [04:27<1:46:07, 13.27s/it]  4%|▍         | 21/500 [04:40<1:46:58, 13.40s/it]  4%|▍         | 22/500 [04:54<1:46:42, 13.39s/it]  5%|▍         | 23/500 [05:06<1:44:12, 13.11s/it]  5%|▍         | 24/500 [05:19<1:44:17, 13.15s/it]  5%|▌         | 25/500 [05:33<1:44:51, 13.24s/it]  5%|▌         | 26/500 [05:46<1:44:25, 13.22s/it]  5%|▌         | 27/500 [06:04<1:56:08, 14.73s/it]  6%|▌         | 28/500 [06:17<1:51:28, 14.17s/it]  6%|▌         | 29/500 [06:30<1:48:30, 13.82s/it]  6%|▌         | 30/500 [06:43<1:46:27, 13.59s/it]  6%|▌         | 31/500 [07:01<1:55:13, 14.74s/it]  6%|▋         | 32/500 [07:14<1:51:14, 14.26s/it]  6%|▋         | 32/500 [07:14<1:45:52, 13.57s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.311 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.231 MB of 0.311 MB uploadedwandb: - 0.231 MB of 0.311 MB uploadedwandb: \ 0.231 MB of 0.311 MB uploadedwandb: | 0.231 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▂▁▆▁▁▅▅▁▁▁▁▁▂█▁▁▂▁▁▁▅▂▇▁█▃▄▁▁▇▅█
wandb:     train_loss ▁▂▁▂▄▁▁▄█▄▃▁▁▁▅▆▂▇▁▁▁▂▁▄▁▁▁▆▂▂▂▁
wandb:   val_accuracy ▁▁▆▁▁▅▆▁▁▁▁▁▂▇▁▁▂▁▂▁▇▂█▁▇▅▅▁▂▆▄█
wandb:       val_loss ▁▂▁▁▃▁▂▃▁▃▄█▂▁▄▁▃▅▁▅▁▂▁▂▁▂▁█▁▁▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.9688
wandb:     train_loss 0.07947
wandb:   val_accuracy 0.75556
wandb:       val_loss 0.0347
wandb: 
wandb: 🚀 View run silvery-lion-12 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/b05ibaxk
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_183441-b05ibaxk/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_184246-0xq34jt5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-bush-13
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/0xq34jt5
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:32:10, 18.30s/it]  0%|          | 2/500 [00:31<2:05:20, 15.10s/it]  1%|          | 3/500 [00:42<1:50:33, 13.35s/it]  1%|          | 4/500 [00:54<1:44:49, 12.68s/it]  1%|          | 5/500 [01:06<1:42:33, 12.43s/it]  1%|          | 6/500 [01:18<1:41:40, 12.35s/it]  1%|▏         | 7/500 [01:31<1:42:37, 12.49s/it]  2%|▏         | 8/500 [01:42<1:39:47, 12.17s/it]  2%|▏         | 9/500 [01:54<1:37:55, 11.97s/it]  2%|▏         | 10/500 [02:05<1:36:22, 11.80s/it]  2%|▏         | 11/500 [02:17<1:35:51, 11.76s/it]  2%|▏         | 12/500 [02:28<1:34:42, 11.65s/it]  3%|▎         | 13/500 [02:39<1:33:56, 11.57s/it]  3%|▎         | 14/500 [02:51<1:34:12, 11.63s/it]  3%|▎         | 15/500 [03:03<1:34:50, 11.73s/it]  3%|▎         | 16/500 [03:15<1:34:02, 11.66s/it]  3%|▎         | 17/500 [03:26<1:33:15, 11.58s/it]  4%|▎         | 18/500 [03:37<1:32:21, 11.50s/it]  4%|▍         | 19/500 [03:49<1:33:34, 11.67s/it]  4%|▍         | 20/500 [04:01<1:33:22, 11.67s/it]  4%|▍         | 21/500 [04:12<1:31:36, 11.48s/it]  4%|▍         | 22/500 [04:24<1:31:55, 11.54s/it]  5%|▍         | 23/500 [04:35<1:31:49, 11.55s/it]  5%|▍         | 24/500 [04:47<1:32:12, 11.62s/it]  5%|▌         | 25/500 [04:59<1:32:05, 11.63s/it]  5%|▌         | 26/500 [05:10<1:31:48, 11.62s/it]  5%|▌         | 27/500 [05:22<1:32:07, 11.69s/it]  6%|▌         | 28/500 [05:34<1:32:01, 11.70s/it]  6%|▌         | 29/500 [05:46<1:32:21, 11.76s/it]  6%|▌         | 30/500 [05:58<1:32:27, 11.80s/it]  6%|▌         | 31/500 [06:10<1:32:43, 11.86s/it]  6%|▋         | 32/500 [06:23<1:35:34, 12.25s/it]  6%|▋         | 32/500 [06:23<1:33:28, 11.98s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.028 MB uploadedwandb: / 0.010 MB of 0.307 MB uploadedwandb: - 0.231 MB of 0.307 MB uploadedwandb: \ 0.307 MB of 0.307 MB uploadedwandb: | 0.307 MB of 0.307 MB uploadedwandb: / 0.307 MB of 0.307 MB uploadedwandb: - 0.307 MB of 0.307 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▁▁▁▁▁▁▂▅▁▁▁█▁▁▁▁▁▁▃▁▅▁▁▁▄█▃▅█▂▆█
wandb:     train_loss ▁▂▁█▁▆▂▁▁▂▁▁▄▂▁▇▂▅▁▂▁▂▁▂▁▁▁▁▁▂▁▁
wandb:   val_accuracy ▁▁▁▁▁▁▃█▂▁▁█▁▁▁▁▁▁▄▁▇▁▁▁▇█▃▇█▃▇▇
wandb:       val_loss ▁▃▂█▂▆▁▁▂▂▁▂▄▃▂▁▃▇▁▂▁▂▃▂▂▁▂▂▁▂▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.89302
wandb:     train_loss 0.00599
wandb:   val_accuracy 0.68667
wandb:       val_loss 0.00677
wandb: 
wandb: 🚀 View run sweet-bush-13 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/0xq34jt5
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_184246-0xq34jt5/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_184952-82ademwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-resonance-14
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/82ademwl
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:56:12, 13.97s/it]  0%|          | 2/500 [00:26<1:46:32, 12.84s/it]  1%|          | 3/500 [00:37<1:41:33, 12.26s/it]  1%|          | 4/500 [00:49<1:39:22, 12.02s/it]  1%|          | 5/500 [01:01<1:39:23, 12.05s/it]  1%|          | 6/500 [01:12<1:38:05, 11.91s/it]  1%|▏         | 7/500 [01:24<1:36:08, 11.70s/it]  2%|▏         | 8/500 [01:36<1:37:55, 11.94s/it]  2%|▏         | 9/500 [01:48<1:37:26, 11.91s/it]  2%|▏         | 10/500 [02:01<1:38:57, 12.12s/it]  2%|▏         | 11/500 [02:13<1:40:30, 12.33s/it]  2%|▏         | 12/500 [02:25<1:38:30, 12.11s/it]  3%|▎         | 13/500 [02:37<1:38:08, 12.09s/it]  3%|▎         | 14/500 [02:49<1:36:23, 11.90s/it]  3%|▎         | 15/500 [03:00<1:35:06, 11.77s/it]  3%|▎         | 16/500 [03:11<1:32:52, 11.51s/it]  3%|▎         | 17/500 [03:22<1:32:07, 11.44s/it]  4%|▎         | 18/500 [03:35<1:34:07, 11.72s/it]  4%|▍         | 19/500 [03:46<1:34:04, 11.73s/it]  4%|▍         | 20/500 [03:59<1:36:34, 12.07s/it]  4%|▍         | 21/500 [04:11<1:36:06, 12.04s/it]  4%|▍         | 22/500 [04:24<1:36:35, 12.13s/it]  5%|▍         | 23/500 [04:36<1:37:06, 12.21s/it]  5%|▍         | 24/500 [04:49<1:38:08, 12.37s/it]  5%|▌         | 25/500 [05:00<1:36:23, 12.18s/it]  5%|▌         | 26/500 [05:12<1:34:40, 11.98s/it]  5%|▌         | 27/500 [05:24<1:35:01, 12.05s/it]  6%|▌         | 28/500 [05:36<1:35:29, 12.14s/it]  6%|▌         | 29/500 [05:49<1:35:46, 12.20s/it]  6%|▌         | 30/500 [06:01<1:35:38, 12.21s/it]  6%|▌         | 31/500 [06:14<1:37:29, 12.47s/it]  6%|▋         | 32/500 [06:27<1:38:11, 12.59s/it]  6%|▋         | 32/500 [06:27<1:34:27, 12.11s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.021 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▄▄▄▄▆▄▆▄▇▄▆▂▄▄▆▄▄▇▇▁▄▄▆█▄▄▁▃█▄▂█
wandb:     train_loss ▂▃▂▂▂▃▂▄▂▅▂▂█▆▃▆▂▃▁▂▃▃▁▃▁▄▂▂▁▅▂▂
wandb:   val_accuracy ▄▄▄▄▄▄▄▄▆▄▅▁▄▄▅▄▄▇▇▂▄▄▅█▄▄▁▃█▄▃▇
wandb:       val_loss ▃▃▃▃▃▃▃▃▃▄▃▃▆█▃▁▃▃▁▃▃▃▂▂▆▃▃▃▂▄▃▂
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.63447
wandb:     train_loss 1.01041
wandb:   val_accuracy 0.62222
wandb:       val_loss 0.62628
wandb: 
wandb: 🚀 View run misunderstood-resonance-14 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/82ademwl
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_184952-82ademwl/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_185708-wrc2wvhc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-aardvark-15
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wrc2wvhc
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:11:44, 15.84s/it]  0%|          | 2/500 [00:28<1:54:37, 13.81s/it]  1%|          | 3/500 [00:41<1:52:49, 13.62s/it]  1%|          | 4/500 [00:54<1:50:03, 13.31s/it]  1%|          | 5/500 [01:05<1:44:31, 12.67s/it]  1%|          | 6/500 [01:17<1:41:20, 12.31s/it]  1%|▏         | 7/500 [01:30<1:42:07, 12.43s/it]  2%|▏         | 8/500 [01:42<1:40:43, 12.28s/it]  2%|▏         | 9/500 [01:55<1:41:51, 12.45s/it]  2%|▏         | 10/500 [02:08<1:43:58, 12.73s/it]  2%|▏         | 11/500 [02:20<1:41:31, 12.46s/it]  2%|▏         | 12/500 [02:32<1:41:48, 12.52s/it]  3%|▎         | 13/500 [02:44<1:39:50, 12.30s/it]  3%|▎         | 14/500 [02:57<1:40:03, 12.35s/it]  3%|▎         | 15/500 [03:09<1:39:04, 12.26s/it]  3%|▎         | 16/500 [03:21<1:38:18, 12.19s/it]  3%|▎         | 17/500 [03:32<1:35:44, 11.89s/it]  4%|▎         | 18/500 [03:44<1:35:28, 11.88s/it]  4%|▍         | 19/500 [03:55<1:34:21, 11.77s/it]  4%|▍         | 20/500 [04:07<1:34:19, 11.79s/it]  4%|▍         | 21/500 [04:19<1:35:11, 11.92s/it]  4%|▍         | 22/500 [04:32<1:35:50, 12.03s/it]  5%|▍         | 23/500 [04:44<1:37:08, 12.22s/it]  5%|▍         | 24/500 [04:57<1:38:47, 12.45s/it]  5%|▌         | 25/500 [05:10<1:38:20, 12.42s/it]  5%|▌         | 26/500 [05:23<1:39:47, 12.63s/it]  5%|▌         | 27/500 [05:36<1:40:19, 12.73s/it]  6%|▌         | 28/500 [05:49<1:40:56, 12.83s/it]  6%|▌         | 29/500 [06:02<1:40:35, 12.81s/it]  6%|▌         | 30/500 [06:14<1:38:59, 12.64s/it]  6%|▌         | 31/500 [06:26<1:38:24, 12.59s/it]  6%|▋         | 32/500 [06:39<1:37:42, 12.53s/it]  7%|▋         | 33/500 [06:53<1:40:33, 12.92s/it]  7%|▋         | 34/500 [07:06<1:41:08, 13.02s/it]  7%|▋         | 35/500 [07:18<1:39:29, 12.84s/it]  7%|▋         | 36/500 [07:30<1:36:55, 12.53s/it]  7%|▋         | 37/500 [07:43<1:36:43, 12.53s/it]  8%|▊         | 38/500 [07:55<1:36:09, 12.49s/it]  8%|▊         | 39/500 [08:07<1:34:02, 12.24s/it]  8%|▊         | 40/500 [08:19<1:34:26, 12.32s/it]  8%|▊         | 41/500 [08:31<1:33:15, 12.19s/it]  8%|▊         | 41/500 [08:31<1:35:26, 12.48s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.021 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▅▁▁▁▂▇▁▅▂▁▁▁▁▁▃▄▆▅▆▁▇█▂▅█
wandb:     train_loss ▁▁▁▂▂▁█▂▁▅▃▁▂▁▅▁▃▄▁▁▁▂▁▂▁▂▁▂▁▃▂▁▁▁▂▁▁▃▁▁
wandb:   val_accuracy ▁▁▁▁▂▁▁▁▂▁▁▁▁▂▁▇▁▁▁▃█▂▆▃▂▁▁▁▁▃▆▇▇▇▂██▃▆█
wandb:       val_loss ▁▂▁▂▁▃▇▂▂▄▅█▃▁█▁▅▄▁▁▁▂▁▂▁▂▃▃▂▂▂▁▂▂▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.91233
wandb:     train_loss 0.00142
wandb:   val_accuracy 0.72444
wandb:       val_loss 0.00235
wandb: 
wandb: 🚀 View run crimson-aardvark-15 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wrc2wvhc
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_185708-wrc2wvhc/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_190627-kfp46p97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-wildflower-16
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/kfp46p97
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:28:08, 17.81s/it]  0%|          | 2/500 [00:33<2:17:16, 16.54s/it]  1%|          | 3/500 [00:49<2:14:15, 16.21s/it]  1%|          | 4/500 [01:05<2:14:00, 16.21s/it]  1%|          | 5/500 [01:21<2:12:26, 16.05s/it]  1%|          | 6/500 [01:36<2:10:55, 15.90s/it]  1%|▏         | 7/500 [01:52<2:10:17, 15.86s/it]  2%|▏         | 8/500 [02:08<2:11:14, 16.00s/it]  2%|▏         | 9/500 [02:24<2:10:52, 15.99s/it]  2%|▏         | 10/500 [02:40<2:09:19, 15.83s/it]  2%|▏         | 11/500 [02:57<2:11:07, 16.09s/it]  2%|▏         | 12/500 [03:12<2:09:55, 15.98s/it]  3%|▎         | 13/500 [03:28<2:09:11, 15.92s/it]  3%|▎         | 14/500 [03:44<2:08:42, 15.89s/it]  3%|▎         | 15/500 [04:00<2:07:49, 15.81s/it]  3%|▎         | 16/500 [04:16<2:08:13, 15.90s/it]  3%|▎         | 17/500 [04:36<2:18:16, 17.18s/it]  4%|▎         | 18/500 [04:51<2:13:32, 16.62s/it]  4%|▍         | 19/500 [05:07<2:11:36, 16.42s/it]  4%|▍         | 20/500 [05:23<2:09:26, 16.18s/it]  4%|▍         | 21/500 [05:38<2:07:03, 15.92s/it]  4%|▍         | 22/500 [05:54<2:07:05, 15.95s/it]  5%|▍         | 23/500 [06:09<2:05:21, 15.77s/it]  5%|▍         | 24/500 [06:25<2:04:24, 15.68s/it]  5%|▌         | 25/500 [06:40<2:03:46, 15.63s/it]  5%|▌         | 26/500 [06:57<2:04:53, 15.81s/it]  5%|▌         | 27/500 [07:13<2:06:28, 16.04s/it]  6%|▌         | 28/500 [07:29<2:04:35, 15.84s/it]  6%|▌         | 29/500 [07:44<2:03:40, 15.75s/it]  6%|▌         | 30/500 [08:04<2:13:20, 17.02s/it]  6%|▌         | 31/500 [08:20<2:09:34, 16.58s/it]  6%|▋         | 32/500 [08:35<2:06:31, 16.22s/it]  7%|▋         | 33/500 [08:50<2:04:20, 15.98s/it]  7%|▋         | 34/500 [09:06<2:03:08, 15.86s/it]  7%|▋         | 35/500 [09:26<2:12:28, 17.09s/it]  7%|▋         | 36/500 [09:42<2:08:56, 16.67s/it]  7%|▋         | 37/500 [09:57<2:06:11, 16.35s/it]  8%|▊         | 38/500 [10:13<2:04:43, 16.20s/it]  8%|▊         | 39/500 [10:33<2:12:26, 17.24s/it]  8%|▊         | 40/500 [10:54<2:21:09, 18.41s/it]  8%|▊         | 41/500 [11:11<2:16:48, 17.88s/it]  8%|▊         | 42/500 [11:27<2:12:07, 17.31s/it]  9%|▊         | 43/500 [11:43<2:09:21, 16.98s/it]  9%|▉         | 44/500 [11:59<2:07:33, 16.78s/it]  9%|▉         | 45/500 [12:15<2:06:19, 16.66s/it]  9%|▉         | 46/500 [12:32<2:04:57, 16.51s/it]  9%|▉         | 47/500 [12:48<2:04:25, 16.48s/it] 10%|▉         | 48/500 [13:04<2:03:50, 16.44s/it] 10%|▉         | 49/500 [13:21<2:03:54, 16.48s/it] 10%|█         | 50/500 [13:37<2:02:17, 16.31s/it] 10%|█         | 51/500 [13:53<2:01:48, 16.28s/it] 10%|█         | 52/500 [14:10<2:03:14, 16.51s/it] 11%|█         | 53/500 [14:26<2:00:41, 16.20s/it] 11%|█         | 54/500 [14:41<1:59:22, 16.06s/it] 11%|█         | 55/500 [14:57<1:57:35, 15.86s/it] 11%|█         | 56/500 [15:13<1:57:26, 15.87s/it] 11%|█         | 56/500 [15:13<2:00:39, 16.31s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.309 MB uploadedwandb: | 0.019 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▄▁▂▃▄▃▄▆▄▇▅█▄▅█████████████████████████
wandb:     train_loss ▃▃█▇▁▁▁▁█▃▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▃▁▂▂▄▂▅▆▄▆▄█▃▄▆▆▆▇▇▇▆▇▆▆▅▇▆▇▆▆▆▅▇▆▅▆▅▅▆
wandb:       val_loss ▂▂▃▄▄▁▆█▂▇▄▅▂▃▃▁▁▄▂▁▁▅▂▄▅▄▂▄▁▄▁▃▅▃▁▅▂▆▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 55
wandb:  learning_rate 3e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.00064
wandb:   val_accuracy 0.64
wandb:       val_loss 0.00321
wandb: 
wandb: 🚀 View run glamorous-wildflower-16 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/kfp46p97
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_190627-kfp46p97/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_192225-dlvw6fwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-fire-17
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dlvw6fwv
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:25:11, 17.46s/it]  0%|          | 2/500 [00:32<2:15:01, 16.27s/it]  1%|          | 3/500 [00:49<2:16:12, 16.44s/it]  1%|          | 4/500 [01:05<2:14:35, 16.28s/it]  1%|          | 5/500 [01:21<2:13:34, 16.19s/it]  1%|          | 6/500 [01:37<2:11:59, 16.03s/it]  1%|▏         | 7/500 [01:57<2:23:31, 17.47s/it]  2%|▏         | 8/500 [02:13<2:19:04, 16.96s/it]  2%|▏         | 9/500 [02:29<2:16:03, 16.63s/it]  2%|▏         | 10/500 [02:45<2:13:44, 16.38s/it]  2%|▏         | 11/500 [03:00<2:11:14, 16.10s/it]  2%|▏         | 12/500 [03:16<2:10:24, 16.03s/it]  3%|▎         | 13/500 [03:32<2:09:43, 15.98s/it]  3%|▎         | 14/500 [03:48<2:09:55, 16.04s/it]  3%|▎         | 15/500 [04:05<2:11:46, 16.30s/it]  3%|▎         | 16/500 [04:22<2:12:39, 16.44s/it]  3%|▎         | 17/500 [04:38<2:10:56, 16.27s/it]  4%|▎         | 18/500 [04:54<2:09:58, 16.18s/it]  4%|▍         | 19/500 [05:10<2:09:09, 16.11s/it]  4%|▍         | 20/500 [05:25<2:07:38, 15.95s/it]  4%|▍         | 21/500 [05:41<2:07:06, 15.92s/it]  4%|▍         | 22/500 [06:02<2:18:51, 17.43s/it]  5%|▍         | 23/500 [06:18<2:14:48, 16.96s/it]  5%|▍         | 24/500 [06:34<2:12:11, 16.66s/it]  5%|▌         | 25/500 [06:50<2:09:48, 16.40s/it]  5%|▌         | 26/500 [07:06<2:08:47, 16.30s/it]  5%|▌         | 27/500 [07:22<2:08:59, 16.36s/it]  6%|▌         | 28/500 [07:38<2:07:50, 16.25s/it]  6%|▌         | 29/500 [07:54<2:06:32, 16.12s/it]  6%|▌         | 30/500 [08:10<2:05:47, 16.06s/it]  6%|▌         | 31/500 [08:26<2:04:57, 15.99s/it]  6%|▋         | 32/500 [08:42<2:04:18, 15.94s/it]  7%|▋         | 33/500 [08:58<2:05:19, 16.10s/it]  7%|▋         | 34/500 [09:19<2:15:28, 17.44s/it]  7%|▋         | 35/500 [09:35<2:13:08, 17.18s/it]  7%|▋         | 36/500 [09:51<2:08:59, 16.68s/it]  7%|▋         | 37/500 [10:11<2:17:04, 17.76s/it]  8%|▊         | 38/500 [10:28<2:15:37, 17.61s/it]  8%|▊         | 39/500 [10:45<2:13:50, 17.42s/it]  8%|▊         | 39/500 [10:50<2:08:06, 16.67s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.019 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▂▂▂▂▃▂▇▂▂▂▂▂▂▃▃▂▆▄▇▂▃▂▃▂▄▃▃▄▂▃▂▃▃▃▃█
wandb:     train_loss ▂▂▂▂▂▂▂▂▂▂▂▂▆▂▂█▂▂▂▂▁▁█▂▁▂▅▂▂▂▁▅▂▁▂▂▁▂▁
wandb:   val_accuracy ▁▁▁▁▁▂▂▁▂█▂▂▁▂▂▁▂▂▃▇▄▇▁▂▁▂▁▄▂▂▄▁▂▁▂▂▂▂█
wandb:       val_loss ▂▂▂▂▂▂▂▂▂▂▂▂▆▂▂█▂▂▂▂▂▁▁▂▁▁▅▂▂▂▂▃▂▅▂▂▃▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 38
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.82615
wandb:     train_loss 0.17491
wandb:   val_accuracy 0.72444
wandb:       val_loss 0.90982
wandb: 
wandb: 🚀 View run copper-fire-17 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dlvw6fwv
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_192225-dlvw6fwv/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_193359-rcanamoj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-cloud-18
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rcanamoj
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:27:21, 17.72s/it]  0%|          | 2/500 [00:38<2:42:05, 19.53s/it]  1%|          | 3/500 [00:54<2:29:55, 18.10s/it]  1%|          | 4/500 [01:10<2:22:02, 17.18s/it]  1%|          | 5/500 [01:26<2:18:05, 16.74s/it]  1%|          | 6/500 [01:46<2:27:52, 17.96s/it]  1%|▏         | 7/500 [02:02<2:21:19, 17.20s/it]  2%|▏         | 8/500 [02:23<2:29:28, 18.23s/it]  2%|▏         | 9/500 [02:38<2:22:49, 17.45s/it]  2%|▏         | 10/500 [02:54<2:19:14, 17.05s/it]  2%|▏         | 11/500 [03:10<2:15:24, 16.61s/it]  2%|▏         | 12/500 [03:26<2:12:52, 16.34s/it]  3%|▎         | 13/500 [03:41<2:10:40, 16.10s/it]  3%|▎         | 14/500 [03:58<2:12:22, 16.34s/it]  3%|▎         | 15/500 [04:15<2:12:10, 16.35s/it]  3%|▎         | 16/500 [04:30<2:10:42, 16.20s/it]  3%|▎         | 17/500 [04:46<2:08:57, 16.02s/it]  4%|▎         | 18/500 [05:02<2:08:05, 15.94s/it]  4%|▍         | 19/500 [05:17<2:07:10, 15.86s/it]  4%|▍         | 20/500 [05:33<2:06:34, 15.82s/it]  4%|▍         | 21/500 [05:54<2:17:58, 17.28s/it]  4%|▍         | 22/500 [06:10<2:13:50, 16.80s/it]  5%|▍         | 23/500 [06:25<2:10:45, 16.45s/it]  5%|▍         | 24/500 [06:41<2:08:50, 16.24s/it]  5%|▌         | 25/500 [06:57<2:07:49, 16.15s/it]  5%|▌         | 26/500 [07:13<2:07:02, 16.08s/it]  5%|▌         | 27/500 [07:29<2:07:23, 16.16s/it]  6%|▌         | 28/500 [07:45<2:07:03, 16.15s/it]  6%|▌         | 29/500 [08:06<2:17:26, 17.51s/it]  6%|▌         | 30/500 [08:21<2:12:20, 16.89s/it]  6%|▌         | 31/500 [08:37<2:08:44, 16.47s/it]  6%|▋         | 32/500 [08:57<2:17:31, 17.63s/it]  7%|▋         | 33/500 [09:14<2:14:30, 17.28s/it]  7%|▋         | 34/500 [09:29<2:09:44, 16.71s/it]  7%|▋         | 35/500 [09:45<2:06:56, 16.38s/it]  7%|▋         | 36/500 [10:01<2:06:08, 16.31s/it]  7%|▋         | 37/500 [10:21<2:14:51, 17.48s/it]  8%|▊         | 38/500 [10:37<2:10:15, 16.92s/it]  8%|▊         | 39/500 [10:58<2:19:14, 18.12s/it]  8%|▊         | 40/500 [11:13<2:13:00, 17.35s/it]  8%|▊         | 41/500 [11:29<2:10:10, 17.02s/it]  8%|▊         | 41/500 [11:29<2:08:43, 16.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.019 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▃▂▁▁▁▁▁▁▁▁▁▁█▄▁▂▂▄▄█▄▁▄██▂▁██▇▇▇▃█▅██
wandb:     train_loss ▁▁▁▁▁▂▁▄▁▁▆▂▃▄█▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▁▁▁▁
wandb:   val_accuracy ▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁█▆▁▄▂▆▃▇▆▁▅█▇▂▂▆▇▅█▅▄▇▆▆▆
wandb:       val_loss ▁▁▁▁▁▃▆▅▄▄█▃▃▃▇▁▁▂▂▂▁▁▁▂▁▁▁▁▁▂▂▁▁▁▂▂▁▂▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.97771
wandb:     train_loss 6e-05
wandb:   val_accuracy 0.70667
wandb:       val_loss 0.70389
wandb: 
wandb: 🚀 View run driven-cloud-18 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rcanamoj
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_193359-rcanamoj/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_194614-18hmlf92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-oath-19
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/18hmlf92
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:37:02, 18.88s/it]  0%|          | 2/500 [00:34<2:21:51, 17.09s/it]  1%|          | 3/500 [00:49<2:14:31, 16.24s/it]  1%|          | 4/500 [01:06<2:15:49, 16.43s/it]  1%|          | 5/500 [01:27<2:27:26, 17.87s/it]  1%|          | 6/500 [01:46<2:30:22, 18.27s/it]  1%|▏         | 7/500 [02:01<2:23:05, 17.41s/it]  2%|▏         | 8/500 [02:17<2:19:26, 17.01s/it]  2%|▏         | 9/500 [02:33<2:15:21, 16.54s/it]  2%|▏         | 10/500 [02:48<2:12:07, 16.18s/it]  2%|▏         | 11/500 [03:08<2:21:10, 17.32s/it]  2%|▏         | 12/500 [03:24<2:18:00, 16.97s/it]  3%|▎         | 13/500 [03:41<2:16:47, 16.85s/it]  3%|▎         | 14/500 [03:57<2:13:31, 16.49s/it]  3%|▎         | 15/500 [04:13<2:12:45, 16.42s/it]  3%|▎         | 16/500 [04:29<2:11:10, 16.26s/it]  3%|▎         | 17/500 [04:44<2:09:29, 16.09s/it]  4%|▎         | 18/500 [05:00<2:08:04, 15.94s/it]  4%|▍         | 19/500 [05:16<2:08:19, 16.01s/it]  4%|▍         | 20/500 [05:32<2:07:32, 15.94s/it]  4%|▍         | 21/500 [05:48<2:06:46, 15.88s/it]  4%|▍         | 22/500 [06:03<2:06:13, 15.84s/it]  5%|▍         | 23/500 [06:19<2:04:56, 15.72s/it]  5%|▍         | 24/500 [06:34<2:04:03, 15.64s/it]  5%|▌         | 25/500 [06:55<2:14:47, 17.03s/it]  5%|▌         | 26/500 [07:10<2:11:11, 16.61s/it]  5%|▌         | 27/500 [07:27<2:12:05, 16.76s/it]  6%|▌         | 28/500 [07:48<2:20:03, 17.80s/it]  6%|▌         | 29/500 [08:04<2:16:00, 17.33s/it]  6%|▌         | 30/500 [08:19<2:11:28, 16.78s/it]  6%|▌         | 31/500 [08:39<2:17:35, 17.60s/it]  6%|▋         | 32/500 [08:55<2:13:28, 17.11s/it]  7%|▋         | 33/500 [09:11<2:10:20, 16.75s/it]  7%|▋         | 34/500 [09:26<2:06:46, 16.32s/it]  7%|▋         | 35/500 [09:42<2:06:30, 16.32s/it]  7%|▋         | 36/500 [09:59<2:06:21, 16.34s/it]  7%|▋         | 37/500 [10:15<2:05:28, 16.26s/it]  8%|▊         | 38/500 [10:31<2:04:02, 16.11s/it]  8%|▊         | 39/500 [10:47<2:04:11, 16.16s/it]  8%|▊         | 40/500 [11:04<2:05:48, 16.41s/it]  8%|▊         | 41/500 [11:21<2:06:15, 16.50s/it]  8%|▊         | 41/500 [11:21<2:07:04, 16.61s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.010 MB of 0.310 MB uploadedwandb: - 0.019 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▄▁▂▁▂▁▆███▄▅██▅██▃▆██▇█▇███████████████
wandb:     train_loss ▃▃█▁█▃█▁▁▁▂█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▁▂▂▃▁▇▇▇▇▄▅██▅██▃▆██▆█▆█▇▇▇▇▇▇▇▇▆▆██▆▇
wandb:       val_loss ▂▂▃▃▃▄█▁▄▃▃▄▆▁▂▄▃▂▃▂▁▁▁▃▁▂▁▄▁▄▃▁▃▂▆▃▁▂▁▃
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.00042
wandb:   val_accuracy 0.7
wandb:       val_loss 2.16041
wandb: 
wandb: 🚀 View run mild-oath-19 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/18hmlf92
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_194614-18hmlf92/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_195823-t0hddei3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-plasma-20
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t0hddei3
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:31:49, 18.25s/it]  0%|          | 2/500 [00:33<2:16:23, 16.43s/it]  1%|          | 3/500 [00:48<2:09:58, 15.69s/it]  1%|          | 4/500 [01:03<2:09:25, 15.66s/it]  1%|          | 5/500 [01:19<2:08:17, 15.55s/it]  1%|          | 6/500 [01:38<2:18:57, 16.88s/it]  1%|▏         | 7/500 [01:53<2:13:37, 16.26s/it]  2%|▏         | 8/500 [02:08<2:10:30, 15.91s/it]  2%|▏         | 9/500 [02:24<2:08:32, 15.71s/it]  2%|▏         | 10/500 [02:39<2:07:03, 15.56s/it]  2%|▏         | 11/500 [02:54<2:05:46, 15.43s/it]  2%|▏         | 12/500 [03:09<2:04:01, 15.25s/it]  3%|▎         | 13/500 [03:24<2:03:05, 15.16s/it]  3%|▎         | 14/500 [03:39<2:02:24, 15.11s/it]  3%|▎         | 15/500 [03:54<2:02:21, 15.14s/it]  3%|▎         | 16/500 [04:09<2:01:16, 15.03s/it]  3%|▎         | 17/500 [04:24<2:00:42, 14.99s/it]  4%|▎         | 18/500 [04:39<2:00:30, 15.00s/it]  4%|▍         | 19/500 [04:59<2:12:05, 16.48s/it]  4%|▍         | 20/500 [05:14<2:08:53, 16.11s/it]  4%|▍         | 21/500 [05:29<2:06:50, 15.89s/it]  4%|▍         | 22/500 [05:44<2:04:29, 15.63s/it]  5%|▍         | 23/500 [06:00<2:03:44, 15.56s/it]  5%|▍         | 24/500 [06:15<2:02:45, 15.47s/it]  5%|▌         | 25/500 [06:30<2:01:25, 15.34s/it]  5%|▌         | 26/500 [06:45<2:00:36, 15.27s/it]  5%|▌         | 27/500 [07:00<2:00:14, 15.25s/it]  6%|▌         | 28/500 [07:15<1:59:23, 15.18s/it]  6%|▌         | 29/500 [07:35<2:09:32, 16.50s/it]  6%|▌         | 30/500 [07:50<2:06:59, 16.21s/it]  6%|▌         | 31/500 [08:06<2:05:29, 16.05s/it]  6%|▋         | 32/500 [08:22<2:04:19, 15.94s/it]  7%|▋         | 33/500 [08:37<2:01:51, 15.66s/it]  7%|▋         | 34/500 [08:52<2:00:23, 15.50s/it]  7%|▋         | 35/500 [09:07<1:59:22, 15.40s/it]  7%|▋         | 36/500 [09:27<2:10:50, 16.92s/it]  7%|▋         | 37/500 [09:43<2:07:37, 16.54s/it]  8%|▊         | 38/500 [09:58<2:04:08, 16.12s/it]  8%|▊         | 39/500 [10:13<2:01:09, 15.77s/it]  8%|▊         | 39/500 [10:13<2:00:55, 15.74s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.019 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▂▄▁▂▂▂▂▂▂▂▂█▂▃▃▃▂▂▃▂▃▆▃▂▃▃█▃▂▃▂▃▃▂▃▅
wandb:     train_loss ▁▁▁▂▁▁▁▁▁▂▁▁▂▁▁█▁▁▂▅▁▂▅▂▁▂▂▁▁▁▂▂▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▂▁▃▁▃▂▂▁▂▂▁▂█▁▂▂▂▁▁▂▁▂▅▂▁▂▂▇▂▁▂▁▂▂▂▂▄
wandb:       val_loss ▁▁▁▁▁▁▁▁▁▂▁▂▂▁▁█▁▁▁▅▄▂▁▁▁▁▂▁▁▁▁▂▂▃▁▁▂▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 38
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.52749
wandb:     train_loss 0.08805
wandb:   val_accuracy 0.48667
wandb:       val_loss 1.82623
wandb: 
wandb: 🚀 View run fresh-plasma-20 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t0hddei3
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_195823-t0hddei3/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_200920-sj3eeje1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-universe-21
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sj3eeje1
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:20:40, 16.92s/it]  0%|          | 2/500 [00:32<2:13:58, 16.14s/it]  1%|          | 3/500 [00:57<2:47:01, 20.16s/it]  1%|          | 4/500 [01:13<2:32:16, 18.42s/it]  1%|          | 5/500 [01:29<2:24:09, 17.47s/it]  1%|          | 6/500 [01:49<2:32:09, 18.48s/it]  1%|▏         | 7/500 [02:05<2:24:25, 17.58s/it]  2%|▏         | 8/500 [02:25<2:32:19, 18.58s/it]  2%|▏         | 9/500 [02:41<2:24:44, 17.69s/it]  2%|▏         | 10/500 [02:57<2:19:27, 17.08s/it]  2%|▏         | 11/500 [03:13<2:16:18, 16.72s/it]  2%|▏         | 12/500 [03:33<2:23:52, 17.69s/it]  3%|▎         | 13/500 [03:48<2:16:50, 16.86s/it]  3%|▎         | 14/500 [04:03<2:13:11, 16.44s/it]  3%|▎         | 15/500 [04:19<2:11:16, 16.24s/it]  3%|▎         | 16/500 [04:35<2:09:36, 16.07s/it]  3%|▎         | 17/500 [04:55<2:19:13, 17.30s/it]  4%|▎         | 18/500 [05:11<2:16:07, 16.94s/it]  4%|▍         | 19/500 [05:26<2:12:33, 16.53s/it]  4%|▍         | 20/500 [05:42<2:10:36, 16.33s/it]  4%|▍         | 21/500 [05:58<2:08:57, 16.15s/it]  4%|▍         | 22/500 [06:18<2:18:43, 17.41s/it]  5%|▍         | 23/500 [06:34<2:14:27, 16.91s/it]  5%|▍         | 24/500 [06:50<2:12:01, 16.64s/it]  5%|▌         | 25/500 [07:06<2:09:01, 16.30s/it]  5%|▌         | 26/500 [07:21<2:06:55, 16.07s/it]  5%|▌         | 27/500 [07:37<2:05:21, 15.90s/it]  6%|▌         | 28/500 [07:52<2:04:28, 15.82s/it]  6%|▌         | 29/500 [08:08<2:03:57, 15.79s/it]  6%|▌         | 30/500 [08:23<2:02:56, 15.70s/it]  6%|▌         | 31/500 [08:39<2:02:19, 15.65s/it]  6%|▋         | 32/500 [08:54<2:01:42, 15.60s/it]  7%|▋         | 33/500 [09:10<2:02:17, 15.71s/it]  7%|▋         | 34/500 [09:26<2:01:01, 15.58s/it]  7%|▋         | 35/500 [09:41<2:01:06, 15.63s/it]  7%|▋         | 36/500 [09:57<2:00:35, 15.59s/it]  7%|▋         | 37/500 [10:12<1:59:50, 15.53s/it]  8%|▊         | 38/500 [10:28<2:00:07, 15.60s/it]  8%|▊         | 39/500 [10:48<2:09:59, 16.92s/it]  8%|▊         | 40/500 [11:04<2:08:25, 16.75s/it]  8%|▊         | 41/500 [11:25<2:16:04, 17.79s/it]  8%|▊         | 41/500 [11:25<2:07:50, 16.71s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.231 MB of 0.312 MB uploadedwandb: - 0.231 MB of 0.312 MB uploadedwandb: \ 0.231 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▆▄▅▆▇▅▃███▆▇█▇█████████████████▇█████
wandb:     train_loss ▅▅▂▄▁▃▁▁▂█▁▂▁▄▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▅▅▅▅▆▆▄▃█▆▇▅█▆███▇▆▆▅▆▆▆▆▆▆▆▆▆▅▅▅▅▆▆▅▅
wandb:       val_loss ▃▃▂▂▂▂▂▁▂▄▁▃▃▁▁▅▁▃▂▁▁▁▁▂▁▃▁▇▂▇▆▁▆▆▄▇▃▄▂█
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.99257
wandb:     train_loss 0.01264
wandb:   val_accuracy 0.66667
wandb:       val_loss 5.03167
wandb: 
wandb: 🚀 View run glamorous-universe-21 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sj3eeje1
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_200920-sj3eeje1/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_202124-o7bd0vfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-tree-22
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/o7bd0vfn
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:25:46, 17.53s/it]  0%|          | 2/500 [00:33<2:17:34, 16.57s/it]  1%|          | 3/500 [00:49<2:14:27, 16.23s/it]  1%|          | 4/500 [01:05<2:12:44, 16.06s/it]  1%|          | 5/500 [01:25<2:25:22, 17.62s/it]  1%|          | 6/500 [01:41<2:19:37, 16.96s/it]  1%|▏         | 7/500 [01:56<2:16:21, 16.60s/it]  2%|▏         | 8/500 [02:17<2:26:24, 17.85s/it]  2%|▏         | 9/500 [02:33<2:20:54, 17.22s/it]  2%|▏         | 10/500 [02:48<2:16:36, 16.73s/it]  2%|▏         | 11/500 [03:04<2:13:50, 16.42s/it]  2%|▏         | 12/500 [03:20<2:11:40, 16.19s/it]  3%|▎         | 13/500 [03:35<2:09:44, 15.98s/it]  3%|▎         | 14/500 [04:00<2:30:51, 18.62s/it]  3%|▎         | 15/500 [04:16<2:23:48, 17.79s/it]  3%|▎         | 16/500 [04:32<2:18:09, 17.13s/it]  3%|▎         | 17/500 [04:47<2:14:10, 16.67s/it]  4%|▎         | 18/500 [05:03<2:11:06, 16.32s/it]  4%|▍         | 19/500 [05:19<2:09:46, 16.19s/it]  4%|▍         | 20/500 [05:39<2:19:42, 17.46s/it]  4%|▍         | 21/500 [05:55<2:15:55, 17.03s/it]  4%|▍         | 22/500 [06:11<2:12:19, 16.61s/it]  5%|▍         | 23/500 [06:26<2:09:51, 16.33s/it]  5%|▍         | 24/500 [06:42<2:07:17, 16.05s/it]  5%|▌         | 25/500 [06:57<2:06:27, 15.97s/it]  5%|▌         | 26/500 [07:13<2:05:00, 15.82s/it]  5%|▌         | 27/500 [07:28<2:04:01, 15.73s/it]  6%|▌         | 28/500 [07:44<2:03:10, 15.66s/it]  6%|▌         | 29/500 [08:00<2:03:02, 15.67s/it]  6%|▌         | 30/500 [08:15<2:02:24, 15.63s/it]  6%|▌         | 31/500 [08:31<2:03:00, 15.74s/it]  6%|▋         | 32/500 [08:47<2:02:12, 15.67s/it]  7%|▋         | 33/500 [09:06<2:11:31, 16.90s/it]  7%|▋         | 34/500 [09:22<2:08:16, 16.52s/it]  7%|▋         | 35/500 [09:38<2:06:34, 16.33s/it]  7%|▋         | 36/500 [09:54<2:05:03, 16.17s/it]  7%|▋         | 37/500 [10:10<2:04:20, 16.11s/it]  8%|▊         | 38/500 [10:30<2:13:37, 17.35s/it]  8%|▊         | 39/500 [10:46<2:09:25, 16.84s/it]  8%|▊         | 40/500 [11:01<2:06:14, 16.47s/it]  8%|▊         | 41/500 [11:21<2:14:12, 17.54s/it]  8%|▊         | 41/500 [11:21<2:07:12, 16.63s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.232 MB of 0.311 MB uploadedwandb: \ 0.232 MB of 0.311 MB uploadedwandb: | 0.232 MB of 0.311 MB uploadedwandb: / 0.232 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▁▂▁▁▂▂▃▅▄▄▇▆▄▆█▅▆██▇█▇███████████████
wandb:     train_loss ▃▃█▁█▃█▃▁▁▄▇█▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▁▂▂▂▁▃▂▃▆▄▅▇▆▄██▅▅▇█▆▇▆▇▇▆▇▆▇▇▆▆▅▆▆▇▆▆
wandb:       val_loss ▂▂▃▄▃▆▇▁▇█▃▃▆▁▂▄▂▂▃▂▁▁▁▄▁▄▁▆▁▄▃▁▃▅▆▄▂▁▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99108
wandb:     train_loss 0.00052
wandb:   val_accuracy 0.64667
wandb:       val_loss 2.97329
wandb: 
wandb: 🚀 View run effortless-tree-22 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/o7bd0vfn
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_202124-o7bd0vfn/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_203334-c0jm3wvz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-valley-23
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/c0jm3wvz
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:27:04, 17.68s/it]  0%|          | 2/500 [00:33<2:16:17, 16.42s/it]  1%|          | 3/500 [00:48<2:13:14, 16.08s/it]  1%|          | 4/500 [01:09<2:27:30, 17.84s/it]  1%|          | 5/500 [01:25<2:20:37, 17.05s/it]  1%|          | 6/500 [01:45<2:28:47, 18.07s/it]  1%|▏         | 7/500 [02:00<2:21:25, 17.21s/it]  2%|▏         | 8/500 [02:16<2:16:51, 16.69s/it]  2%|▏         | 9/500 [02:31<2:14:03, 16.38s/it]  2%|▏         | 10/500 [02:47<2:11:31, 16.10s/it]  2%|▏         | 11/500 [03:03<2:10:10, 15.97s/it]  2%|▏         | 12/500 [03:18<2:09:03, 15.87s/it]  3%|▎         | 13/500 [03:34<2:07:57, 15.77s/it]  3%|▎         | 14/500 [03:49<2:07:11, 15.70s/it]  3%|▎         | 15/500 [04:09<2:17:39, 17.03s/it]  3%|▎         | 16/500 [04:26<2:15:19, 16.78s/it]  3%|▎         | 17/500 [04:42<2:14:41, 16.73s/it]  4%|▎         | 18/500 [04:58<2:11:52, 16.42s/it]  4%|▍         | 19/500 [05:13<2:09:28, 16.15s/it]  4%|▍         | 20/500 [05:29<2:07:53, 15.99s/it]  4%|▍         | 21/500 [05:45<2:07:53, 16.02s/it]  4%|▍         | 22/500 [06:01<2:06:44, 15.91s/it]  5%|▍         | 23/500 [06:17<2:07:24, 16.03s/it]  5%|▍         | 24/500 [06:33<2:06:58, 16.00s/it]  5%|▌         | 25/500 [06:49<2:05:38, 15.87s/it]  5%|▌         | 26/500 [07:09<2:15:29, 17.15s/it]  5%|▌         | 27/500 [07:24<2:11:51, 16.73s/it]  6%|▌         | 28/500 [07:40<2:09:34, 16.47s/it]  6%|▌         | 29/500 [07:56<2:07:10, 16.20s/it]  6%|▌         | 30/500 [08:16<2:16:40, 17.45s/it]  6%|▌         | 31/500 [08:32<2:12:29, 16.95s/it]  6%|▋         | 32/500 [08:48<2:09:28, 16.60s/it]  7%|▋         | 33/500 [09:03<2:06:54, 16.31s/it]  7%|▋         | 34/500 [09:19<2:04:56, 16.09s/it]  7%|▋         | 35/500 [09:35<2:05:01, 16.13s/it]  7%|▋         | 36/500 [09:51<2:03:47, 16.01s/it]  7%|▋         | 37/500 [10:07<2:02:38, 15.89s/it]  8%|▊         | 38/500 [10:27<2:13:07, 17.29s/it]  8%|▊         | 39/500 [10:47<2:19:24, 18.14s/it]  8%|▊         | 40/500 [11:03<2:13:17, 17.39s/it]  8%|▊         | 41/500 [11:19<2:09:24, 16.92s/it]  8%|▊         | 42/500 [11:35<2:06:44, 16.60s/it]  9%|▊         | 43/500 [11:50<2:04:31, 16.35s/it]  9%|▉         | 44/500 [12:06<2:03:03, 16.19s/it]  9%|▉         | 45/500 [12:22<2:01:25, 16.01s/it]  9%|▉         | 46/500 [12:38<2:00:47, 15.96s/it]  9%|▉         | 47/500 [12:53<1:59:39, 15.85s/it] 10%|▉         | 48/500 [13:09<1:59:03, 15.80s/it] 10%|▉         | 49/500 [13:25<1:58:41, 15.79s/it] 10%|█         | 50/500 [13:40<1:58:09, 15.75s/it] 10%|█         | 51/500 [13:56<1:57:33, 15.71s/it] 10%|█         | 51/500 [14:01<2:03:24, 16.49s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.316 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▂▆▆▆▇▇▇▇▇▇▇▇▇▇▇▃▃▂▃▃▂▃▂▂▃█▃▃▃▄▂▂▄▄▃▇▆
wandb:     train_loss ▃▃▃▃▃▂▂▃▃▃▃▃▃▃▂▃▂▁▃▃▁▃▃▁▃█▁▃▃▃▃▃▄▁▁▆▂▃▂▃
wandb:   val_accuracy ▁▁▁▁████▇▆▇▃▅██▇█▇▂▂▁▂▂▁▂▁▁▂▇▂▂▂▄▁▂▄▃▂▇▆
wandb:       val_loss ▂▂▂▂▁▂▁▂▁▂▂▂▂▂▁▂▂▁▂▂▃▂▂▄▂▄█▁▂▂▂▂▃▃▄▃▂▂▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 50
wandb:  learning_rate 0.0
wandb: train_accuracy 0.68351
wandb:     train_loss 0.9908
wandb:   val_accuracy 0.60444
wandb:       val_loss 1.0023
wandb: 
wandb: 🚀 View run spring-valley-23 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/c0jm3wvz
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_203334-c0jm3wvz/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_204830-1g1ai6np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-star-24
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1g1ai6np
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:28:39, 17.88s/it]  0%|          | 2/500 [00:33<2:17:23, 16.55s/it]  1%|          | 3/500 [00:49<2:13:57, 16.17s/it]  1%|          | 4/500 [01:04<2:12:10, 15.99s/it]  1%|          | 5/500 [01:20<2:11:02, 15.88s/it]  1%|          | 6/500 [01:36<2:09:22, 15.71s/it]  1%|▏         | 7/500 [01:51<2:08:01, 15.58s/it]  2%|▏         | 8/500 [02:11<2:19:22, 17.00s/it]  2%|▏         | 9/500 [02:26<2:15:19, 16.54s/it]  2%|▏         | 10/500 [02:41<2:10:46, 16.01s/it]  2%|▏         | 11/500 [03:01<2:19:33, 17.12s/it]  2%|▏         | 12/500 [03:16<2:13:32, 16.42s/it]  3%|▎         | 13/500 [03:36<2:21:46, 17.47s/it]  3%|▎         | 14/500 [03:50<2:15:11, 16.69s/it]  3%|▎         | 15/500 [04:06<2:11:35, 16.28s/it]  3%|▎         | 16/500 [04:21<2:07:39, 15.83s/it]  3%|▎         | 17/500 [04:36<2:06:32, 15.72s/it]  4%|▎         | 18/500 [04:55<2:15:20, 16.85s/it]  4%|▍         | 19/500 [05:11<2:11:11, 16.36s/it]  4%|▍         | 20/500 [05:26<2:07:14, 15.90s/it]  4%|▍         | 21/500 [05:41<2:05:36, 15.73s/it]  4%|▍         | 22/500 [06:01<2:16:09, 17.09s/it]  5%|▍         | 23/500 [06:16<2:10:49, 16.46s/it]  5%|▍         | 24/500 [06:32<2:08:27, 16.19s/it]  5%|▍         | 24/500 [06:32<2:09:39, 16.34s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▂▅▆▇▆▇▄▅▆▇██▇▇█▇█████▇█
wandb:     train_loss ▇█▄▅▂▃▂▁▂▂▂▅▂▅▁▁▁▄▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▆█▆▇▆▃▃▅█▇█▇▇▆▇▇▇▇▇▇▆▇
wandb:       val_loss ▄▄▃▂▃▂▂▁▃▅▂▃▅▂▁█▇█▂▂▁▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.99703
wandb:     train_loss 0.00795
wandb:   val_accuracy 0.67778
wandb:       val_loss 0.45601
wandb: 
wandb: 🚀 View run misunderstood-star-24 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1g1ai6np
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_204830-1g1ai6np/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_205554-eorcvnkb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-river-25
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eorcvnkb
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:24:55, 17.43s/it]  0%|          | 2/500 [00:36<2:33:16, 18.47s/it]  1%|          | 3/500 [00:51<2:18:44, 16.75s/it]  1%|          | 4/500 [01:05<2:10:48, 15.82s/it]  1%|          | 5/500 [01:24<2:20:01, 16.97s/it]  1%|          | 6/500 [01:39<2:12:47, 16.13s/it]  1%|▏         | 7/500 [01:58<2:20:14, 17.07s/it]  2%|▏         | 8/500 [02:12<2:12:31, 16.16s/it]  2%|▏         | 9/500 [02:31<2:19:38, 17.07s/it]  2%|▏         | 10/500 [02:45<2:12:35, 16.24s/it]  2%|▏         | 11/500 [03:05<2:21:10, 17.32s/it]  2%|▏         | 12/500 [03:19<2:13:28, 16.41s/it]  3%|▎         | 13/500 [03:39<2:19:53, 17.24s/it]  3%|▎         | 14/500 [03:58<2:25:08, 17.92s/it]  3%|▎         | 15/500 [04:13<2:17:33, 17.02s/it]  3%|▎         | 16/500 [04:33<2:23:23, 17.78s/it]  3%|▎         | 17/500 [04:47<2:15:45, 16.86s/it]  4%|▎         | 18/500 [05:02<2:10:07, 16.20s/it]  4%|▍         | 19/500 [05:17<2:06:12, 15.74s/it]  4%|▍         | 20/500 [05:31<2:03:38, 15.46s/it]  4%|▍         | 21/500 [05:47<2:02:42, 15.37s/it]  4%|▍         | 22/500 [06:01<2:00:49, 15.17s/it]  5%|▍         | 23/500 [06:16<2:00:22, 15.14s/it]  5%|▍         | 24/500 [06:32<2:00:03, 15.13s/it]  5%|▌         | 25/500 [06:47<1:59:29, 15.09s/it]  5%|▌         | 26/500 [07:01<1:58:33, 15.01s/it]  5%|▌         | 27/500 [07:16<1:58:34, 15.04s/it]  6%|▌         | 28/500 [07:32<1:58:32, 15.07s/it]  6%|▌         | 29/500 [07:46<1:57:26, 14.96s/it]  6%|▌         | 30/500 [08:01<1:56:58, 14.93s/it]  6%|▌         | 31/500 [08:16<1:56:12, 14.87s/it]  6%|▋         | 32/500 [08:31<1:56:05, 14.88s/it]  7%|▋         | 33/500 [08:45<1:55:22, 14.82s/it]  7%|▋         | 34/500 [09:05<2:05:49, 16.20s/it]  7%|▋         | 35/500 [09:20<2:01:53, 15.73s/it]  7%|▋         | 36/500 [09:34<1:59:49, 15.50s/it]  7%|▋         | 37/500 [09:49<1:58:20, 15.34s/it]  8%|▊         | 38/500 [10:06<2:01:43, 15.81s/it]  8%|▊         | 39/500 [10:21<1:58:37, 15.44s/it]  8%|▊         | 40/500 [10:36<1:56:43, 15.23s/it]  8%|▊         | 41/500 [10:51<1:56:06, 15.18s/it]  8%|▊         | 41/500 [10:51<2:01:30, 15.88s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.028 MB uploadedwandb: | 0.019 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▂▂▂▂▂▂▁▁▁▃▃▅▄▄▂▇█▇▇██▅▇█▇█▇█▇▇███████▇█
wandb:     train_loss ▂▂▃▂▅▃▅▇▁▁▄▇▃▄▁▁▂▁▁▁▁▁▁▁▁█▂▁▁▁▁▁▁▁▄▁▁▁▁▁
wandb:   val_accuracy ▂▁▁▂▂▄▃▃▃▃▃▄▆▆▃▃▆█▅▇▇▆▃▄▅▅▇▄▇▅▅▇▆▅▇▆▇▇▅▆
wandb:       val_loss ▂▂▂▂▂▂▂▄▄▄▂▅▅▁▅▄▂▁▂▂▁▄█▂▁▂▁▆▂▄▆▁▄▅▃▄▁▂▂▃
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.9896
wandb:     train_loss 0.01351
wandb:   val_accuracy 0.58889
wandb:       val_loss 2.71349
wandb: 
wandb: 🚀 View run icy-river-25 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eorcvnkb
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_205554-eorcvnkb/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_210724-lbnt7wr8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-brook-26
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lbnt7wr8
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:29:43, 18.00s/it]  0%|          | 2/500 [00:32<2:14:34, 16.21s/it]  1%|          | 3/500 [00:48<2:10:34, 15.76s/it]  1%|          | 4/500 [01:03<2:08:50, 15.58s/it]  1%|          | 5/500 [01:18<2:07:28, 15.45s/it]  1%|          | 6/500 [01:33<2:05:56, 15.30s/it]  1%|▏         | 7/500 [01:48<2:05:06, 15.23s/it]  2%|▏         | 8/500 [02:03<2:04:27, 15.18s/it]  2%|▏         | 9/500 [02:18<2:03:13, 15.06s/it]  2%|▏         | 10/500 [02:33<2:03:12, 15.09s/it]  2%|▏         | 11/500 [02:48<2:02:51, 15.07s/it]  2%|▏         | 12/500 [03:03<2:02:11, 15.02s/it]  3%|▎         | 13/500 [03:18<2:02:16, 15.07s/it]  3%|▎         | 14/500 [03:33<2:01:47, 15.04s/it]  3%|▎         | 15/500 [03:58<2:23:57, 17.81s/it]  3%|▎         | 16/500 [04:13<2:16:58, 16.98s/it]  3%|▎         | 17/500 [04:28<2:11:55, 16.39s/it]  4%|▎         | 18/500 [04:43<2:08:11, 15.96s/it]  4%|▍         | 19/500 [04:57<2:05:07, 15.61s/it]  4%|▍         | 20/500 [05:12<2:02:59, 15.37s/it]  4%|▍         | 21/500 [05:27<2:02:17, 15.32s/it]  4%|▍         | 22/500 [05:42<2:00:19, 15.10s/it]  5%|▍         | 23/500 [05:57<1:59:11, 14.99s/it]  5%|▍         | 24/500 [06:12<1:58:39, 14.96s/it]  5%|▌         | 25/500 [06:27<1:58:24, 14.96s/it]  5%|▌         | 26/500 [06:42<1:58:44, 15.03s/it]  5%|▌         | 27/500 [06:57<1:57:58, 14.96s/it]  6%|▌         | 28/500 [07:12<1:57:51, 14.98s/it]  6%|▌         | 29/500 [07:27<1:57:20, 14.95s/it]  6%|▌         | 30/500 [07:41<1:57:02, 14.94s/it]  6%|▌         | 31/500 [07:57<1:57:51, 15.08s/it]  6%|▋         | 32/500 [08:12<1:58:00, 15.13s/it]  7%|▋         | 33/500 [08:27<1:57:19, 15.07s/it]  7%|▋         | 34/500 [08:42<1:56:45, 15.03s/it]  7%|▋         | 35/500 [08:57<1:56:38, 15.05s/it]  7%|▋         | 36/500 [09:12<1:56:17, 15.04s/it]  7%|▋         | 37/500 [09:27<1:56:08, 15.05s/it]  8%|▊         | 38/500 [09:42<1:55:47, 15.04s/it]  8%|▊         | 39/500 [09:57<1:55:28, 15.03s/it]  8%|▊         | 40/500 [10:12<1:54:47, 14.97s/it]  8%|▊         | 41/500 [10:27<1:54:16, 14.94s/it]  8%|▊         | 41/500 [10:27<1:57:03, 15.30s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.313 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.138 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▃▅▆▆▇▇▇▇▇▇█▇▇██▇▇▇█▇████████████▇█▇▇█
wandb:     train_loss █▇▆▇▅█▄▄▇▆▇▆▆▇▅▅▆▅▆▅▃▂▄▂▂▄▆▄▂▁▁▄▄▂▇▇▃▄▄▄
wandb:   val_accuracy ▁▁▃▁▅█▆▆▆▇▇▅▆▆▆▄▇▆▄▆▇▆▄▆▆▆▆▅▆▆▆▆▆▅▅▅▇▇▅▆
wandb:       val_loss ▆▆▅▅▆▄▅▃▆▆▄▆▅▅▃▆▄▄▆▃▄▂█▄▁▂▅▇▇▄▂▄▄▇▃▅▅▅▅▄
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.76374
wandb:     train_loss 0.70869
wandb:   val_accuracy 0.62444
wandb:       val_loss 0.8627
wandb: 
wandb: 🚀 View run curious-brook-26 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lbnt7wr8
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_210724-lbnt7wr8/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_211835-fuzr69iq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-voice-27
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fuzr69iq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:27<3:48:59, 27.53s/it]  0%|          | 2/500 [00:43<2:53:41, 20.93s/it]  1%|          | 3/500 [01:00<2:37:14, 18.98s/it]  1%|          | 4/500 [01:17<2:30:18, 18.18s/it]  1%|          | 5/500 [01:33<2:24:36, 17.53s/it]  1%|          | 6/500 [01:50<2:21:09, 17.14s/it]  1%|▏         | 7/500 [02:06<2:18:19, 16.83s/it]  2%|▏         | 8/500 [02:22<2:16:56, 16.70s/it]  2%|▏         | 9/500 [02:38<2:15:02, 16.50s/it]  2%|▏         | 10/500 [03:00<2:26:41, 17.96s/it]  2%|▏         | 11/500 [03:16<2:22:29, 17.48s/it]  2%|▏         | 12/500 [03:32<2:19:01, 17.09s/it]  3%|▎         | 13/500 [03:49<2:17:17, 16.92s/it]  3%|▎         | 14/500 [04:05<2:15:42, 16.75s/it]  3%|▎         | 15/500 [04:22<2:14:38, 16.66s/it]  3%|▎         | 16/500 [04:43<2:26:25, 18.15s/it]  3%|▎         | 17/500 [05:00<2:21:48, 17.62s/it]  4%|▎         | 18/500 [05:16<2:17:52, 17.16s/it]  4%|▍         | 19/500 [05:37<2:27:11, 18.36s/it]  4%|▍         | 20/500 [05:53<2:22:34, 17.82s/it]  4%|▍         | 21/500 [06:10<2:20:16, 17.57s/it]  4%|▍         | 22/500 [06:27<2:16:48, 17.17s/it]  5%|▍         | 23/500 [06:43<2:14:51, 16.96s/it]  5%|▍         | 24/500 [06:59<2:12:12, 16.67s/it]  5%|▌         | 25/500 [07:20<2:22:06, 17.95s/it]  5%|▌         | 26/500 [07:36<2:18:08, 17.49s/it]  5%|▌         | 27/500 [07:57<2:26:12, 18.55s/it]  6%|▌         | 28/500 [08:14<2:20:37, 17.88s/it]  6%|▌         | 29/500 [08:30<2:16:40, 17.41s/it]  6%|▌         | 30/500 [08:46<2:13:57, 17.10s/it]  6%|▌         | 31/500 [09:03<2:13:15, 17.05s/it]  6%|▋         | 32/500 [09:20<2:12:05, 16.94s/it]  7%|▋         | 33/500 [09:37<2:10:49, 16.81s/it]  7%|▋         | 34/500 [09:58<2:22:15, 18.32s/it]  7%|▋         | 35/500 [10:15<2:17:19, 17.72s/it]  7%|▋         | 36/500 [10:31<2:14:31, 17.40s/it]  7%|▋         | 37/500 [10:48<2:12:23, 17.16s/it]  8%|▊         | 38/500 [11:04<2:09:59, 16.88s/it]  8%|▊         | 39/500 [11:20<2:07:50, 16.64s/it]  8%|▊         | 40/500 [11:41<2:17:08, 17.89s/it]  8%|▊         | 41/500 [11:57<2:12:40, 17.34s/it]  8%|▊         | 41/500 [11:57<2:13:54, 17.51s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.019 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▄▅▅▆▆▇▅▇▇▆▇▆▆▇▆▆▇▇█▆▇▆██▇▇█▇██▇█▇██▇█
wandb:     train_loss ▁█▁▂▁▂▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▃▃▃▆▅█▆▃▇▆▆▇▆▅▇▆▆▇▇▇▆▇▆▇█▆▇▇▇▇▇▆▇▇█▇▆█
wandb:       val_loss ▂█▁▁▂▁▁▁▂▂▁▂▃▁▁▂▁▂▂▂▁▁▁▂▁▂▁▂▁▂▂▁▂▃▂▂▁▂▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.91085
wandb:     train_loss 0.00105
wandb:   val_accuracy 0.63111
wandb:       val_loss 2.20991
wandb: 
wandb: 🚀 View run chocolate-voice-27 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fuzr69iq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_211835-fuzr69iq/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_213117-blvxk8s0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-frost-28
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/blvxk8s0
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:26:15, 17.59s/it]  0%|          | 2/500 [00:33<2:17:07, 16.52s/it]  1%|          | 3/500 [00:48<2:12:41, 16.02s/it]  1%|          | 4/500 [01:04<2:12:08, 15.99s/it]  1%|          | 5/500 [01:20<2:11:30, 15.94s/it]  1%|          | 6/500 [01:36<2:11:16, 15.95s/it]  1%|▏         | 7/500 [01:52<2:09:56, 15.81s/it]  2%|▏         | 8/500 [02:08<2:10:19, 15.89s/it]  2%|▏         | 9/500 [02:23<2:09:06, 15.78s/it]  2%|▏         | 10/500 [02:39<2:09:12, 15.82s/it]  2%|▏         | 11/500 [02:55<2:08:13, 15.73s/it]  2%|▏         | 12/500 [03:10<2:07:44, 15.71s/it]  3%|▎         | 13/500 [03:26<2:07:37, 15.72s/it]  3%|▎         | 14/500 [03:42<2:07:03, 15.69s/it]  3%|▎         | 15/500 [03:57<2:06:30, 15.65s/it]  3%|▎         | 16/500 [04:13<2:06:08, 15.64s/it]  3%|▎         | 17/500 [04:28<2:05:56, 15.65s/it]  4%|▎         | 18/500 [04:44<2:05:29, 15.62s/it]  4%|▍         | 19/500 [05:00<2:05:56, 15.71s/it]  4%|▍         | 20/500 [05:16<2:05:27, 15.68s/it]  4%|▍         | 21/500 [05:32<2:06:07, 15.80s/it]  4%|▍         | 22/500 [05:47<2:05:38, 15.77s/it]  5%|▍         | 23/500 [06:03<2:04:31, 15.66s/it]  5%|▍         | 24/500 [06:19<2:04:42, 15.72s/it]  5%|▍         | 24/500 [06:23<2:06:55, 16.00s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.314 MB uploadedwandb: \ 0.021 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▅▁▂▄▄▂▄▂██▄▆█▂▁█▆█▅▇▇█▇
wandb:     train_loss ▃▃▆▂▁▆▁▁▆▁▁▁▁▁█▂▁█▁▃▁▁▁▁
wandb:   val_accuracy ▁▇▁▄▆▆▃▆▄██▆▅█▃▂█▇▆▆▆▇██
wandb:       val_loss ▅▄█▂▃▁▂▁▁▃▂▁▃▂▁▇▃▂▁▅▃▁▁█
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.8321
wandb:     train_loss 0.00157
wandb:   val_accuracy 0.80667
wandb:       val_loss 1.85212
wandb: 
wandb: 🚀 View run decent-frost-28 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/blvxk8s0
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_213117-blvxk8s0/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_213821-febkvt66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sun-29
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/febkvt66
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:34:04, 18.53s/it]  0%|          | 2/500 [00:34<2:22:32, 17.17s/it]  1%|          | 3/500 [00:50<2:17:48, 16.64s/it]  1%|          | 4/500 [01:06<2:14:56, 16.32s/it]  1%|          | 5/500 [01:22<2:13:59, 16.24s/it]  1%|          | 6/500 [01:38<2:12:37, 16.11s/it]  1%|▏         | 7/500 [01:54<2:12:21, 16.11s/it]  2%|▏         | 8/500 [02:10<2:11:00, 15.98s/it]  2%|▏         | 9/500 [02:25<2:09:34, 15.83s/it]  2%|▏         | 10/500 [02:41<2:08:34, 15.74s/it]  2%|▏         | 11/500 [02:56<2:07:37, 15.66s/it]  2%|▏         | 12/500 [03:17<2:19:05, 17.10s/it]  3%|▎         | 13/500 [03:32<2:15:08, 16.65s/it]  3%|▎         | 14/500 [03:49<2:13:46, 16.52s/it]  3%|▎         | 15/500 [04:04<2:09:57, 16.08s/it]  3%|▎         | 16/500 [04:22<2:15:59, 16.86s/it]  3%|▎         | 17/500 [04:38<2:12:46, 16.49s/it]  4%|▎         | 18/500 [04:54<2:10:25, 16.24s/it]  4%|▍         | 19/500 [05:09<2:08:33, 16.04s/it]  4%|▍         | 20/500 [05:25<2:06:52, 15.86s/it]  4%|▍         | 21/500 [05:40<2:06:04, 15.79s/it]  4%|▍         | 22/500 [05:56<2:06:22, 15.86s/it]  5%|▍         | 23/500 [06:12<2:05:41, 15.81s/it]  5%|▍         | 24/500 [06:28<2:04:56, 15.75s/it]  5%|▌         | 25/500 [06:43<2:04:02, 15.67s/it]  5%|▌         | 26/500 [06:59<2:03:28, 15.63s/it]  5%|▌         | 27/500 [07:14<2:03:34, 15.68s/it]  6%|▌         | 28/500 [07:30<2:04:00, 15.76s/it]  6%|▌         | 29/500 [07:46<2:02:38, 15.62s/it]  6%|▌         | 30/500 [08:01<2:02:20, 15.62s/it]  6%|▌         | 31/500 [08:17<2:02:17, 15.64s/it]  6%|▋         | 32/500 [08:33<2:01:51, 15.62s/it]  7%|▋         | 33/500 [08:48<2:01:18, 15.59s/it]  7%|▋         | 34/500 [09:04<2:01:27, 15.64s/it]  7%|▋         | 35/500 [09:19<2:01:02, 15.62s/it]  7%|▋         | 36/500 [09:35<2:00:51, 15.63s/it]  7%|▋         | 37/500 [09:51<2:00:26, 15.61s/it]  8%|▊         | 38/500 [10:07<2:01:30, 15.78s/it]  8%|▊         | 38/500 [10:07<2:03:02, 15.98s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.315 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▅▇▇▇▇▆▇▇▅▆▆▆▆▇█▆▆▇█▅█▆█▇▇▇▇▇▇▇▇▇▆▇▇
wandb:     train_loss ▇▇▆▆▅▆▄▄▅▅▇█▇▇▄▄▆▄▅▄▃▂▄▂▃▅▅▆▁▂▁▃▇▃▇▃▃▄
wandb:   val_accuracy ▁▁▁▄█▇█▆▂▅▅▁▃▅▅▄▆▆▄▅▇▇▄▇▆█▇▆▇▇▇▇▇▇▆▆█▇
wandb:       val_loss ▆▆▅▆▆▄▆▅▆▆▅█▆▄▇▆▄▄▄▄▂▁▆▄▂▄▁█▃▄▅▂▄▄▇▅▅▅
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.65676
wandb:     train_loss 0.70687
wandb:   val_accuracy 0.62222
wandb:       val_loss 1.0185
wandb: 
wandb: 🚀 View run glorious-sun-29 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/febkvt66
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_213821-febkvt66/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_214913-wprlxns1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-plant-30
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wprlxns1
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:25:07, 17.45s/it]  0%|          | 2/500 [00:34<2:20:30, 16.93s/it]  1%|          | 3/500 [00:49<2:15:30, 16.36s/it]  1%|          | 4/500 [01:05<2:12:53, 16.08s/it]  1%|          | 5/500 [01:21<2:11:54, 15.99s/it]  1%|          | 6/500 [01:36<2:10:29, 15.85s/it]  1%|▏         | 7/500 [01:52<2:09:06, 15.71s/it]  2%|▏         | 8/500 [02:08<2:09:08, 15.75s/it]  2%|▏         | 9/500 [02:23<2:09:04, 15.77s/it]  2%|▏         | 10/500 [02:39<2:08:27, 15.73s/it]  2%|▏         | 11/500 [02:55<2:07:43, 15.67s/it]  2%|▏         | 12/500 [03:10<2:06:58, 15.61s/it]  3%|▎         | 13/500 [03:25<2:06:20, 15.57s/it]  3%|▎         | 14/500 [03:41<2:06:11, 15.58s/it]  3%|▎         | 15/500 [03:57<2:07:29, 15.77s/it]  3%|▎         | 16/500 [04:13<2:06:45, 15.71s/it]  3%|▎         | 17/500 [04:29<2:06:40, 15.74s/it]  4%|▎         | 18/500 [04:44<2:06:22, 15.73s/it]  4%|▍         | 19/500 [05:00<2:05:56, 15.71s/it]  4%|▍         | 20/500 [05:15<2:04:30, 15.56s/it]  4%|▍         | 21/500 [05:30<2:03:14, 15.44s/it]  4%|▍         | 22/500 [05:46<2:03:12, 15.47s/it]  5%|▍         | 23/500 [06:01<2:03:10, 15.49s/it]  5%|▍         | 24/500 [06:17<2:03:15, 15.54s/it]  5%|▌         | 25/500 [06:33<2:04:04, 15.67s/it]  5%|▌         | 26/500 [06:49<2:04:05, 15.71s/it]  5%|▌         | 27/500 [07:05<2:04:00, 15.73s/it]  6%|▌         | 28/500 [07:20<2:03:33, 15.71s/it]  6%|▌         | 29/500 [07:36<2:03:54, 15.78s/it]  6%|▌         | 30/500 [07:52<2:03:08, 15.72s/it]  6%|▌         | 31/500 [08:08<2:02:50, 15.72s/it]  6%|▋         | 32/500 [08:23<2:02:48, 15.74s/it]  7%|▋         | 33/500 [08:39<2:02:28, 15.74s/it]  7%|▋         | 34/500 [08:55<2:02:14, 15.74s/it]  7%|▋         | 35/500 [09:10<2:01:37, 15.69s/it]  7%|▋         | 36/500 [09:26<2:01:06, 15.66s/it]  7%|▋         | 37/500 [09:42<2:01:43, 15.77s/it]  8%|▊         | 38/500 [09:58<2:01:03, 15.72s/it]  8%|▊         | 39/500 [10:18<2:10:59, 17.05s/it]  8%|▊         | 40/500 [10:33<2:06:56, 16.56s/it]  8%|▊         | 41/500 [10:49<2:04:05, 16.22s/it]  8%|▊         | 41/500 [10:53<2:01:59, 15.95s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.313 MB uploadedwandb: \ 0.019 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▆▁▂▁▁▂▆▇▂█▂█▅▃▆▆▄▂▅▄▆█▇▃▆▆▅▇██▆██▇▇▇▇█▇
wandb:     train_loss ▂▂▃▂▃▂▁▁▁▅▂█▂▆▂▁▅▅▁▁▁▁▁▁▁▁▃▆▁▁▁▁▃▁▂▁▁▁▁▁
wandb:   val_accuracy ▄█▁▃▃▃▄██▄█▄█▆▅█▇█▄▇▇███▅███████████████
wandb:       val_loss ▂▂▂▂▂▂▃▁▃▅▂▅▄▁▂▁▅▁▆▅▁▁▁▄▁▃▁▂▁▃▄▁▂▃█▂▂▂▄▃
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.75483
wandb:     train_loss 2e-05
wandb:   val_accuracy 0.67778
wandb:       val_loss 2.33286
wandb: 
wandb: 🚀 View run happy-plant-30 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wprlxns1
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_214913-wprlxns1/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_220045-4ejsvwok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-brook-31
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4ejsvwok
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:29:45, 25.22s/it]  0%|          | 2/500 [00:49<3:24:43, 24.67s/it]  1%|          | 3/500 [01:13<3:21:11, 24.29s/it]  1%|          | 4/500 [01:37<3:19:40, 24.15s/it]  1%|          | 5/500 [02:06<3:34:34, 26.01s/it]  1%|          | 6/500 [02:36<3:45:45, 27.42s/it]  1%|▏         | 7/500 [03:00<3:35:36, 26.24s/it]  2%|▏         | 8/500 [03:24<3:28:35, 25.44s/it]  2%|▏         | 9/500 [03:47<3:23:26, 24.86s/it]  2%|▏         | 10/500 [04:11<3:20:32, 24.56s/it]  2%|▏         | 11/500 [04:35<3:17:53, 24.28s/it]  2%|▏         | 12/500 [04:59<3:16:27, 24.16s/it]  3%|▎         | 13/500 [05:23<3:15:04, 24.03s/it]  3%|▎         | 14/500 [05:46<3:13:44, 23.92s/it]  3%|▎         | 15/500 [06:10<3:12:36, 23.83s/it]  3%|▎         | 16/500 [06:39<3:25:01, 25.42s/it]  3%|▎         | 17/500 [07:03<3:20:33, 24.91s/it]  4%|▎         | 18/500 [07:27<3:17:40, 24.61s/it]  4%|▎         | 18/500 [07:27<3:19:30, 24.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.306 MB uploadedwandb: - 0.010 MB of 0.306 MB uploadedwandb: \ 0.230 MB of 0.306 MB uploadedwandb: | 0.230 MB of 0.306 MB uploadedwandb: / 0.230 MB of 0.306 MB uploadedwandb: - 0.306 MB of 0.306 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██
wandb:  learning_rate █████████▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▃█▁▁▁▁▃▂▂▄▂▃▂▂▂▃▂▂
wandb:     train_loss ▃▂▁▁█▁▂▂▂▂▁▂▁▂▂▂▂▂
wandb:   val_accuracy ▇█████▆▆▃▁▅▅▅▆▆▃▆▅
wandb:       val_loss ▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 17
wandb:  learning_rate 0.0005
wandb: train_accuracy 0.33581
wandb:     train_loss 1.09861
wandb:   val_accuracy 0.30889
wandb:       val_loss 1.09861
wandb: 
wandb: 🚀 View run frosty-brook-31 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4ejsvwok
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_220045-4ejsvwok/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_220850-x6h7er5v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-valley-32
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x6h7er5v
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:41:57, 26.69s/it]  0%|          | 2/500 [00:50<3:28:59, 25.18s/it]  1%|          | 3/500 [01:15<3:24:57, 24.74s/it]  1%|          | 4/500 [01:39<3:22:38, 24.51s/it]  1%|          | 5/500 [02:03<3:20:49, 24.34s/it]  1%|          | 6/500 [02:27<3:19:32, 24.24s/it]  1%|▏         | 7/500 [02:51<3:19:18, 24.26s/it]  2%|▏         | 8/500 [03:15<3:18:54, 24.26s/it]  2%|▏         | 9/500 [03:39<3:18:17, 24.23s/it]  2%|▏         | 10/500 [04:03<3:16:17, 24.04s/it]  2%|▏         | 11/500 [04:27<3:14:48, 23.90s/it]  2%|▏         | 12/500 [04:50<3:13:49, 23.83s/it]  3%|▎         | 13/500 [05:14<3:12:52, 23.76s/it]  3%|▎         | 14/500 [05:38<3:13:27, 23.88s/it]  3%|▎         | 15/500 [06:03<3:16:17, 24.28s/it]  3%|▎         | 16/500 [06:27<3:15:28, 24.23s/it]  3%|▎         | 17/500 [06:51<3:14:12, 24.13s/it]  4%|▎         | 18/500 [07:15<3:12:46, 24.00s/it]  4%|▍         | 19/500 [07:39<3:12:04, 23.96s/it]  4%|▍         | 20/500 [08:03<3:11:52, 23.98s/it]  4%|▍         | 21/500 [08:27<3:11:54, 24.04s/it]  4%|▍         | 22/500 [08:51<3:10:53, 23.96s/it]  5%|▍         | 23/500 [09:15<3:10:57, 24.02s/it]  5%|▍         | 24/500 [09:39<3:10:02, 23.96s/it]  5%|▌         | 25/500 [10:03<3:09:15, 23.91s/it]  5%|▌         | 26/500 [10:26<3:08:26, 23.85s/it]  5%|▌         | 27/500 [10:50<3:07:59, 23.85s/it]  6%|▌         | 28/500 [11:14<3:07:36, 23.85s/it]  6%|▌         | 29/500 [11:38<3:07:03, 23.83s/it]  6%|▌         | 30/500 [12:02<3:07:17, 23.91s/it]  6%|▌         | 31/500 [12:26<3:07:28, 23.98s/it]  6%|▋         | 32/500 [12:50<3:07:01, 23.98s/it]  7%|▋         | 33/500 [13:14<3:06:23, 23.95s/it]  7%|▋         | 34/500 [13:39<3:07:45, 24.18s/it]  7%|▋         | 35/500 [14:03<3:06:46, 24.10s/it]  7%|▋         | 36/500 [14:27<3:06:30, 24.12s/it]  7%|▋         | 37/500 [14:50<3:05:04, 23.98s/it]  8%|▊         | 38/500 [15:14<3:03:51, 23.88s/it]  8%|▊         | 39/500 [15:38<3:04:02, 23.95s/it]  8%|▊         | 40/500 [16:02<3:03:42, 23.96s/it]  8%|▊         | 41/500 [16:26<3:03:16, 23.96s/it]  8%|▊         | 42/500 [16:51<3:04:48, 24.21s/it]  9%|▊         | 43/500 [17:15<3:03:51, 24.14s/it]  9%|▉         | 44/500 [17:39<3:03:00, 24.08s/it]  9%|▉         | 45/500 [18:03<3:02:24, 24.05s/it]  9%|▉         | 46/500 [18:27<3:02:14, 24.08s/it]  9%|▉         | 47/500 [18:51<3:01:26, 24.03s/it] 10%|▉         | 48/500 [19:15<3:00:54, 24.01s/it] 10%|▉         | 49/500 [19:39<3:00:07, 23.96s/it] 10%|█         | 50/500 [20:03<2:59:30, 23.94s/it] 10%|█         | 51/500 [20:27<2:59:25, 23.98s/it] 10%|█         | 52/500 [20:51<2:59:08, 23.99s/it] 11%|█         | 53/500 [21:15<3:00:11, 24.19s/it] 11%|█         | 54/500 [21:39<2:59:37, 24.16s/it] 11%|█         | 55/500 [22:03<2:58:21, 24.05s/it] 11%|█         | 56/500 [22:27<2:57:27, 23.98s/it] 11%|█▏        | 57/500 [22:51<2:56:24, 23.89s/it] 12%|█▏        | 58/500 [23:15<2:56:13, 23.92s/it] 12%|█▏        | 59/500 [23:39<2:56:05, 23.96s/it] 12%|█▏        | 60/500 [24:02<2:55:12, 23.89s/it] 12%|█▏        | 61/500 [24:26<2:54:36, 23.87s/it] 12%|█▏        | 61/500 [24:26<2:55:56, 24.05s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.316 MB uploadedwandb: - 0.010 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▄▆▇▇▇▇▇▇████████████████▇█▇███████████
wandb:     train_loss ▆▇▇▅▃▂▆▅▅▃▃▁▃▁▂▆▁▂▃█▃▂▂▃▂▁▂▄▆▁▂▃▁▃▂▂▁▁▂▃
wandb:   val_accuracy ▁▄▄█▇▆▆▇▇▇▆▆▇▇▇▆▇▇▇▇▇▇▆▇▇▇██▇██████████▇
wandb:       val_loss ▅▅▄▄▃▂▄▃▅▆▁▄▄▂▂▁▆▂▂▁▄▅▁▄▄▃█▅▅▁▁▁▂▁▃▁▇▂▅▁
wandb: 
wandb: Run summary:
wandb:          epoch 60
wandb:  learning_rate 0.0
wandb: train_accuracy 0.9153
wandb:     train_loss 0.31156
wandb:   val_accuracy 0.68222
wandb:       val_loss 0.16088
wandb: 
wandb: 🚀 View run classic-valley-32 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x6h7er5v
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_220850-x6h7er5v/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_223400-c4iin8yc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-puddle-33
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/c4iin8yc
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:34:10, 25.75s/it]  0%|          | 2/500 [00:50<3:29:04, 25.19s/it]  1%|          | 3/500 [01:14<3:25:18, 24.79s/it]  1%|          | 4/500 [01:39<3:23:15, 24.59s/it]  1%|          | 5/500 [02:03<3:22:00, 24.49s/it]  1%|          | 6/500 [02:28<3:21:52, 24.52s/it]  1%|▏         | 7/500 [02:52<3:20:42, 24.43s/it]  2%|▏         | 8/500 [03:16<3:20:10, 24.41s/it]  2%|▏         | 9/500 [03:41<3:20:07, 24.46s/it]  2%|▏         | 10/500 [04:05<3:19:40, 24.45s/it]  2%|▏         | 11/500 [04:30<3:21:21, 24.71s/it]  2%|▏         | 12/500 [04:55<3:21:03, 24.72s/it]  3%|▎         | 13/500 [05:20<3:20:27, 24.70s/it]  3%|▎         | 14/500 [05:44<3:19:20, 24.61s/it]  3%|▎         | 15/500 [06:09<3:18:26, 24.55s/it]  3%|▎         | 16/500 [06:33<3:17:04, 24.43s/it]  3%|▎         | 17/500 [06:57<3:15:53, 24.33s/it]  4%|▎         | 18/500 [07:21<3:15:23, 24.32s/it]  4%|▍         | 19/500 [07:46<3:15:05, 24.34s/it]  4%|▍         | 20/500 [08:10<3:14:54, 24.36s/it]  4%|▍         | 21/500 [08:35<3:16:10, 24.57s/it]  4%|▍         | 22/500 [08:59<3:15:01, 24.48s/it]  5%|▍         | 23/500 [09:24<3:14:25, 24.46s/it]  5%|▍         | 24/500 [09:48<3:13:33, 24.40s/it]  5%|▌         | 25/500 [10:13<3:13:28, 24.44s/it]  5%|▌         | 26/500 [10:37<3:12:08, 24.32s/it]  5%|▌         | 27/500 [11:01<3:11:32, 24.30s/it]  6%|▌         | 28/500 [11:25<3:11:36, 24.36s/it]  6%|▌         | 29/500 [11:50<3:11:06, 24.34s/it]  6%|▌         | 30/500 [12:14<3:11:18, 24.42s/it]  6%|▌         | 31/500 [12:39<3:11:10, 24.46s/it]  6%|▋         | 32/500 [13:03<3:10:07, 24.37s/it]  7%|▋         | 33/500 [13:27<3:09:45, 24.38s/it]  7%|▋         | 34/500 [13:52<3:10:31, 24.53s/it]  7%|▋         | 35/500 [14:17<3:09:53, 24.50s/it]  7%|▋         | 36/500 [14:41<3:08:41, 24.40s/it]  7%|▋         | 37/500 [15:05<3:08:51, 24.47s/it]  8%|▊         | 38/500 [15:29<3:07:23, 24.34s/it]  8%|▊         | 39/500 [15:54<3:07:11, 24.36s/it]  8%|▊         | 40/500 [16:18<3:06:14, 24.29s/it]  8%|▊         | 41/500 [16:42<3:04:56, 24.17s/it]  8%|▊         | 42/500 [17:06<3:04:45, 24.20s/it]  9%|▊         | 43/500 [17:31<3:04:48, 24.26s/it]  9%|▉         | 44/500 [17:55<3:04:47, 24.31s/it]  9%|▉         | 45/500 [18:19<3:04:06, 24.28s/it]  9%|▉         | 46/500 [18:44<3:04:21, 24.37s/it]  9%|▉         | 47/500 [19:09<3:06:28, 24.70s/it] 10%|▉         | 48/500 [19:33<3:04:45, 24.53s/it] 10%|▉         | 49/500 [19:58<3:03:35, 24.42s/it] 10%|█         | 50/500 [20:22<3:02:30, 24.33s/it] 10%|█         | 51/500 [20:46<3:02:01, 24.32s/it] 10%|█         | 52/500 [21:10<3:01:42, 24.34s/it] 11%|█         | 53/500 [21:35<3:01:14, 24.33s/it] 11%|█         | 54/500 [21:59<3:00:54, 24.34s/it] 11%|█         | 55/500 [22:23<3:00:25, 24.33s/it] 11%|█         | 56/500 [22:47<2:59:25, 24.25s/it] 11%|█▏        | 57/500 [23:12<2:58:54, 24.23s/it] 12%|█▏        | 58/500 [23:36<2:58:27, 24.22s/it] 12%|█▏        | 59/500 [24:00<2:58:08, 24.24s/it] 12%|█▏        | 60/500 [24:24<2:57:58, 24.27s/it] 12%|█▏        | 61/500 [24:49<2:57:15, 24.23s/it] 12%|█▏        | 61/500 [24:49<2:58:36, 24.41s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.315 MB uploadedwandb: \ 0.019 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▄▃▂▅▂▇█▇▅▆████████████████████████████
wandb:     train_loss ▃▂▂▂▂▃▃▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▄▂▂▂▄▄▆▇▄▃▅▇▇▆▇▅▆▇▇▇▅▇█▇▇▇█▇██▇▇█▇▇█▇▇▆
wandb:       val_loss ▂▂▂▂▄▁▅▁▃▆▁▅▂▁▁▁█▂▁▄▂▂▁▁▁▃▁▁▁▁▁▁▁▁▂▁▃▂▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 60
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.99703
wandb:     train_loss 0.00117
wandb:   val_accuracy 0.70667
wandb:       val_loss 0.00119
wandb: 
wandb: 🚀 View run deft-puddle-33 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/c4iin8yc
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_223400-c4iin8yc/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_225931-u3ykkok2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-monkey-34
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/u3ykkok2
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:33:09, 25.63s/it]  0%|          | 2/500 [00:49<3:24:55, 24.69s/it]  1%|          | 3/500 [01:13<3:20:22, 24.19s/it]  1%|          | 4/500 [01:37<3:19:01, 24.07s/it]  1%|          | 5/500 [02:02<3:21:55, 24.48s/it]  1%|          | 6/500 [02:26<3:21:38, 24.49s/it]  1%|▏         | 7/500 [02:51<3:21:22, 24.51s/it]  2%|▏         | 8/500 [03:15<3:18:55, 24.26s/it]  2%|▏         | 9/500 [03:38<3:17:06, 24.09s/it]  2%|▏         | 10/500 [04:02<3:15:23, 23.93s/it]  2%|▏         | 11/500 [04:25<3:13:57, 23.80s/it]  2%|▏         | 12/500 [04:49<3:12:54, 23.72s/it]  3%|▎         | 13/500 [05:13<3:13:29, 23.84s/it]  3%|▎         | 14/500 [05:38<3:14:51, 24.06s/it]  3%|▎         | 15/500 [06:01<3:13:47, 23.98s/it]  3%|▎         | 16/500 [06:25<3:12:31, 23.87s/it]  3%|▎         | 17/500 [06:49<3:11:31, 23.79s/it]  4%|▎         | 18/500 [07:13<3:11:46, 23.87s/it]  4%|▍         | 19/500 [07:36<3:10:57, 23.82s/it]  4%|▍         | 20/500 [08:01<3:11:47, 23.97s/it]  4%|▍         | 21/500 [08:25<3:11:21, 23.97s/it]  4%|▍         | 22/500 [08:48<3:10:19, 23.89s/it]  5%|▍         | 23/500 [09:12<3:09:13, 23.80s/it]  5%|▍         | 24/500 [09:36<3:08:30, 23.76s/it]  5%|▌         | 25/500 [10:05<3:21:22, 25.44s/it]  5%|▌         | 26/500 [10:29<3:17:22, 24.98s/it]  5%|▌         | 27/500 [10:53<3:13:45, 24.58s/it]  6%|▌         | 28/500 [11:16<3:10:37, 24.23s/it]  6%|▌         | 28/500 [11:16<3:10:04, 24.16s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.306 MB uploadedwandb: \ 0.010 MB of 0.306 MB uploadedwandb: | 0.306 MB of 0.306 MB uploadedwandb: / 0.306 MB of 0.306 MB uploadedwandb: - 0.306 MB of 0.306 MB uploadedwandb: \ 0.306 MB of 0.306 MB uploadedwandb: | 0.306 MB of 0.306 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▃▅▂▇▇██▃▆▅██▂██▇█▆▇██▇█▇██
wandb:     train_loss ▃▃▃▇▁▂▁▁▁▃▅█▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁
wandb:   val_accuracy ▂▁▂▄▁█▇██▃▇▄▇▇▅▇▅▇▇▇█▆▇▇▇▆█▇
wandb:       val_loss ▂▂▂▃▆▁▁▂▁▇▁▁▃▃▂▁█▃▁▂▂▁▁▁▄▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 27
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.99406
wandb:     train_loss 0.00653
wandb:   val_accuracy 0.68889
wandb:       val_loss 0.62222
wandb: 
wandb: 🚀 View run autumn-monkey-34 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/u3ykkok2
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_225931-u3ykkok2/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_231124-6i5rox4k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-galaxy-35
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6i5rox4k
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:34:50, 25.83s/it]  0%|          | 2/500 [00:49<3:25:49, 24.80s/it]  1%|          | 3/500 [01:14<3:22:58, 24.50s/it]  1%|          | 4/500 [01:38<3:22:12, 24.46s/it]  1%|          | 5/500 [02:02<3:21:26, 24.42s/it]  1%|          | 6/500 [02:26<3:19:47, 24.27s/it]  1%|▏         | 7/500 [02:50<3:18:49, 24.20s/it]  2%|▏         | 8/500 [03:14<3:17:55, 24.14s/it]  2%|▏         | 9/500 [03:38<3:17:10, 24.10s/it]  2%|▏         | 10/500 [04:02<3:16:29, 24.06s/it]  2%|▏         | 11/500 [04:27<3:17:14, 24.20s/it]  2%|▏         | 12/500 [04:51<3:17:18, 24.26s/it]  3%|▎         | 13/500 [05:15<3:16:28, 24.21s/it]  3%|▎         | 14/500 [05:39<3:15:12, 24.10s/it]  3%|▎         | 15/500 [06:03<3:14:37, 24.08s/it]  3%|▎         | 16/500 [06:27<3:14:27, 24.11s/it]  3%|▎         | 17/500 [06:52<3:15:31, 24.29s/it]  4%|▎         | 18/500 [07:16<3:14:26, 24.20s/it]  4%|▍         | 19/500 [07:41<3:14:33, 24.27s/it]  4%|▍         | 20/500 [08:05<3:13:39, 24.21s/it]  4%|▍         | 21/500 [08:29<3:13:36, 24.25s/it]  4%|▍         | 22/500 [08:53<3:13:17, 24.26s/it]  5%|▍         | 23/500 [09:17<3:12:33, 24.22s/it]  5%|▍         | 24/500 [09:41<3:11:23, 24.12s/it]  5%|▌         | 25/500 [10:05<3:10:49, 24.10s/it]  5%|▌         | 26/500 [10:29<3:09:52, 24.04s/it]  5%|▌         | 27/500 [10:53<3:08:40, 23.93s/it]  6%|▌         | 28/500 [11:17<3:08:00, 23.90s/it]  6%|▌         | 29/500 [11:40<3:07:10, 23.84s/it]  6%|▌         | 30/500 [12:04<3:06:23, 23.80s/it]  6%|▌         | 31/500 [12:28<3:05:47, 23.77s/it]  6%|▋         | 32/500 [12:51<3:05:14, 23.75s/it]  6%|▋         | 32/500 [12:51<3:08:10, 24.12s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.021 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▂▄▃▄▆▇▇▇▇▇██████▂▁▁▁▁▁▂▂▂▂▂▃▃▃▂▃
wandb:     train_loss ▃▄▄▄▄▄▂▂▂▂▂▃▁▂▁▁██▂▆▆▁▃▃▁▄▁▃▅▃▄▂
wandb:   val_accuracy ▄▄▄▆█▇▇▇▆▅▇▆▆▆▇▆▄▂▁▂▂▂▂▂▂▂▂▂▃▂▂▂
wandb:       val_loss ▄▄▃▃▃▃▃▂▂▃▂▃▃▃▂▁▄█▅▇▅▄▆▄▅▇▅▅▃▄▃▆
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.42496
wandb:     train_loss 0.38491
wandb:   val_accuracy 0.23333
wandb:       val_loss 1.95394
wandb: 
wandb: 🚀 View run good-galaxy-35 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6i5rox4k
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_231124-6i5rox4k/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_232501-q6cuuhp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-meadow-36
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q6cuuhp6
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:33:51, 25.71s/it]  0%|          | 2/500 [00:49<3:24:54, 24.69s/it]  1%|          | 3/500 [01:14<3:23:06, 24.52s/it]  1%|          | 4/500 [01:38<3:22:07, 24.45s/it]  1%|          | 5/500 [02:02<3:21:55, 24.48s/it]  1%|          | 6/500 [02:26<3:20:04, 24.30s/it]  1%|▏         | 7/500 [02:50<3:19:16, 24.25s/it]  2%|▏         | 8/500 [03:15<3:18:29, 24.21s/it]  2%|▏         | 9/500 [03:39<3:18:03, 24.20s/it]  2%|▏         | 10/500 [04:03<3:16:46, 24.10s/it]  2%|▏         | 11/500 [04:27<3:16:15, 24.08s/it]  2%|▏         | 12/500 [04:51<3:15:43, 24.06s/it]  3%|▎         | 13/500 [05:15<3:16:42, 24.23s/it]  3%|▎         | 14/500 [05:40<3:16:10, 24.22s/it]  3%|▎         | 15/500 [06:03<3:14:46, 24.10s/it]  3%|▎         | 16/500 [06:28<3:15:02, 24.18s/it]  3%|▎         | 17/500 [06:52<3:15:02, 24.23s/it]  4%|▎         | 18/500 [07:17<3:15:29, 24.33s/it]  4%|▍         | 19/500 [07:41<3:14:59, 24.32s/it]  4%|▍         | 20/500 [08:05<3:15:04, 24.39s/it]  4%|▍         | 21/500 [08:30<3:15:46, 24.52s/it]  4%|▍         | 22/500 [08:55<3:14:43, 24.44s/it]  5%|▍         | 23/500 [09:19<3:13:23, 24.33s/it]  5%|▍         | 24/500 [09:43<3:12:20, 24.24s/it]  5%|▌         | 25/500 [10:07<3:11:43, 24.22s/it]  5%|▌         | 26/500 [10:31<3:11:09, 24.20s/it]  5%|▌         | 27/500 [10:55<3:10:45, 24.20s/it]  6%|▌         | 28/500 [11:20<3:11:05, 24.29s/it]  6%|▌         | 29/500 [11:44<3:10:25, 24.26s/it]  6%|▌         | 30/500 [12:08<3:10:41, 24.34s/it]  6%|▌         | 31/500 [12:32<3:09:38, 24.26s/it]  6%|▋         | 32/500 [12:57<3:08:49, 24.21s/it]  7%|▋         | 33/500 [13:21<3:08:14, 24.19s/it]  7%|▋         | 34/500 [13:45<3:08:11, 24.23s/it]  7%|▋         | 35/500 [14:09<3:07:16, 24.17s/it]  7%|▋         | 36/500 [14:34<3:08:06, 24.32s/it]  7%|▋         | 37/500 [14:58<3:07:11, 24.26s/it]  8%|▊         | 38/500 [15:22<3:06:50, 24.27s/it]  8%|▊         | 39/500 [15:46<3:06:06, 24.22s/it]  8%|▊         | 40/500 [16:11<3:06:39, 24.35s/it]  8%|▊         | 41/500 [16:35<3:06:05, 24.33s/it]  8%|▊         | 42/500 [16:59<3:05:34, 24.31s/it]  9%|▊         | 43/500 [17:24<3:05:14, 24.32s/it]  9%|▉         | 44/500 [17:48<3:04:42, 24.30s/it]  9%|▉         | 44/500 [17:48<3:04:33, 24.28s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.019 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▂▅▁▆▇▆▇▇▇▇▇██▇▇██████████████████████
wandb:     train_loss ▂▁▂▄▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▃▂▅▂▆▇▆▇▇▇▇▅▇▇█▆▇▇▇▇▇▇▇▇▇▇▆▆▆▆▇▇▆▆▇▆▇▆
wandb:       val_loss ▃▄▂▃▂▄▁▁▁▃▁▃▃▂▁▅▂▃▁▁▁▁▆▃▃▁█▅▅▁▂▇▁▃▁▂▅▃▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 43
wandb:  learning_rate 3e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.00037
wandb:   val_accuracy 0.74444
wandb:       val_loss 0.12663
wandb: 
wandb: 🚀 View run amber-meadow-36 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q6cuuhp6
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_232501-q6cuuhp6/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240917_234335-1l6u5qdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-monkey-37
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1l6u5qdk
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:43:52, 26.92s/it]  0%|          | 2/500 [00:51<3:30:16, 25.34s/it]  1%|          | 3/500 [01:14<3:24:11, 24.65s/it]  1%|          | 4/500 [01:38<3:20:42, 24.28s/it]  1%|          | 5/500 [02:02<3:19:55, 24.23s/it]  1%|          | 6/500 [02:26<3:17:25, 23.98s/it]  1%|▏         | 7/500 [02:49<3:15:53, 23.84s/it]  2%|▏         | 8/500 [03:13<3:15:16, 23.81s/it]  2%|▏         | 9/500 [03:37<3:14:48, 23.80s/it]  2%|▏         | 10/500 [04:02<3:16:29, 24.06s/it]  2%|▏         | 11/500 [04:25<3:15:26, 23.98s/it]  2%|▏         | 12/500 [04:49<3:13:29, 23.79s/it]  3%|▎         | 13/500 [05:17<3:23:23, 25.06s/it]  3%|▎         | 14/500 [05:40<3:19:22, 24.61s/it]  3%|▎         | 15/500 [06:04<3:16:22, 24.29s/it]  3%|▎         | 16/500 [06:28<3:14:57, 24.17s/it]  3%|▎         | 17/500 [06:53<3:16:40, 24.43s/it]  4%|▎         | 18/500 [07:17<3:15:28, 24.33s/it]  4%|▍         | 19/500 [07:40<3:13:02, 24.08s/it]  4%|▍         | 20/500 [08:04<3:11:02, 23.88s/it]  4%|▍         | 21/500 [08:28<3:11:14, 23.96s/it]  4%|▍         | 22/500 [08:52<3:10:03, 23.86s/it]  5%|▍         | 23/500 [09:15<3:09:06, 23.79s/it]  5%|▍         | 24/500 [09:39<3:08:03, 23.71s/it]  5%|▌         | 25/500 [10:02<3:07:55, 23.74s/it]  5%|▌         | 26/500 [10:26<3:07:23, 23.72s/it]  5%|▌         | 27/500 [10:50<3:07:00, 23.72s/it]  6%|▌         | 28/500 [11:14<3:06:36, 23.72s/it]  6%|▌         | 29/500 [11:37<3:05:51, 23.68s/it]  6%|▌         | 30/500 [12:01<3:05:15, 23.65s/it]  6%|▌         | 31/500 [12:24<3:04:51, 23.65s/it]  6%|▋         | 32/500 [12:48<3:04:04, 23.60s/it]  7%|▋         | 33/500 [13:11<3:03:07, 23.53s/it]  7%|▋         | 34/500 [13:35<3:02:51, 23.54s/it]  7%|▋         | 35/500 [13:59<3:03:05, 23.62s/it]  7%|▋         | 36/500 [14:22<3:02:32, 23.60s/it]  7%|▋         | 37/500 [14:46<3:01:26, 23.51s/it]  8%|▊         | 38/500 [15:09<3:00:43, 23.47s/it]  8%|▊         | 39/500 [15:32<3:00:08, 23.44s/it]  8%|▊         | 40/500 [15:56<3:00:40, 23.57s/it]  8%|▊         | 41/500 [16:20<3:00:13, 23.56s/it]  8%|▊         | 42/500 [16:43<3:00:12, 23.61s/it]  9%|▊         | 43/500 [17:07<2:59:46, 23.60s/it]  9%|▊         | 43/500 [17:07<3:02:00, 23.90s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.313 MB uploadedwandb: - 0.010 MB of 0.313 MB uploadedwandb: \ 0.232 MB of 0.313 MB uploadedwandb: | 0.232 MB of 0.313 MB uploadedwandb: / 0.232 MB of 0.313 MB uploadedwandb: - 0.232 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▁▅▁▁▁▄▅▃█▆▃▇█▆█▇█████████████████████
wandb:     train_loss ▃▁▃▆▃█▁█▁▁▃▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▅▂█▃▃▃▅▅▅█▇▅█▇▆▇▇█▇▇▇▇█▇▇▇▇▆▆▇▆▇▇▇▆▇▇▆
wandb:       val_loss ▂▂▂▃▁▂▃▁▂▂▃▁▁▃▁▃█▆▁▁▁▁▁▁▁▁▁▂▁▂▁▁▁▁▂▁▁▂▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 42
wandb:  learning_rate 6e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.00031
wandb:   val_accuracy 0.75111
wandb:       val_loss 0.00011
wandb: 
wandb: 🚀 View run autumn-monkey-37 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1l6u5qdk
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240917_234335-1l6u5qdk/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_000128-6wv5p20v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-brook-38
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6wv5p20v
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:35:41, 25.93s/it]  0%|          | 2/500 [00:50<3:28:41, 25.14s/it]  1%|          | 3/500 [01:15<3:28:44, 25.20s/it]  1%|          | 4/500 [01:40<3:27:44, 25.13s/it]  1%|          | 5/500 [02:05<3:25:22, 24.89s/it]  1%|          | 6/500 [02:29<3:24:09, 24.80s/it]  1%|▏         | 7/500 [02:54<3:23:33, 24.77s/it]  2%|▏         | 8/500 [03:19<3:22:57, 24.75s/it]  2%|▏         | 9/500 [03:44<3:23:01, 24.81s/it]  2%|▏         | 10/500 [04:08<3:21:59, 24.73s/it]  2%|▏         | 11/500 [04:33<3:20:31, 24.60s/it]  2%|▏         | 12/500 [04:57<3:19:08, 24.48s/it]  3%|▎         | 13/500 [05:21<3:18:37, 24.47s/it]  3%|▎         | 14/500 [05:46<3:17:37, 24.40s/it]  3%|▎         | 15/500 [06:10<3:17:31, 24.44s/it]  3%|▎         | 16/500 [06:35<3:17:27, 24.48s/it]  3%|▎         | 17/500 [06:59<3:16:58, 24.47s/it]  4%|▎         | 18/500 [07:24<3:17:17, 24.56s/it]  4%|▍         | 19/500 [07:48<3:16:42, 24.54s/it]  4%|▍         | 20/500 [08:13<3:15:58, 24.50s/it]  4%|▍         | 21/500 [08:38<3:16:16, 24.59s/it]  4%|▍         | 22/500 [09:02<3:15:41, 24.56s/it]  5%|▍         | 23/500 [09:26<3:14:18, 24.44s/it]  5%|▍         | 24/500 [09:51<3:14:10, 24.47s/it]  5%|▌         | 25/500 [10:15<3:13:37, 24.46s/it]  5%|▌         | 26/500 [10:39<3:10:40, 24.14s/it]  5%|▌         | 27/500 [11:03<3:11:16, 24.26s/it]  6%|▌         | 28/500 [11:28<3:12:08, 24.42s/it]  6%|▌         | 29/500 [11:53<3:13:05, 24.60s/it]  6%|▌         | 30/500 [12:17<3:11:25, 24.44s/it]  6%|▌         | 31/500 [12:44<3:16:40, 25.16s/it]  6%|▋         | 32/500 [13:08<3:14:11, 24.90s/it]  6%|▋         | 32/500 [13:08<3:12:13, 24.64s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.130 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▁▁▂▁▂▂▂▅▆▇▇▇▇▇▇▇████████████████
wandb:     train_loss ▄▅▅▇▄▅▃▄▃▃▄▂▃▂▂▃▁▂▃▁▁▂▂▃▁▃▁▂▁▅█▂
wandb:   val_accuracy ▂▂▁▁▁▁▁▆███████▅▇██▇████▇██▇████
wandb:       val_loss ▅▆▅▄▅▇▅▄▄▄▄▆▆▆▂▁▆▄▆▇▂▂▂▂█▄▂▂▅▂▄▂
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.89896
wandb:     train_loss 0.25999
wandb:   val_accuracy 0.64222
wandb:       val_loss 0.3644
wandb: 
wandb: 🚀 View run spring-brook-38 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6wv5p20v
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_000128-6wv5p20v/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_001521-6ch0icb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-haze-39
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6ch0icb0
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:30<4:12:45, 30.39s/it]  0%|          | 2/500 [00:54<3:43:05, 26.88s/it]  1%|          | 3/500 [01:18<3:32:15, 25.62s/it]  1%|          | 4/500 [01:42<3:26:22, 24.96s/it]  1%|          | 5/500 [02:07<3:23:25, 24.66s/it]  1%|          | 6/500 [02:35<3:33:41, 25.96s/it]  1%|▏         | 7/500 [02:59<3:28:17, 25.35s/it]  2%|▏         | 8/500 [03:23<3:23:21, 24.80s/it]  2%|▏         | 9/500 [03:47<3:21:14, 24.59s/it]  2%|▏         | 10/500 [04:11<3:18:58, 24.36s/it]  2%|▏         | 11/500 [04:35<3:17:19, 24.21s/it]  2%|▏         | 12/500 [04:58<3:15:56, 24.09s/it]  3%|▎         | 13/500 [05:22<3:14:46, 24.00s/it]  3%|▎         | 14/500 [05:46<3:14:01, 23.95s/it]  3%|▎         | 15/500 [06:10<3:12:54, 23.86s/it]  3%|▎         | 16/500 [06:34<3:13:07, 23.94s/it]  3%|▎         | 17/500 [06:58<3:12:40, 23.93s/it]  4%|▎         | 18/500 [07:21<3:11:25, 23.83s/it]  4%|▍         | 19/500 [07:46<3:12:17, 23.99s/it]  4%|▍         | 20/500 [08:09<3:11:33, 23.94s/it]  4%|▍         | 21/500 [08:34<3:11:45, 24.02s/it]  4%|▍         | 22/500 [08:57<3:10:16, 23.88s/it]  5%|▍         | 23/500 [09:21<3:09:50, 23.88s/it]  5%|▍         | 24/500 [09:45<3:09:51, 23.93s/it]  5%|▌         | 25/500 [10:09<3:09:06, 23.89s/it]  5%|▌         | 26/500 [10:33<3:08:29, 23.86s/it]  5%|▌         | 27/500 [10:57<3:07:54, 23.84s/it]  6%|▌         | 28/500 [11:20<3:07:35, 23.85s/it]  6%|▌         | 29/500 [11:44<3:07:26, 23.88s/it]  6%|▌         | 30/500 [12:08<3:06:43, 23.84s/it]  6%|▌         | 31/500 [12:32<3:05:50, 23.78s/it]  6%|▋         | 32/500 [12:56<3:05:27, 23.78s/it]  7%|▋         | 33/500 [13:19<3:05:02, 23.78s/it]  7%|▋         | 34/500 [13:43<3:05:16, 23.85s/it]  7%|▋         | 35/500 [14:07<3:05:13, 23.90s/it]  7%|▋         | 36/500 [14:31<3:04:50, 23.90s/it]  7%|▋         | 37/500 [14:55<3:04:24, 23.90s/it]  8%|▊         | 38/500 [15:19<3:04:18, 23.94s/it]  8%|▊         | 39/500 [15:43<3:03:30, 23.88s/it]  8%|▊         | 40/500 [16:07<3:02:39, 23.82s/it]  8%|▊         | 41/500 [16:30<3:02:21, 23.84s/it]  8%|▊         | 42/500 [16:54<3:01:57, 23.84s/it]  9%|▊         | 43/500 [17:18<3:01:26, 23.82s/it]  9%|▉         | 44/500 [17:43<3:03:57, 24.20s/it]  9%|▉         | 45/500 [18:08<3:04:57, 24.39s/it]  9%|▉         | 46/500 [18:32<3:03:47, 24.29s/it]  9%|▉         | 47/500 [18:56<3:02:43, 24.20s/it] 10%|▉         | 48/500 [19:21<3:04:09, 24.45s/it] 10%|▉         | 49/500 [19:45<3:03:23, 24.40s/it] 10%|█         | 50/500 [20:09<3:02:18, 24.31s/it] 10%|█         | 51/500 [20:33<3:01:01, 24.19s/it] 10%|█         | 52/500 [20:57<2:59:49, 24.08s/it] 11%|█         | 53/500 [21:21<2:59:08, 24.05s/it] 11%|█         | 54/500 [21:45<2:58:30, 24.01s/it] 11%|█         | 55/500 [22:09<2:57:54, 23.99s/it] 11%|█         | 56/500 [22:33<2:57:33, 23.99s/it] 11%|█▏        | 57/500 [22:57<2:56:52, 23.96s/it] 12%|█▏        | 58/500 [23:21<2:56:53, 24.01s/it] 12%|█▏        | 59/500 [23:45<2:56:30, 24.01s/it] 12%|█▏        | 60/500 [24:09<2:56:27, 24.06s/it] 12%|█▏        | 61/500 [24:33<2:55:41, 24.01s/it] 12%|█▏        | 62/500 [24:57<2:55:42, 24.07s/it] 12%|█▏        | 62/500 [24:57<2:56:21, 24.16s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.019 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▂▂▃▅▂▇█▇▅▇████████████████████████████
wandb:     train_loss █▄▆▇▄▇▇▁▄▁▂▁▁▁▂▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▂▃▁▁▄▄▃▆▆▆▅▆▇▆▆▆▆▇█▇▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▆▇▆▆▇
wandb:       val_loss ▃▂▃▃▄▂█▅▂▄▁▃▁▁▁▁▁▂▃▂▂▂▄▁▁▄▃▁▂▁▁▄▁▁▁▅▃▄▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 61
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.98366
wandb:     train_loss 0.02655
wandb:   val_accuracy 0.66444
wandb:       val_loss 0.04086
wandb: 
wandb: 🚀 View run amber-haze-39 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6ch0icb0
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_001521-6ch0icb0/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_004058-midado89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-wave-40
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/midado89
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:37:31, 26.16s/it]  0%|          | 2/500 [00:49<3:21:54, 24.33s/it]  1%|          | 3/500 [01:13<3:19:42, 24.11s/it]  1%|          | 4/500 [01:36<3:16:36, 23.78s/it]  1%|          | 5/500 [01:59<3:15:45, 23.73s/it]  1%|          | 6/500 [02:24<3:16:38, 23.88s/it]  1%|▏         | 7/500 [02:47<3:14:38, 23.69s/it]  2%|▏         | 8/500 [03:10<3:13:34, 23.61s/it]  2%|▏         | 9/500 [03:34<3:13:04, 23.59s/it]  2%|▏         | 10/500 [03:57<3:11:30, 23.45s/it]  2%|▏         | 11/500 [04:20<3:10:35, 23.39s/it]  2%|▏         | 12/500 [04:43<3:09:28, 23.30s/it]  3%|▎         | 13/500 [05:07<3:09:01, 23.29s/it]  3%|▎         | 14/500 [05:30<3:08:38, 23.29s/it]  3%|▎         | 15/500 [05:53<3:07:54, 23.25s/it]  3%|▎         | 16/500 [06:16<3:07:22, 23.23s/it]  3%|▎         | 17/500 [06:39<3:06:40, 23.19s/it]  4%|▎         | 18/500 [07:03<3:06:40, 23.24s/it]  4%|▍         | 19/500 [07:26<3:06:40, 23.29s/it]  4%|▍         | 20/500 [07:50<3:07:07, 23.39s/it]  4%|▍         | 21/500 [08:13<3:06:55, 23.41s/it]  4%|▍         | 22/500 [08:36<3:05:55, 23.34s/it]  5%|▍         | 23/500 [09:00<3:06:50, 23.50s/it]  5%|▍         | 24/500 [09:24<3:06:15, 23.48s/it]  5%|▌         | 25/500 [09:47<3:04:45, 23.34s/it]  5%|▌         | 26/500 [10:10<3:03:44, 23.26s/it]  5%|▌         | 27/500 [10:33<3:02:42, 23.18s/it]  6%|▌         | 28/500 [10:56<3:02:41, 23.22s/it]  6%|▌         | 29/500 [11:19<3:01:57, 23.18s/it]  6%|▌         | 30/500 [11:42<3:01:22, 23.15s/it]  6%|▌         | 31/500 [12:05<3:00:38, 23.11s/it]  6%|▋         | 32/500 [12:28<2:59:08, 22.97s/it]  7%|▋         | 33/500 [12:51<2:58:13, 22.90s/it]  7%|▋         | 34/500 [13:14<2:58:58, 23.04s/it]  7%|▋         | 35/500 [13:37<2:59:13, 23.13s/it]  7%|▋         | 36/500 [14:01<3:00:05, 23.29s/it]  7%|▋         | 37/500 [14:24<2:59:14, 23.23s/it]  8%|▊         | 38/500 [14:47<2:59:13, 23.28s/it]  8%|▊         | 39/500 [15:11<2:58:29, 23.23s/it]  8%|▊         | 40/500 [15:34<2:58:10, 23.24s/it]  8%|▊         | 41/500 [15:57<2:57:48, 23.24s/it]  8%|▊         | 42/500 [16:20<2:57:20, 23.23s/it]  9%|▊         | 43/500 [16:44<2:57:35, 23.32s/it]  9%|▉         | 44/500 [17:07<2:56:42, 23.25s/it]  9%|▉         | 45/500 [17:30<2:56:24, 23.26s/it]  9%|▉         | 46/500 [17:53<2:55:43, 23.22s/it]  9%|▉         | 47/500 [18:17<2:55:31, 23.25s/it] 10%|▉         | 48/500 [18:40<2:55:35, 23.31s/it] 10%|▉         | 49/500 [19:03<2:54:40, 23.24s/it] 10%|█         | 50/500 [19:26<2:54:08, 23.22s/it] 10%|█         | 51/500 [19:50<2:53:39, 23.21s/it] 10%|█         | 52/500 [20:13<2:53:18, 23.21s/it] 11%|█         | 53/500 [20:36<2:53:10, 23.25s/it] 11%|█         | 54/500 [20:59<2:52:44, 23.24s/it] 11%|█         | 55/500 [21:23<2:52:49, 23.30s/it] 11%|█         | 56/500 [21:46<2:51:44, 23.21s/it] 11%|█▏        | 57/500 [22:09<2:50:49, 23.14s/it] 12%|█▏        | 58/500 [22:32<2:50:38, 23.16s/it] 12%|█▏        | 59/500 [22:55<2:50:22, 23.18s/it] 12%|█▏        | 59/500 [22:55<2:51:24, 23.32s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.310 MB uploadedwandb: \ 0.010 MB of 0.310 MB uploadedwandb: | 0.233 MB of 0.310 MB uploadedwandb: / 0.233 MB of 0.310 MB uploadedwandb: - 0.233 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▅▅▇▇▇▇▆▇▆▇▇▇▇██▇█▆▇███▆███▇█▆▇█▇▇███▇█
wandb:     train_loss █▆▃▅▁▂▁▂▄▁▁▁▁▁▁▁▄▁▂▁▁▂▃▁█▃▁▁▂▄▁▁▃▁▄▁▁▁▃▁
wandb:   val_accuracy ▂▁▅▃▆▇██▇██▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       val_loss ▃▄▂▂▂▅▁▃▁▃▁█▁▁▁▁▁▁▁▄▂▁▁▆▂▁▃▄▂▁▁▁▁▁▃▄▁▆▂▅
wandb: 
wandb: Run summary:
wandb:          epoch 58
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.99257
wandb:     train_loss 0.00071
wandb:   val_accuracy 0.70667
wandb:       val_loss 1.96107
wandb: 
wandb: 🚀 View run pretty-wave-40 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/midado89
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_004058-midado89/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_010444-uih0fffp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-deluge-41
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/uih0fffp
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:29:52, 25.24s/it]  0%|          | 2/500 [00:49<3:23:03, 24.46s/it]  1%|          | 3/500 [01:12<3:19:44, 24.11s/it]  1%|          | 4/500 [01:37<3:19:34, 24.14s/it]  1%|          | 5/500 [02:01<3:19:49, 24.22s/it]  1%|          | 6/500 [02:25<3:18:48, 24.15s/it]  1%|▏         | 7/500 [02:54<3:31:39, 25.76s/it]  2%|▏         | 8/500 [03:18<3:27:04, 25.25s/it]  2%|▏         | 9/500 [03:42<3:22:58, 24.80s/it]  2%|▏         | 10/500 [04:06<3:20:16, 24.52s/it]  2%|▏         | 11/500 [04:30<3:17:53, 24.28s/it]  2%|▏         | 12/500 [04:53<3:15:43, 24.06s/it]  3%|▎         | 13/500 [05:20<3:23:05, 25.02s/it]  3%|▎         | 14/500 [05:44<3:20:09, 24.71s/it]  3%|▎         | 15/500 [06:08<3:17:15, 24.40s/it]  3%|▎         | 16/500 [06:40<3:35:03, 26.66s/it]  3%|▎         | 17/500 [07:04<3:28:19, 25.88s/it]  4%|▎         | 18/500 [07:28<3:23:46, 25.37s/it]  4%|▍         | 19/500 [07:52<3:20:17, 24.98s/it]  4%|▍         | 20/500 [08:16<3:16:56, 24.62s/it]  4%|▍         | 21/500 [08:40<3:15:00, 24.43s/it]  4%|▍         | 22/500 [09:04<3:12:45, 24.20s/it]  5%|▍         | 23/500 [09:28<3:12:37, 24.23s/it]  5%|▍         | 24/500 [09:53<3:13:37, 24.41s/it]  5%|▌         | 25/500 [10:17<3:12:00, 24.25s/it]  5%|▌         | 26/500 [10:44<3:18:37, 25.14s/it]  5%|▌         | 27/500 [11:12<3:25:35, 26.08s/it]  6%|▌         | 28/500 [11:36<3:20:28, 25.48s/it]  6%|▌         | 29/500 [12:01<3:17:23, 25.14s/it]  6%|▌         | 30/500 [12:25<3:14:40, 24.85s/it]  6%|▌         | 31/500 [12:49<3:13:46, 24.79s/it]  6%|▋         | 32/500 [13:14<3:11:46, 24.59s/it]  7%|▋         | 33/500 [13:38<3:10:59, 24.54s/it]  7%|▋         | 34/500 [14:02<3:09:53, 24.45s/it]  7%|▋         | 35/500 [14:26<3:07:25, 24.18s/it]  7%|▋         | 36/500 [14:50<3:06:03, 24.06s/it]  7%|▋         | 37/500 [15:13<3:04:45, 23.94s/it]  8%|▊         | 38/500 [15:37<3:04:32, 23.97s/it]  8%|▊         | 39/500 [16:11<3:27:11, 26.97s/it]  8%|▊         | 40/500 [16:40<3:29:56, 27.38s/it]  8%|▊         | 41/500 [17:09<3:34:31, 28.04s/it]  8%|▊         | 42/500 [17:33<3:24:54, 26.84s/it]  9%|▊         | 43/500 [17:57<3:17:29, 25.93s/it]  9%|▉         | 44/500 [18:21<3:12:13, 25.29s/it]  9%|▉         | 45/500 [18:55<3:32:20, 28.00s/it]  9%|▉         | 46/500 [19:19<3:22:08, 26.72s/it]  9%|▉         | 47/500 [19:43<3:15:08, 25.85s/it] 10%|▉         | 48/500 [20:06<3:10:04, 25.23s/it] 10%|▉         | 49/500 [20:30<3:06:05, 24.76s/it] 10%|█         | 50/500 [20:59<3:14:03, 25.87s/it] 10%|█         | 51/500 [21:22<3:08:34, 25.20s/it] 10%|█         | 52/500 [21:50<3:14:52, 26.10s/it] 11%|█         | 53/500 [22:14<3:09:24, 25.42s/it] 11%|█         | 54/500 [22:42<3:14:13, 26.13s/it] 11%|█         | 55/500 [23:05<3:07:45, 25.32s/it] 11%|█         | 56/500 [23:34<3:14:18, 26.26s/it] 11%|█▏        | 57/500 [24:02<3:18:04, 26.83s/it] 12%|█▏        | 58/500 [24:31<3:22:00, 27.42s/it] 12%|█▏        | 59/500 [24:55<3:13:40, 26.35s/it] 12%|█▏        | 60/500 [25:18<3:07:25, 25.56s/it] 12%|█▏        | 61/500 [25:48<3:14:59, 26.65s/it] 12%|█▏        | 62/500 [26:11<3:07:56, 25.74s/it] 13%|█▎        | 63/500 [26:40<3:14:25, 26.70s/it] 13%|█▎        | 64/500 [27:09<3:18:58, 27.38s/it] 13%|█▎        | 65/500 [27:38<3:22:04, 27.87s/it] 13%|█▎        | 66/500 [28:08<3:25:09, 28.36s/it] 13%|█▎        | 67/500 [28:31<3:14:44, 26.99s/it] 14%|█▎        | 68/500 [28:55<3:07:06, 25.99s/it] 14%|█▍        | 69/500 [29:19<3:01:36, 25.28s/it] 14%|█▍        | 70/500 [29:42<2:57:33, 24.77s/it] 14%|█▍        | 71/500 [30:06<2:55:15, 24.51s/it] 14%|█▍        | 72/500 [30:30<2:52:54, 24.24s/it] 15%|█▍        | 73/500 [30:53<2:50:59, 24.03s/it] 15%|█▍        | 74/500 [31:17<2:49:32, 23.88s/it] 15%|█▌        | 75/500 [31:41<2:49:07, 23.88s/it] 15%|█▌        | 76/500 [32:04<2:48:10, 23.80s/it] 15%|█▌        | 77/500 [32:33<2:58:31, 25.32s/it] 15%|█▌        | 77/500 [32:38<2:59:20, 25.44s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.318 MB uploadedwandb: - 0.019 MB of 0.318 MB uploadedwandb: \ 0.314 MB of 0.318 MB uploadedwandb: | 0.314 MB of 0.318 MB uploadedwandb: / 0.314 MB of 0.318 MB uploadedwandb: - 0.314 MB of 0.318 MB uploadedwandb: \ 0.314 MB of 0.318 MB uploadedwandb: | 0.314 MB of 0.318 MB uploadedwandb: / 0.314 MB of 0.318 MB uploadedwandb: - 0.314 MB of 0.318 MB uploadedwandb: \ 0.314 MB of 0.318 MB uploadedwandb: | 0.314 MB of 0.318 MB uploadedwandb: / 0.314 MB of 0.318 MB uploadedwandb: - 0.314 MB of 0.318 MB uploadedwandb: \ 0.318 MB of 0.318 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▆▄▇▇▇▇▆▇▇▆█▆█▇▇▇▇▇█▇█████▇███████████
wandb:     train_loss ▆▇▇▆▆▅▆█▂▄▂▃▄▄▄█▁█▁▄▁▇▃▂▃▄▇▃▃▅▂▂▅▂▄▂▂▇▃▃
wandb:   val_accuracy ▁▂▁█▁▇▅▆▅▄▅▅▄█▄█▆▇▇▇██▇███▇█▇▇▇▇▇▇▇████▇
wandb:       val_loss ▆▆▅▇▅▄▆▅▃█▄▅▃▆▆▃▄▃▅▃▅▆▄▁▂▄▃▄▄▆▃▁▄▁▄▄▁▃▂▄
wandb: 
wandb: Run summary:
wandb:          epoch 76
wandb:  learning_rate 0.0
wandb: train_accuracy 0.81129
wandb:     train_loss 0.35908
wandb:   val_accuracy 0.62222
wandb:       val_loss 0.68327
wandb: 
wandb: 🚀 View run lilac-deluge-41 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/uih0fffp
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_010444-uih0fffp/logs
Successfully processed 1_20131027
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_013819-jn6dvbf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sound-42
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jn6dvbf7
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:28<3:56:08, 28.39s/it]  0%|          | 2/500 [00:51<3:31:13, 25.45s/it]  1%|          | 3/500 [01:14<3:22:07, 24.40s/it]  1%|          | 4/500 [01:37<3:17:05, 23.84s/it]  1%|          | 5/500 [02:05<3:26:35, 25.04s/it]  1%|          | 6/500 [02:33<3:34:33, 26.06s/it]  1%|▏         | 7/500 [02:56<3:26:22, 25.12s/it]  2%|▏         | 8/500 [03:24<3:35:17, 26.25s/it]  2%|▏         | 9/500 [03:47<3:26:15, 25.21s/it]  2%|▏         | 10/500 [04:18<3:39:53, 26.93s/it]  2%|▏         | 11/500 [04:41<3:29:40, 25.73s/it]  2%|▏         | 12/500 [05:04<3:22:05, 24.85s/it]  3%|▎         | 13/500 [05:27<3:16:31, 24.21s/it]  3%|▎         | 14/500 [05:50<3:12:52, 23.81s/it]  3%|▎         | 15/500 [06:18<3:22:45, 25.08s/it]  3%|▎         | 16/500 [06:46<3:30:05, 26.04s/it]  3%|▎         | 17/500 [07:09<3:22:53, 25.20s/it]  4%|▎         | 18/500 [07:40<3:35:24, 26.81s/it]  4%|▍         | 19/500 [08:08<3:39:13, 27.35s/it]  4%|▍         | 20/500 [08:31<3:28:36, 26.08s/it]  4%|▍         | 21/500 [09:00<3:34:58, 26.93s/it]  4%|▍         | 22/500 [09:23<3:25:19, 25.77s/it]  5%|▍         | 23/500 [09:52<3:30:46, 26.51s/it]  5%|▍         | 24/500 [10:16<3:23:53, 25.70s/it]  5%|▌         | 25/500 [10:39<3:17:36, 24.96s/it]  5%|▌         | 26/500 [11:02<3:13:39, 24.51s/it]  5%|▌         | 27/500 [11:29<3:19:46, 25.34s/it]  6%|▌         | 28/500 [11:58<3:26:16, 26.22s/it]  6%|▌         | 29/500 [12:25<3:29:05, 26.64s/it]  6%|▌         | 30/500 [12:48<3:19:31, 25.47s/it]  6%|▌         | 31/500 [13:11<3:13:20, 24.73s/it]  6%|▋         | 32/500 [13:39<3:20:51, 25.75s/it]  6%|▋         | 32/500 [13:39<3:19:48, 25.62s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▃▄▅▆▄▅▅▅▇▅▇▇█▇▇██▁▅▅▅▅▅▅▅▆▇▇████
wandb:     train_loss ▂▁▂▂▁▃▁▁▁▆▁▂▂▁▁▁▁█▁▄▄▁▁▂▁▂▁▃▂▂▂▁
wandb:   val_accuracy ▄▅▆▇▅▇▇▆█▇███▇█▇█▁▄▄▄▄▅▄▅▇▇▆▇▇▇▆
wandb:       val_loss ▂▂▁▁▂▁▁▁▁▄▃▂▁▂▁▁▂█▁▃▂▂▂▂▂▃▂▁▂▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.9049
wandb:     train_loss 0.41604
wandb:   val_accuracy 0.50222
wandb:       val_loss 0.57054
wandb: 
wandb: 🚀 View run vivid-sound-42 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jn6dvbf7
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_013819-jn6dvbf7/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_015243-d2swf8p8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run quiet-fog-43
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/d2swf8p8
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:10:52, 37.38s/it]  0%|          | 2/500 [01:00<4:02:33, 29.22s/it]  1%|          | 3/500 [01:29<3:59:57, 28.97s/it]  1%|          | 4/500 [01:52<3:41:08, 26.75s/it]  1%|          | 5/500 [02:22<3:47:59, 27.63s/it]  1%|          | 6/500 [02:46<3:37:42, 26.44s/it]  1%|▏         | 7/500 [03:15<3:45:03, 27.39s/it]  2%|▏         | 8/500 [03:39<3:34:23, 26.15s/it]  2%|▏         | 9/500 [04:02<3:27:10, 25.32s/it]  2%|▏         | 10/500 [04:26<3:22:51, 24.84s/it]  2%|▏         | 11/500 [04:50<3:21:30, 24.73s/it]  2%|▏         | 12/500 [05:14<3:18:19, 24.38s/it]  3%|▎         | 13/500 [05:38<3:16:38, 24.23s/it]  3%|▎         | 14/500 [06:02<3:16:19, 24.24s/it]  3%|▎         | 15/500 [06:26<3:14:59, 24.12s/it]  3%|▎         | 16/500 [06:50<3:14:47, 24.15s/it]  3%|▎         | 17/500 [07:14<3:13:00, 23.98s/it]  4%|▎         | 18/500 [07:38<3:14:25, 24.20s/it]  4%|▍         | 19/500 [08:02<3:13:21, 24.12s/it]  4%|▍         | 20/500 [08:27<3:14:45, 24.34s/it]  4%|▍         | 21/500 [08:51<3:13:49, 24.28s/it]  4%|▍         | 22/500 [09:15<3:12:49, 24.20s/it]  5%|▍         | 23/500 [09:39<3:11:57, 24.15s/it]  5%|▍         | 24/500 [10:14<3:35:25, 27.16s/it]  5%|▌         | 25/500 [10:38<3:28:04, 26.28s/it]  5%|▌         | 26/500 [11:02<3:22:33, 25.64s/it]  5%|▌         | 27/500 [11:32<3:33:39, 27.10s/it]  6%|▌         | 28/500 [11:57<3:28:08, 26.46s/it]  6%|▌         | 29/500 [12:22<3:22:56, 25.85s/it]  6%|▌         | 30/500 [12:47<3:20:06, 25.55s/it]  6%|▌         | 31/500 [13:13<3:20:44, 25.68s/it]  6%|▋         | 32/500 [13:37<3:18:05, 25.40s/it]  7%|▋         | 33/500 [14:02<3:16:25, 25.24s/it]  7%|▋         | 34/500 [14:27<3:14:40, 25.06s/it]  7%|▋         | 35/500 [14:50<3:10:24, 24.57s/it]  7%|▋         | 36/500 [15:15<3:09:39, 24.53s/it]  7%|▋         | 37/500 [15:39<3:08:18, 24.40s/it]  8%|▊         | 38/500 [16:03<3:06:50, 24.26s/it]  8%|▊         | 39/500 [16:27<3:05:24, 24.13s/it]  8%|▊         | 40/500 [16:50<3:03:53, 23.99s/it]  8%|▊         | 40/500 [16:50<3:13:46, 25.27s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.138 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▁▁▁▃▇▂▂▆▅▆▃▅▇█▆██▇██████▆▆▆█▇▇█▇█████
wandb:     train_loss ▂▁▂▂██▁▁▁▂▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▄▁▁▁▁▁
wandb:   val_accuracy ▁▂▁▂▁▁▅▆▅▂█████▇▇███████▇█▇▅██▇▆▆█▅▇█▇▆▇
wandb:       val_loss ▃▅▄▆▄▆▁▂▂▆▁▁▄▁▁▄█▁▁▁▁▁▁▁▃▁▁▁▃▂▂▁▂▂▄▁▁▁▅▆
wandb: 
wandb: Run summary:
wandb:          epoch 39
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.98068
wandb:     train_loss 0.00964
wandb:   val_accuracy 0.79111
wandb:       val_loss 2.85431
wandb: 
wandb: 🚀 View run quiet-fog-43 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/d2swf8p8
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_015243-d2swf8p8/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_021015-lqhrzzek
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-darkness-44
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lqhrzzek
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:29:23, 25.18s/it]  0%|          | 2/500 [00:49<3:22:29, 24.40s/it]  1%|          | 3/500 [01:13<3:23:22, 24.55s/it]  1%|          | 4/500 [01:38<3:22:21, 24.48s/it]  1%|          | 5/500 [02:02<3:20:13, 24.27s/it]  1%|          | 6/500 [02:27<3:21:48, 24.51s/it]  1%|▏         | 7/500 [02:51<3:21:40, 24.54s/it]  2%|▏         | 8/500 [03:15<3:19:45, 24.36s/it]  2%|▏         | 9/500 [03:39<3:18:26, 24.25s/it]  2%|▏         | 10/500 [04:02<3:15:35, 23.95s/it]  2%|▏         | 11/500 [04:33<3:32:19, 26.05s/it]  2%|▏         | 12/500 [04:57<3:27:29, 25.51s/it]  3%|▎         | 13/500 [05:21<3:23:07, 25.03s/it]  3%|▎         | 14/500 [05:46<3:20:57, 24.81s/it]  3%|▎         | 15/500 [06:09<3:18:00, 24.50s/it]  3%|▎         | 16/500 [06:34<3:17:50, 24.53s/it]  3%|▎         | 17/500 [06:58<3:16:00, 24.35s/it]  4%|▎         | 18/500 [07:22<3:14:14, 24.18s/it]  4%|▍         | 19/500 [07:46<3:13:16, 24.11s/it]  4%|▍         | 20/500 [08:10<3:14:15, 24.28s/it]  4%|▍         | 21/500 [08:35<3:15:15, 24.46s/it]  4%|▍         | 22/500 [08:59<3:13:29, 24.29s/it]  5%|▍         | 23/500 [09:23<3:12:07, 24.17s/it]  5%|▍         | 24/500 [09:47<3:11:44, 24.17s/it]  5%|▌         | 25/500 [10:11<3:11:31, 24.19s/it]  5%|▌         | 26/500 [10:35<3:10:01, 24.05s/it]  5%|▌         | 27/500 [10:59<3:08:59, 23.97s/it]  6%|▌         | 28/500 [11:28<3:21:09, 25.57s/it]  6%|▌         | 29/500 [11:53<3:19:11, 25.38s/it]  6%|▌         | 30/500 [12:17<3:15:19, 24.94s/it]  6%|▌         | 31/500 [12:42<3:13:49, 24.80s/it]  6%|▋         | 32/500 [13:06<3:11:32, 24.56s/it]  7%|▋         | 33/500 [13:30<3:09:50, 24.39s/it]  7%|▋         | 34/500 [13:53<3:07:33, 24.15s/it]  7%|▋         | 35/500 [14:17<3:06:18, 24.04s/it]  7%|▋         | 36/500 [14:41<3:04:51, 23.90s/it]  7%|▋         | 37/500 [15:04<3:03:47, 23.82s/it]  8%|▊         | 38/500 [15:28<3:04:10, 23.92s/it]  8%|▊         | 39/500 [15:52<3:03:32, 23.89s/it]  8%|▊         | 40/500 [16:15<3:01:53, 23.72s/it]  8%|▊         | 41/500 [16:39<3:01:05, 23.67s/it]  8%|▊         | 42/500 [17:03<3:01:14, 23.74s/it]  9%|▊         | 43/500 [17:28<3:03:05, 24.04s/it]  9%|▉         | 44/500 [17:53<3:05:04, 24.35s/it]  9%|▉         | 45/500 [18:17<3:03:40, 24.22s/it]  9%|▉         | 46/500 [18:40<3:02:16, 24.09s/it]  9%|▉         | 47/500 [19:04<3:01:20, 24.02s/it] 10%|▉         | 48/500 [19:29<3:01:26, 24.09s/it] 10%|▉         | 49/500 [19:53<3:00:51, 24.06s/it] 10%|█         | 50/500 [20:17<3:02:17, 24.31s/it] 10%|█         | 51/500 [20:42<3:01:32, 24.26s/it] 10%|█         | 52/500 [21:06<3:00:29, 24.17s/it] 11%|█         | 53/500 [21:29<2:59:36, 24.11s/it] 11%|█         | 54/500 [21:54<3:00:07, 24.23s/it] 11%|█         | 55/500 [22:18<3:00:09, 24.29s/it] 11%|█         | 56/500 [22:42<2:58:51, 24.17s/it] 11%|█▏        | 57/500 [23:06<2:56:33, 23.91s/it] 12%|█▏        | 58/500 [23:30<2:57:59, 24.16s/it] 12%|█▏        | 59/500 [23:55<2:58:46, 24.32s/it] 12%|█▏        | 60/500 [24:20<2:58:50, 24.39s/it] 12%|█▏        | 61/500 [24:44<2:58:55, 24.45s/it] 12%|█▏        | 61/500 [24:44<2:58:05, 24.34s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.317 MB uploadedwandb: | 0.010 MB of 0.317 MB uploadedwandb: / 0.139 MB of 0.317 MB uploadedwandb: - 0.233 MB of 0.317 MB uploadedwandb: \ 0.233 MB of 0.317 MB uploadedwandb: | 0.295 MB of 0.317 MB uploadedwandb: / 0.295 MB of 0.317 MB uploadedwandb: - 0.317 MB of 0.317 MB uploadedwandb: \ 0.317 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb: / 0.317 MB of 0.317 MB uploadedwandb: - 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▆▇▃▂▅▇▄▄▅▄▇▇▇▅▄▇▆▇█▇▇█▇█▇█▇█████▇▇██▇█
wandb:     train_loss ▅▅▇▆▆▅▅▅▅█▅▄▅▂▅▅▂▃▄▅▆▃▅▄▄▁▂▃▃▁▄▄▂▂▄▄▁▃▃▃
wandb:   val_accuracy ▁▄▇▇▁▁▂▅▃▃▃▂▆▆▆▄▃▆▅▇▇▆▆▇▇▇▆▇▇█████▇▇▇█▇▇
wandb:       val_loss ▆▆▄▅▆▆▇▆▅▅▄▄▅▅▅▄█▅▄▂▅▃▄▄▄▅▅▄▄▁▃▄▄▄▂▃▄▄▄▁
wandb: 
wandb: Run summary:
wandb:          epoch 60
wandb:  learning_rate 0.0
wandb: train_accuracy 0.70134
wandb:     train_loss 0.46524
wandb:   val_accuracy 0.68667
wandb:       val_loss 0.29989
wandb: 
wandb: 🚀 View run magic-darkness-44 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lqhrzzek
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_021015-lqhrzzek/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_023544-thsllcmx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-brook-45
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/thsllcmx
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:27<3:51:40, 27.86s/it]  0%|          | 2/500 [00:53<3:41:26, 26.68s/it]  1%|          | 3/500 [01:17<3:31:10, 25.49s/it]  1%|          | 4/500 [01:41<3:24:51, 24.78s/it]  1%|          | 5/500 [02:05<3:22:24, 24.53s/it]  1%|          | 6/500 [02:30<3:24:09, 24.80s/it]  1%|▏         | 7/500 [02:55<3:22:19, 24.62s/it]  2%|▏         | 8/500 [03:19<3:20:16, 24.42s/it]  2%|▏         | 9/500 [03:42<3:17:04, 24.08s/it]  2%|▏         | 10/500 [04:14<3:36:00, 26.45s/it]  2%|▏         | 11/500 [04:39<3:31:43, 25.98s/it]  2%|▏         | 12/500 [05:04<3:29:23, 25.75s/it]  3%|▎         | 13/500 [05:30<3:29:50, 25.85s/it]  3%|▎         | 14/500 [05:55<3:27:04, 25.56s/it]  3%|▎         | 15/500 [06:20<3:25:57, 25.48s/it]  3%|▎         | 16/500 [06:45<3:23:56, 25.28s/it]  3%|▎         | 17/500 [07:10<3:22:02, 25.10s/it]  4%|▎         | 18/500 [07:34<3:20:24, 24.95s/it]  4%|▍         | 19/500 [07:59<3:20:26, 25.00s/it]  4%|▍         | 20/500 [08:24<3:19:19, 24.91s/it]  4%|▍         | 21/500 [08:49<3:18:14, 24.83s/it]  4%|▍         | 22/500 [09:13<3:16:01, 24.61s/it]  5%|▍         | 23/500 [09:38<3:17:24, 24.83s/it]  5%|▍         | 24/500 [10:02<3:15:08, 24.60s/it]  5%|▌         | 25/500 [10:27<3:14:14, 24.54s/it]  5%|▌         | 26/500 [10:52<3:16:34, 24.88s/it]  5%|▌         | 27/500 [11:16<3:13:44, 24.58s/it]  6%|▌         | 28/500 [11:42<3:15:40, 24.87s/it]  6%|▌         | 29/500 [12:06<3:14:20, 24.76s/it]  6%|▌         | 30/500 [12:31<3:13:17, 24.67s/it]  6%|▌         | 31/500 [12:55<3:12:32, 24.63s/it]  6%|▋         | 32/500 [13:19<3:10:48, 24.46s/it]  7%|▋         | 33/500 [13:44<3:11:51, 24.65s/it]  7%|▋         | 34/500 [14:09<3:12:01, 24.72s/it]  7%|▋         | 35/500 [14:34<3:10:35, 24.59s/it]  7%|▋         | 36/500 [14:59<3:11:11, 24.72s/it]  7%|▋         | 37/500 [15:22<3:08:18, 24.40s/it]  8%|▊         | 38/500 [15:46<3:06:55, 24.28s/it]  8%|▊         | 38/500 [15:46<3:11:50, 24.91s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.311 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.200 MB of 0.311 MB uploadedwandb: - 0.200 MB of 0.311 MB uploadedwandb: \ 0.200 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▆▂▂▄▆▂▂▁▂▂▂▂▅▃█▂▁▂▂█▇▆▃▄▂▃▅▅▆▆▅▆▆▆▆▆▆
wandb:     train_loss ▃▂▃▃▂▂▇▃▇▂▅▅▆▂▂▁▁▁█▂▆▃▁▅▁▇▁▄▁▂▂▁▁▁▁▁▄▁
wandb:   val_accuracy ▃█▃▁▃▆▃▁▂▂▃▃▃▆▃▆▃▂▂▃▅▅▄▃▃▃▃▃▃▃▃▃▃▄▄▃▃▃
wandb:       val_loss ▂▂▃▃▂▂▄▄▃▄▄▁▄▇▄▂▂▇▄▄▁▁▃▃▅█▄▃▂▂▂▃▁▂▃▂▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.63299
wandb:     train_loss 0.17956
wandb:   val_accuracy 0.32222
wandb:       val_loss 2.60316
wandb: 
wandb: 🚀 View run graceful-brook-45 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/thsllcmx
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_023544-thsllcmx/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_025211-h7t8d7jd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-glitter-46
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h7t8d7jd
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:27:13, 17.70s/it]  0%|          | 2/500 [00:33<2:18:16, 16.66s/it]  1%|          | 3/500 [00:49<2:13:24, 16.11s/it]  1%|          | 4/500 [01:04<2:12:12, 15.99s/it]  1%|          | 5/500 [01:20<2:09:30, 15.70s/it]  1%|          | 6/500 [01:35<2:08:36, 15.62s/it]  1%|▏         | 7/500 [01:50<2:07:51, 15.56s/it]  2%|▏         | 8/500 [02:06<2:07:32, 15.55s/it]  2%|▏         | 9/500 [02:22<2:07:49, 15.62s/it]  2%|▏         | 10/500 [02:37<2:07:00, 15.55s/it]  2%|▏         | 11/500 [02:53<2:07:32, 15.65s/it]  2%|▏         | 12/500 [03:09<2:08:57, 15.85s/it]  3%|▎         | 13/500 [03:26<2:11:19, 16.18s/it]  3%|▎         | 14/500 [03:43<2:11:19, 16.21s/it]  3%|▎         | 15/500 [03:59<2:12:14, 16.36s/it]  3%|▎         | 16/500 [04:16<2:11:55, 16.35s/it]  3%|▎         | 17/500 [04:33<2:12:57, 16.52s/it]  4%|▎         | 18/500 [04:49<2:11:54, 16.42s/it]  4%|▍         | 19/500 [05:05<2:10:28, 16.28s/it]  4%|▍         | 20/500 [05:23<2:14:30, 16.81s/it]  4%|▍         | 21/500 [05:40<2:15:55, 17.03s/it]  4%|▍         | 22/500 [05:57<2:15:52, 17.06s/it]  5%|▍         | 23/500 [06:13<2:13:18, 16.77s/it]  5%|▍         | 24/500 [06:30<2:12:27, 16.70s/it]  5%|▌         | 25/500 [06:48<2:15:00, 17.05s/it]  5%|▌         | 26/500 [07:04<2:13:23, 16.88s/it]  5%|▌         | 27/500 [07:21<2:12:15, 16.78s/it]  6%|▌         | 28/500 [07:38<2:13:09, 16.93s/it]  6%|▌         | 29/500 [07:56<2:15:49, 17.30s/it]  6%|▌         | 30/500 [08:14<2:16:18, 17.40s/it]  6%|▌         | 31/500 [08:31<2:15:09, 17.29s/it]  6%|▋         | 32/500 [08:49<2:16:30, 17.50s/it]  7%|▋         | 33/500 [09:07<2:17:42, 17.69s/it]  7%|▋         | 34/500 [09:25<2:16:49, 17.62s/it]  7%|▋         | 35/500 [09:42<2:15:54, 17.54s/it]  7%|▋         | 36/500 [09:59<2:14:52, 17.44s/it]  7%|▋         | 37/500 [10:16<2:13:01, 17.24s/it]  8%|▊         | 38/500 [10:33<2:12:19, 17.19s/it]  8%|▊         | 39/500 [10:50<2:11:09, 17.07s/it]  8%|▊         | 40/500 [11:07<2:11:38, 17.17s/it]  8%|▊         | 41/500 [11:22<2:06:19, 16.51s/it]  8%|▊         | 41/500 [11:22<2:07:22, 16.65s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.309 MB uploadedwandb: | 0.010 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▅▁▂▇▁▁▄▂▂▇▄▃██▄▅█▅▃██▆█▇█████████▆█████
wandb:     train_loss ▃▃▇▁▁▂█▂▁▁▂▇█▁▁▁▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▄▁▂▇▂▁▃▂▂▆▃▃▇▇▃▄▆▃▃▇▇▅█▅█▆▆▇▆▇▆▆▆▅▇▇▇▇▇
wandb:       val_loss ▂▂▃▂▂▅█▁▇█▃▆▇▁▂▅▄▂▄▃▁▁▁▃▁▂▁▄▁▄▃▁▂▅▇▃▁▁▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99703
wandb:     train_loss 0.00056
wandb:   val_accuracy 0.67111
wandb:       val_loss 1.57056
wandb: 
wandb: 🚀 View run true-glitter-46 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h7t8d7jd
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_025211-h7t8d7jd/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_030414-xi8l5i97
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-capybara-47
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xi8l5i97
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:31:30, 18.22s/it]  0%|          | 2/500 [00:34<2:23:59, 17.35s/it]  1%|          | 3/500 [00:51<2:19:08, 16.80s/it]  1%|          | 4/500 [01:07<2:18:47, 16.79s/it]  1%|          | 5/500 [01:23<2:15:06, 16.38s/it]  1%|          | 6/500 [01:39<2:13:02, 16.16s/it]  1%|▏         | 7/500 [01:59<2:24:44, 17.62s/it]  2%|▏         | 8/500 [02:15<2:20:13, 17.10s/it]  2%|▏         | 9/500 [02:32<2:19:10, 17.01s/it]  2%|▏         | 10/500 [02:48<2:15:46, 16.63s/it]  2%|▏         | 11/500 [03:04<2:13:57, 16.44s/it]  2%|▏         | 12/500 [03:20<2:12:07, 16.24s/it]  3%|▎         | 13/500 [03:36<2:11:15, 16.17s/it]  3%|▎         | 14/500 [03:51<2:09:31, 15.99s/it]  3%|▎         | 15/500 [04:08<2:09:48, 16.06s/it]  3%|▎         | 16/500 [04:24<2:10:30, 16.18s/it]  3%|▎         | 17/500 [04:40<2:09:17, 16.06s/it]  4%|▎         | 18/500 [04:56<2:08:57, 16.05s/it]  4%|▍         | 19/500 [05:12<2:09:05, 16.10s/it]  4%|▍         | 20/500 [05:28<2:08:41, 16.09s/it]  4%|▍         | 21/500 [05:45<2:10:15, 16.32s/it]  4%|▍         | 22/500 [06:00<2:08:05, 16.08s/it]  5%|▍         | 23/500 [06:15<2:04:44, 15.69s/it]  5%|▍         | 24/500 [06:30<2:02:44, 15.47s/it]  5%|▌         | 25/500 [06:46<2:03:22, 15.58s/it]  5%|▌         | 26/500 [07:03<2:06:21, 15.99s/it]  5%|▌         | 27/500 [07:20<2:07:54, 16.22s/it]  6%|▌         | 28/500 [07:36<2:07:32, 16.21s/it]  6%|▌         | 29/500 [07:52<2:07:55, 16.30s/it]  6%|▌         | 30/500 [08:09<2:07:15, 16.25s/it]  6%|▌         | 31/500 [08:25<2:06:44, 16.21s/it]  6%|▋         | 32/500 [08:42<2:08:03, 16.42s/it]  7%|▋         | 33/500 [08:58<2:06:55, 16.31s/it]  7%|▋         | 34/500 [09:13<2:04:58, 16.09s/it]  7%|▋         | 35/500 [09:29<2:03:44, 15.97s/it]  7%|▋         | 36/500 [09:45<2:03:19, 15.95s/it]  7%|▋         | 37/500 [10:01<2:02:58, 15.94s/it]  8%|▊         | 38/500 [10:18<2:05:03, 16.24s/it]  8%|▊         | 39/500 [10:35<2:06:39, 16.49s/it]  8%|▊         | 39/500 [10:35<2:05:10, 16.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.019 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▂▂▃▂▂▂▂▂▂▂▂▂▃▃▃▃▃▂▆▃▂▃██▂▃▃▃▃▂▃▂▃▃▃▃▄
wandb:     train_loss ▂▂▁▁▁▂▁▂▁▃▁▂▄▁▁▁▁▁▂█▁▂▄▂▁▁▂▁▂▂▂▃▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▁▁▃▁▁▁▂▁▃▃▁▂▂▂▁▂▂▁▇▂▁▁█▇▁▂▂▂▂▁▂▁▂▂▄▂▆
wandb:       val_loss ▁▁▁▁▁▂▃▂▂▃▁▂▄▂▂▁▁▁▁█▁▂▁▁▁▁▂▁▁▁▁▂▂▃▁▁▂▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 38
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.53492
wandb:     train_loss 0.10142
wandb:   val_accuracy 0.58
wandb:       val_loss 1.19545
wandb: 
wandb: 🚀 View run hardy-capybara-47 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xi8l5i97
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_030414-xi8l5i97/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_031529-jgizgxpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-butterfly-48
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jgizgxpf
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:33:48, 18.49s/it]  0%|          | 2/500 [00:35<2:27:02, 17.72s/it]  1%|          | 3/500 [00:51<2:19:42, 16.87s/it]  1%|          | 4/500 [01:07<2:17:06, 16.59s/it]  1%|          | 5/500 [01:23<2:15:02, 16.37s/it]  1%|          | 6/500 [01:40<2:14:58, 16.39s/it]  1%|▏         | 7/500 [02:02<2:31:39, 18.46s/it]  2%|▏         | 8/500 [02:20<2:28:36, 18.12s/it]  2%|▏         | 9/500 [02:37<2:26:10, 17.86s/it]  2%|▏         | 10/500 [02:55<2:25:36, 17.83s/it]  2%|▏         | 11/500 [03:12<2:23:41, 17.63s/it]  2%|▏         | 12/500 [03:31<2:25:49, 17.93s/it]  3%|▎         | 13/500 [03:48<2:24:47, 17.84s/it]  3%|▎         | 14/500 [04:06<2:25:08, 17.92s/it]  3%|▎         | 15/500 [04:24<2:25:19, 17.98s/it]  3%|▎         | 16/500 [04:42<2:24:43, 17.94s/it]  3%|▎         | 17/500 [05:00<2:24:46, 17.98s/it]  4%|▎         | 18/500 [05:18<2:23:54, 17.91s/it]  4%|▍         | 19/500 [05:37<2:24:52, 18.07s/it]  4%|▍         | 20/500 [05:55<2:25:31, 18.19s/it]  4%|▍         | 21/500 [06:14<2:27:28, 18.47s/it]  4%|▍         | 22/500 [06:33<2:28:27, 18.64s/it]  5%|▍         | 23/500 [06:51<2:26:07, 18.38s/it]  5%|▍         | 24/500 [07:08<2:22:51, 18.01s/it]  5%|▌         | 25/500 [07:27<2:25:00, 18.32s/it]  5%|▌         | 26/500 [07:46<2:25:16, 18.39s/it]  5%|▌         | 27/500 [08:05<2:26:43, 18.61s/it]  6%|▌         | 28/500 [08:24<2:28:37, 18.89s/it]  6%|▌         | 29/500 [08:44<2:29:36, 19.06s/it]  6%|▌         | 30/500 [09:00<2:23:03, 18.26s/it]  6%|▌         | 31/500 [09:16<2:16:19, 17.44s/it]  6%|▋         | 32/500 [09:32<2:13:21, 17.10s/it]  7%|▋         | 33/500 [09:55<2:27:00, 18.89s/it]  7%|▋         | 34/500 [10:12<2:21:34, 18.23s/it]  7%|▋         | 35/500 [10:28<2:17:25, 17.73s/it]  7%|▋         | 36/500 [10:45<2:13:52, 17.31s/it]  7%|▋         | 37/500 [11:01<2:11:40, 17.06s/it]  8%|▊         | 38/500 [11:18<2:11:45, 17.11s/it]  8%|▊         | 39/500 [11:36<2:13:31, 17.38s/it]  8%|▊         | 40/500 [11:53<2:11:20, 17.13s/it]  8%|▊         | 41/500 [12:11<2:12:10, 17.28s/it]  8%|▊         | 41/500 [12:11<2:16:24, 17.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▂▆▃▃▅▇▇▇▇▆▇███▇▇▇██▇█▆███████████████
wandb:     train_loss █▇▆▇▂▅▃▂▂▁▁▆▃▁▁▁▁▅▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:   val_accuracy ▁▁▁▂▅▂▂▅▄▅▇▆▅█▇▆▇█▅▅▆▇▅▇▃▇▇▆█▆█▆▆▆▅▆▇▇▆▆
wandb:       val_loss ▃▂▃▂▂▄▃▁▅▅▂▃▇▁▃▄▃▃▃▂▁▁▂▅▁▂▁▄▁▄▂▁▄▅█▄▁▃▂▄
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.00837
wandb:   val_accuracy 0.67556
wandb:       val_loss 1.86383
wandb: 
wandb: 🚀 View run desert-butterfly-48 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jgizgxpf
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_031529-jgizgxpf/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_032818-jt2druug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-totem-49
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jt2druug
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:30:03, 18.04s/it]  0%|          | 2/500 [00:34<2:21:16, 17.02s/it]  1%|          | 3/500 [00:50<2:17:49, 16.64s/it]  1%|          | 4/500 [01:06<2:16:29, 16.51s/it]  1%|          | 5/500 [01:23<2:16:19, 16.52s/it]  1%|          | 6/500 [01:39<2:13:47, 16.25s/it]  1%|▏         | 7/500 [01:55<2:13:11, 16.21s/it]  2%|▏         | 8/500 [02:11<2:13:46, 16.31s/it]  2%|▏         | 9/500 [02:27<2:12:30, 16.19s/it]  2%|▏         | 10/500 [02:43<2:11:44, 16.13s/it]  2%|▏         | 11/500 [03:00<2:13:02, 16.32s/it]  2%|▏         | 12/500 [03:16<2:11:58, 16.23s/it]  3%|▎         | 13/500 [03:32<2:12:00, 16.26s/it]  3%|▎         | 14/500 [03:50<2:15:18, 16.70s/it]  3%|▎         | 15/500 [04:07<2:14:52, 16.69s/it]  3%|▎         | 16/500 [04:23<2:14:13, 16.64s/it]  3%|▎         | 17/500 [04:39<2:13:02, 16.53s/it]  4%|▎         | 18/500 [04:56<2:12:16, 16.47s/it]  4%|▍         | 19/500 [05:12<2:11:21, 16.39s/it]  4%|▍         | 20/500 [05:28<2:09:36, 16.20s/it]  4%|▍         | 21/500 [05:44<2:08:59, 16.16s/it]  4%|▍         | 22/500 [06:00<2:09:16, 16.23s/it]  5%|▍         | 23/500 [06:17<2:09:25, 16.28s/it]  5%|▍         | 24/500 [06:32<2:08:03, 16.14s/it]  5%|▌         | 25/500 [06:48<2:07:08, 16.06s/it]  5%|▌         | 26/500 [07:04<2:06:12, 15.98s/it]  5%|▌         | 27/500 [07:20<2:05:30, 15.92s/it]  6%|▌         | 28/500 [07:36<2:04:36, 15.84s/it]  6%|▌         | 29/500 [07:51<2:03:12, 15.70s/it]  6%|▌         | 30/500 [08:06<2:01:56, 15.57s/it]  6%|▌         | 31/500 [08:22<2:01:39, 15.56s/it]  6%|▋         | 32/500 [08:39<2:04:21, 15.94s/it]  7%|▋         | 33/500 [08:55<2:06:02, 16.19s/it]  7%|▋         | 34/500 [09:11<2:04:59, 16.09s/it]  7%|▋         | 35/500 [09:27<2:04:05, 16.01s/it]  7%|▋         | 36/500 [09:43<2:02:47, 15.88s/it]  7%|▋         | 37/500 [10:00<2:05:14, 16.23s/it]  8%|▊         | 38/500 [10:16<2:05:39, 16.32s/it]  8%|▊         | 39/500 [10:32<2:03:57, 16.13s/it]  8%|▊         | 40/500 [10:49<2:06:05, 16.45s/it]  8%|▊         | 41/500 [11:06<2:06:52, 16.58s/it]  8%|▊         | 41/500 [11:06<2:04:21, 16.26s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.028 MB uploadedwandb: - 0.019 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▃▁▂▄▁▁▂▁▃▅▂▄▇█▄▇█▄▅██▆▇███▇▇████▇▇▇██▇█
wandb:     train_loss ▂▃▆▁▄▄▇▄▁▁▄█▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▁▂▄▂▁▂▂▃▅▃▃▆▇▄▇█▄▄▇▇▅▇▇▇▇▆▆▇▇▇▇▆▆▆▇▇▆▇
wandb:       val_loss ▂▂▃▃▃▅▇▂█▇▄▅▆▁▃▃▃▂▃▄▁▁▁▅▁▂▁▄▁▃▄▁▁▄▆▃▁▁▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99554
wandb:     train_loss 0.00044
wandb:   val_accuracy 0.73556
wandb:       val_loss 0.08339
wandb: 
wandb: 🚀 View run efficient-totem-49 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jt2druug
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_032818-jt2druug/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_034006-mz5kmc71
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-wood-50
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mz5kmc71
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:20<2:48:33, 20.27s/it]  0%|          | 2/500 [00:36<2:30:36, 18.15s/it]  1%|          | 3/500 [00:52<2:22:08, 17.16s/it]  1%|          | 4/500 [01:09<2:20:31, 17.00s/it]  1%|          | 5/500 [01:25<2:17:04, 16.62s/it]  1%|          | 6/500 [01:41<2:14:08, 16.29s/it]  1%|▏         | 7/500 [01:58<2:15:39, 16.51s/it]  2%|▏         | 8/500 [02:14<2:14:04, 16.35s/it]  2%|▏         | 9/500 [02:29<2:11:20, 16.05s/it]  2%|▏         | 10/500 [02:45<2:09:45, 15.89s/it]  2%|▏         | 11/500 [03:01<2:10:54, 16.06s/it]  2%|▏         | 12/500 [03:17<2:09:35, 15.93s/it]  3%|▎         | 13/500 [03:33<2:09:33, 15.96s/it]  3%|▎         | 14/500 [03:49<2:09:20, 15.97s/it]  3%|▎         | 15/500 [04:04<2:08:00, 15.84s/it]  3%|▎         | 16/500 [04:21<2:08:41, 15.95s/it]  3%|▎         | 17/500 [04:38<2:11:14, 16.30s/it]  4%|▎         | 18/500 [04:53<2:09:13, 16.09s/it]  4%|▍         | 19/500 [05:09<2:08:15, 16.00s/it]  4%|▍         | 20/500 [05:26<2:09:28, 16.19s/it]  4%|▍         | 21/500 [05:42<2:09:40, 16.24s/it]  4%|▍         | 22/500 [05:58<2:09:35, 16.27s/it]  5%|▍         | 23/500 [06:14<2:08:40, 16.19s/it]  5%|▍         | 24/500 [06:31<2:08:41, 16.22s/it]  5%|▌         | 25/500 [06:47<2:07:50, 16.15s/it]  5%|▌         | 26/500 [07:03<2:08:18, 16.24s/it]  5%|▌         | 27/500 [07:19<2:06:53, 16.10s/it]  6%|▌         | 28/500 [07:35<2:06:09, 16.04s/it]  6%|▌         | 29/500 [07:50<2:04:58, 15.92s/it]  6%|▌         | 30/500 [08:06<2:03:01, 15.71s/it]  6%|▌         | 31/500 [08:21<2:02:10, 15.63s/it]  6%|▋         | 32/500 [08:42<2:14:02, 17.19s/it]  7%|▋         | 33/500 [08:58<2:10:50, 16.81s/it]  7%|▋         | 34/500 [09:14<2:08:55, 16.60s/it]  7%|▋         | 35/500 [09:30<2:07:01, 16.39s/it]  7%|▋         | 36/500 [09:46<2:05:47, 16.27s/it]  7%|▋         | 37/500 [10:02<2:05:08, 16.22s/it]  8%|▊         | 38/500 [10:17<2:03:26, 16.03s/it]  8%|▊         | 38/500 [10:18<2:05:15, 16.27s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.019 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▃▅▆▆▆▇▄▆▇▇▇▇▇▇▇▇▇█▇▇███████████████
wandb:     train_loss ▇▇▆▆▄█▄▃▆▃▆▅▇▆▅▄▆▅▃▄▂▂▄▂▃▃▄▅▁▂▁▄▆▃▅▆▁▄
wandb:   val_accuracy ▁▁▁▁▅█▆▆▆▂▆▅▆▆▅▅▆▆▄▅▅▅▄▅▅▅▅▄▅▅▅▅▄▄▄▄▅▅
wandb:       val_loss ▂▂▂▂▂▂▂▁▂▃▂▂▂▂▂▂▂▂▂▂▂▁▂▂█▂▂▁▃▂▂▄▂▂▂▂▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.86478
wandb:     train_loss 0.59557
wandb:   val_accuracy 0.55111
wandb:       val_loss 1.0322
wandb: 
wandb: 🚀 View run deep-wood-50 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mz5kmc71
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_034006-mz5kmc71/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_035105-ciu3au2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-plasma-51
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ciu3au2i
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:34:39, 18.60s/it]  0%|          | 2/500 [00:35<2:25:53, 17.58s/it]  1%|          | 3/500 [00:51<2:20:44, 16.99s/it]  1%|          | 4/500 [01:07<2:17:52, 16.68s/it]  1%|          | 5/500 [01:23<2:14:33, 16.31s/it]  1%|          | 6/500 [01:39<2:13:00, 16.16s/it]  1%|▏         | 7/500 [01:55<2:12:35, 16.14s/it]  2%|▏         | 8/500 [02:11<2:11:30, 16.04s/it]  2%|▏         | 9/500 [02:27<2:10:36, 15.96s/it]  2%|▏         | 10/500 [02:43<2:10:09, 15.94s/it]  2%|▏         | 11/500 [02:59<2:11:27, 16.13s/it]  2%|▏         | 12/500 [03:15<2:09:53, 15.97s/it]  3%|▎         | 13/500 [03:31<2:09:42, 15.98s/it]  3%|▎         | 14/500 [03:47<2:09:08, 15.94s/it]  3%|▎         | 15/500 [04:02<2:06:57, 15.71s/it]  3%|▎         | 16/500 [04:17<2:04:28, 15.43s/it]  3%|▎         | 17/500 [04:36<2:13:33, 16.59s/it]  4%|▎         | 18/500 [04:52<2:12:40, 16.52s/it]  4%|▍         | 19/500 [05:08<2:11:50, 16.45s/it]  4%|▍         | 20/500 [05:26<2:13:23, 16.67s/it]  4%|▍         | 21/500 [05:42<2:11:54, 16.52s/it]  4%|▍         | 22/500 [05:58<2:11:25, 16.50s/it]  5%|▍         | 23/500 [06:15<2:11:10, 16.50s/it]  5%|▍         | 24/500 [06:31<2:11:14, 16.54s/it]  5%|▌         | 25/500 [06:48<2:10:04, 16.43s/it]  5%|▌         | 26/500 [07:03<2:08:31, 16.27s/it]  5%|▌         | 27/500 [07:20<2:09:10, 16.39s/it]  6%|▌         | 28/500 [07:36<2:07:03, 16.15s/it]  6%|▌         | 29/500 [07:51<2:05:23, 15.97s/it]  6%|▌         | 30/500 [08:07<2:05:28, 16.02s/it]  6%|▌         | 31/500 [08:23<2:05:15, 16.03s/it]  6%|▋         | 32/500 [08:40<2:05:21, 16.07s/it]  7%|▋         | 33/500 [08:57<2:08:36, 16.52s/it]  7%|▋         | 34/500 [09:13<2:07:31, 16.42s/it]  7%|▋         | 35/500 [09:30<2:07:10, 16.41s/it]  7%|▋         | 36/500 [09:46<2:05:58, 16.29s/it]  7%|▋         | 37/500 [10:02<2:06:18, 16.37s/it]  8%|▊         | 38/500 [10:18<2:05:11, 16.26s/it]  8%|▊         | 38/500 [10:18<2:05:24, 16.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▆▆▄▇▇▇▅▇▇▄███▇██▆███▅▇▆█████▇█▆▇▆▆█▇
wandb:     train_loss ▂▂▁▂▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:   val_accuracy ▁▁▇▇▆▆▇█▅█▄▄▅▇▅▅▇▇▅▇▆▆▅▆▆▅▆▆▆▆▆▆▅▆▆▅▆▆
wandb:       val_loss ▃▃▂▂▃▂▂▁▂▂▂▂▇▁▂▆▃▃▇▂▂▁▁▁▂▃▁▆▁▇▄▂█▆▃▅▆▇
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.92422
wandb:     train_loss 0.0047
wandb:   val_accuracy 0.62889
wandb:       val_loss 4.02041
wandb: 
wandb: 🚀 View run amber-plasma-51 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ciu3au2i
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_035105-ciu3au2i/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_040204-qejwc70j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-wildflower-52
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qejwc70j
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:27:12, 17.70s/it]  0%|          | 2/500 [00:33<2:19:28, 16.80s/it]  1%|          | 3/500 [00:51<2:20:45, 16.99s/it]  1%|          | 4/500 [01:07<2:17:44, 16.66s/it]  1%|          | 5/500 [01:22<2:13:39, 16.20s/it]  1%|          | 6/500 [01:37<2:09:27, 15.72s/it]  1%|▏         | 7/500 [01:52<2:07:24, 15.51s/it]  2%|▏         | 8/500 [02:08<2:08:18, 15.65s/it]  2%|▏         | 9/500 [02:28<2:20:03, 17.11s/it]  2%|▏         | 10/500 [02:49<2:28:16, 18.16s/it]  2%|▏         | 11/500 [03:06<2:24:33, 17.74s/it]  2%|▏         | 12/500 [03:21<2:19:08, 17.11s/it]  3%|▎         | 13/500 [03:41<2:25:50, 17.97s/it]  3%|▎         | 14/500 [03:57<2:21:07, 17.42s/it]  3%|▎         | 15/500 [04:13<2:16:47, 16.92s/it]  3%|▎         | 16/500 [04:29<2:13:54, 16.60s/it]  3%|▎         | 17/500 [04:45<2:12:48, 16.50s/it]  4%|▎         | 18/500 [05:01<2:11:12, 16.33s/it]  4%|▍         | 19/500 [05:17<2:09:48, 16.19s/it]  4%|▍         | 20/500 [05:34<2:10:30, 16.31s/it]  4%|▍         | 21/500 [05:50<2:11:11, 16.43s/it]  4%|▍         | 22/500 [06:06<2:09:50, 16.30s/it]  5%|▍         | 23/500 [06:23<2:11:11, 16.50s/it]  5%|▍         | 24/500 [06:40<2:11:54, 16.63s/it]  5%|▌         | 25/500 [06:56<2:10:11, 16.45s/it]  5%|▌         | 26/500 [07:12<2:09:06, 16.34s/it]  5%|▌         | 27/500 [07:28<2:07:44, 16.20s/it]  6%|▌         | 28/500 [07:45<2:09:13, 16.43s/it]  6%|▌         | 29/500 [08:02<2:09:28, 16.49s/it]  6%|▌         | 30/500 [08:19<2:10:51, 16.70s/it]  6%|▌         | 31/500 [08:35<2:08:52, 16.49s/it]  6%|▋         | 32/500 [08:51<2:07:58, 16.41s/it]  7%|▋         | 33/500 [09:07<2:06:21, 16.23s/it]  7%|▋         | 34/500 [09:23<2:05:20, 16.14s/it]  7%|▋         | 35/500 [09:39<2:05:14, 16.16s/it]  7%|▋         | 36/500 [09:56<2:07:09, 16.44s/it]  7%|▋         | 37/500 [10:13<2:08:31, 16.65s/it]  8%|▊         | 38/500 [10:29<2:06:37, 16.45s/it]  8%|▊         | 39/500 [10:45<2:05:13, 16.30s/it]  8%|▊         | 40/500 [11:01<2:03:48, 16.15s/it]  8%|▊         | 41/500 [11:18<2:04:39, 16.30s/it]  8%|▊         | 41/500 [11:18<2:06:33, 16.54s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.308 MB uploadedwandb: \ 0.137 MB of 0.308 MB uploadedwandb: | 0.308 MB of 0.308 MB uploadedwandb: / 0.308 MB of 0.308 MB uploadedwandb: - 0.308 MB of 0.308 MB uploadedwandb: \ 0.308 MB of 0.308 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▄▁▂▂▁▁▁▃▁▃▄▃▆▇▄██▂▆██▅█▅████▇███▇▆█████
wandb:     train_loss ▃▃▇▁▆▂▆▅▁▁█▆▇▂▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁
wandb:   val_accuracy ▂▁▁▂▂▂▁▂▃▂▃▅▃▆▇▄██▃▆██▅█▅█▇▇█▆██▇▆▅▆██▇▇
wandb:       val_loss ▂▂▃▃▃▅▇▃▇█▄▃▇▁▃▄▃▃▅▂▁▁▁▄▁▂▁▆▁▄▄▁▂▄▇▃▁▁▅▂
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.9688
wandb:     train_loss 7e-05
wandb:   val_accuracy 0.70667
wandb:       val_loss 1.33219
wandb: 
wandb: 🚀 View run twilight-wildflower-52 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qejwc70j
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_040204-qejwc70j/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_041405-a3v8k0j0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-haze-53
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/a3v8k0j0
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:28:50, 17.90s/it]  0%|          | 2/500 [00:36<2:31:38, 18.27s/it]  1%|          | 3/500 [00:52<2:24:38, 17.46s/it]  1%|          | 4/500 [01:11<2:26:38, 17.74s/it]  1%|          | 5/500 [01:27<2:22:30, 17.27s/it]  1%|          | 6/500 [01:43<2:18:31, 16.83s/it]  1%|▏         | 7/500 [01:59<2:16:46, 16.65s/it]  2%|▏         | 8/500 [02:15<2:13:53, 16.33s/it]  2%|▏         | 9/500 [02:30<2:11:25, 16.06s/it]  2%|▏         | 10/500 [02:50<2:20:15, 17.17s/it]  2%|▏         | 11/500 [03:05<2:14:13, 16.47s/it]  2%|▏         | 12/500 [03:21<2:12:31, 16.29s/it]  3%|▎         | 13/500 [03:37<2:11:27, 16.20s/it]  3%|▎         | 14/500 [04:03<2:36:50, 19.36s/it]  3%|▎         | 15/500 [04:21<2:31:28, 18.74s/it]  3%|▎         | 16/500 [04:38<2:26:52, 18.21s/it]  3%|▎         | 17/500 [04:58<2:31:58, 18.88s/it]  4%|▎         | 18/500 [05:15<2:25:40, 18.13s/it]  4%|▍         | 19/500 [05:31<2:20:03, 17.47s/it]  4%|▍         | 20/500 [05:46<2:15:53, 16.99s/it]  4%|▍         | 21/500 [06:03<2:14:03, 16.79s/it]  4%|▍         | 22/500 [06:29<2:35:40, 19.54s/it]  5%|▍         | 23/500 [06:45<2:27:01, 18.49s/it]  5%|▍         | 24/500 [07:02<2:23:27, 18.08s/it]  5%|▌         | 25/500 [07:19<2:20:21, 17.73s/it]  5%|▌         | 26/500 [07:35<2:16:33, 17.29s/it]  5%|▌         | 27/500 [07:52<2:15:46, 17.22s/it]  6%|▌         | 28/500 [08:12<2:21:37, 18.00s/it]  6%|▌         | 29/500 [08:29<2:20:13, 17.86s/it]  6%|▌         | 30/500 [08:49<2:23:43, 18.35s/it]  6%|▌         | 31/500 [09:06<2:20:13, 17.94s/it]  6%|▋         | 32/500 [09:26<2:24:57, 18.59s/it]  7%|▋         | 33/500 [09:41<2:16:23, 17.52s/it]  7%|▋         | 34/500 [09:57<2:11:50, 16.97s/it]  7%|▋         | 35/500 [10:13<2:09:43, 16.74s/it]  7%|▋         | 36/500 [10:30<2:09:32, 16.75s/it]  7%|▋         | 37/500 [10:46<2:09:15, 16.75s/it]  8%|▊         | 38/500 [11:03<2:09:22, 16.80s/it]  8%|▊         | 38/500 [11:08<2:15:23, 17.58s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.019 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▃▅▇▇▇▇▇▇▇▇▇▇▇█▇▇███▇███████████████
wandb:     train_loss █▇▆▇▄█▄▃▆▆▇▅▆▇▅▄▆▅▄▄▂▂▄▂▂▄▇▇▁▃▁▄▆▃▆▇▂▂
wandb:   val_accuracy ▁▁▃▂▇█▆▆▇▆▇▅▇▆▅▅▆▆▄▅▆▆▅▆▅▆▆▄▄▄▄▅▄▄▄▄▅▆
wandb:       val_loss ▅▅▄▄▅▃▄▂▄▅▄▅▄▃▂▇▄▄▃▄▃▁▄▂▅▄▅▃█▄▄▆▃▄▂▄▂▄
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.81129
wandb:     train_loss 0.38172
wandb:   val_accuracy 0.56
wandb:       val_loss 0.94095
wandb: 
wandb: 🚀 View run ethereal-haze-53 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/a3v8k0j0
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_041405-a3v8k0j0/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_042558-hx751lp6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-valley-54
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/hx751lp6
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:35:59, 18.76s/it]  0%|          | 2/500 [00:34<2:21:24, 17.04s/it]  1%|          | 3/500 [00:50<2:16:00, 16.42s/it]  1%|          | 4/500 [01:05<2:12:32, 16.03s/it]  1%|          | 5/500 [01:20<2:09:35, 15.71s/it]  1%|          | 6/500 [01:36<2:09:44, 15.76s/it]  1%|▏         | 7/500 [01:52<2:09:13, 15.73s/it]  2%|▏         | 8/500 [02:07<2:08:11, 15.63s/it]  2%|▏         | 9/500 [02:23<2:06:54, 15.51s/it]  2%|▏         | 10/500 [02:38<2:07:15, 15.58s/it]  2%|▏         | 11/500 [02:54<2:06:55, 15.57s/it]  2%|▏         | 12/500 [03:09<2:05:26, 15.42s/it]  3%|▎         | 13/500 [03:25<2:06:06, 15.54s/it]  3%|▎         | 14/500 [03:43<2:12:48, 16.40s/it]  3%|▎         | 15/500 [03:59<2:10:23, 16.13s/it]  3%|▎         | 16/500 [04:14<2:08:12, 15.89s/it]  3%|▎         | 17/500 [04:29<2:06:43, 15.74s/it]  4%|▎         | 18/500 [04:49<2:15:48, 16.91s/it]  4%|▍         | 19/500 [05:04<2:11:19, 16.38s/it]  4%|▍         | 20/500 [05:19<2:08:33, 16.07s/it]  4%|▍         | 21/500 [05:35<2:06:48, 15.88s/it]  4%|▍         | 22/500 [05:50<2:05:00, 15.69s/it]  5%|▍         | 23/500 [06:05<2:03:50, 15.58s/it]  5%|▍         | 24/500 [06:21<2:02:35, 15.45s/it]  5%|▌         | 25/500 [06:36<2:01:57, 15.40s/it]  5%|▌         | 26/500 [06:51<2:01:15, 15.35s/it]  5%|▌         | 27/500 [07:07<2:01:59, 15.47s/it]  6%|▌         | 28/500 [07:22<2:01:46, 15.48s/it]  6%|▌         | 29/500 [07:38<2:01:12, 15.44s/it]  6%|▌         | 30/500 [07:53<2:00:24, 15.37s/it]  6%|▌         | 31/500 [08:08<2:00:07, 15.37s/it]  6%|▋         | 32/500 [08:24<2:00:45, 15.48s/it]  7%|▋         | 33/500 [08:40<2:00:31, 15.48s/it]  7%|▋         | 34/500 [08:55<2:00:12, 15.48s/it]  7%|▋         | 35/500 [09:14<2:08:37, 16.60s/it]  7%|▋         | 36/500 [09:30<2:05:57, 16.29s/it]  7%|▋         | 37/500 [09:45<2:02:17, 15.85s/it]  8%|▊         | 38/500 [10:00<2:00:00, 15.59s/it]  8%|▊         | 39/500 [10:19<2:09:43, 16.88s/it]  8%|▊         | 40/500 [10:35<2:06:23, 16.49s/it]  8%|▊         | 41/500 [10:51<2:03:53, 16.19s/it]  8%|▊         | 42/500 [11:06<2:02:56, 16.11s/it]  9%|▊         | 43/500 [11:22<2:01:11, 15.91s/it]  9%|▉         | 44/500 [11:37<2:00:03, 15.80s/it]  9%|▉         | 45/500 [11:53<1:58:33, 15.63s/it]  9%|▉         | 46/500 [12:08<1:57:21, 15.51s/it]  9%|▉         | 47/500 [12:24<1:57:53, 15.61s/it] 10%|▉         | 48/500 [12:40<1:58:27, 15.72s/it] 10%|▉         | 49/500 [12:55<1:57:17, 15.61s/it] 10%|█         | 50/500 [13:11<1:56:53, 15.59s/it] 10%|█         | 51/500 [13:26<1:55:26, 15.43s/it] 10%|█         | 52/500 [13:41<1:54:24, 15.32s/it] 11%|█         | 53/500 [13:57<1:55:56, 15.56s/it] 11%|█         | 54/500 [14:12<1:55:34, 15.55s/it] 11%|█         | 55/500 [14:28<1:54:54, 15.49s/it] 11%|█         | 56/500 [14:43<1:54:11, 15.43s/it] 11%|█         | 56/500 [14:43<1:56:45, 15.78s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.029 MB uploadedwandb: | 0.139 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▆▅▃█▇▇▄▇▅▇█▆█▇▄▆█▇███▇▇▆█▆▇▇▇▇▇█▆▆█▆▆▇
wandb:     train_loss ▂▂▁▁▂▁▁▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▂▁▂▁
wandb:   val_accuracy ▁▂▆▆▄▇▆█▃▆▃▅▆▅▅▅▃▅▆▅▅▅▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       val_loss ▃▃▂▂▂▁▂▂▅▇▂▇▄▅▁▃▆▁▄▁▃▆▁█▆▅▆▂▁▆▁▆▁▃▂▇▁▆▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 55
wandb:  learning_rate 2e-05
wandb: train_accuracy 0.90936
wandb:     train_loss 0.05592
wandb:   val_accuracy 0.58889
wandb:       val_loss 0.03383
wandb: 
wandb: 🚀 View run fanciful-valley-54 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/hx751lp6
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_042558-hx751lp6/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_044127-aw3vedrj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-universe-55
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aw3vedrj
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:35:37, 18.71s/it]  0%|          | 2/500 [00:36<2:32:02, 18.32s/it]  1%|          | 3/500 [00:54<2:29:09, 18.01s/it]  1%|          | 4/500 [01:11<2:25:42, 17.63s/it]  1%|          | 5/500 [01:28<2:24:28, 17.51s/it]  1%|          | 6/500 [01:45<2:21:26, 17.18s/it]  1%|▏         | 7/500 [02:07<2:34:28, 18.80s/it]  2%|▏         | 8/500 [02:23<2:27:52, 18.03s/it]  2%|▏         | 9/500 [02:40<2:23:48, 17.57s/it]  2%|▏         | 10/500 [02:56<2:20:52, 17.25s/it]  2%|▏         | 11/500 [03:13<2:19:51, 17.16s/it]  2%|▏         | 12/500 [03:30<2:17:37, 16.92s/it]  3%|▎         | 13/500 [03:46<2:15:32, 16.70s/it]  3%|▎         | 14/500 [04:02<2:14:16, 16.58s/it]  3%|▎         | 15/500 [04:19<2:14:11, 16.60s/it]  3%|▎         | 16/500 [04:36<2:16:14, 16.89s/it]  3%|▎         | 17/500 [04:53<2:16:19, 16.94s/it]  4%|▎         | 18/500 [05:11<2:17:35, 17.13s/it]  4%|▍         | 19/500 [05:28<2:16:43, 17.05s/it]  4%|▍         | 20/500 [05:50<2:27:45, 18.47s/it]  4%|▍         | 21/500 [06:09<2:29:17, 18.70s/it]  4%|▍         | 22/500 [06:26<2:26:13, 18.36s/it]  5%|▍         | 23/500 [06:44<2:24:01, 18.12s/it]  5%|▍         | 24/500 [07:03<2:25:03, 18.28s/it]  5%|▌         | 25/500 [07:20<2:22:48, 18.04s/it]  5%|▌         | 26/500 [07:36<2:17:46, 17.44s/it]  5%|▌         | 27/500 [07:52<2:13:25, 16.93s/it]  6%|▌         | 28/500 [08:09<2:12:18, 16.82s/it]  6%|▌         | 29/500 [08:26<2:12:55, 16.93s/it]  6%|▌         | 30/500 [08:42<2:11:32, 16.79s/it]  6%|▌         | 31/500 [09:00<2:14:11, 17.17s/it]  6%|▋         | 32/500 [09:17<2:13:28, 17.11s/it]  7%|▋         | 33/500 [09:34<2:13:35, 17.16s/it]  7%|▋         | 34/500 [09:52<2:13:00, 17.13s/it]  7%|▋         | 35/500 [10:08<2:11:09, 16.92s/it]  7%|▋         | 36/500 [10:24<2:09:19, 16.72s/it]  7%|▋         | 37/500 [10:41<2:10:08, 16.87s/it]  8%|▊         | 38/500 [10:58<2:08:53, 16.74s/it]  8%|▊         | 38/500 [10:58<2:13:24, 17.33s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.312 MB uploadedwandb: - 0.019 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▃▃▃▃▁▁▃▃▂▂▅▂▅▆▅▃▄▆▆▆▆█▆▇▇█▇▆█▇▇██▇▇███
wandb:     train_loss ▂▂▂▂▄▃▄▆▂▂▄▆▃▆▂▁▆▁▁▁▁▁▁▁▁▁█▆▁▁▁▁▄▁▁▁▁▁
wandb:   val_accuracy ▃▂▃▃▁▂▃▂▂▂▆▁▆▇▅▃▅▆▇▇▇█▆▇▇█▇▆█▇▇▇█▇▇███
wandb:       val_loss ▂▂▃▃▂▃▁█▄▂▂█▄▂▂▄▂▁▂▁▁▁▁▁▁▄▁▅▁▅▃▁▁▅▅▂▅▁
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.91976
wandb:     train_loss 0.01798
wandb:   val_accuracy 0.71556
wandb:       val_loss 0.40925
wandb: 
wandb: 🚀 View run generous-universe-55 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aw3vedrj
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_044127-aw3vedrj/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_045308-qhyqn6de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-mountain-56
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qhyqn6de
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:43:57, 19.71s/it]  0%|          | 2/500 [00:36<2:27:10, 17.73s/it]  1%|          | 3/500 [00:53<2:25:40, 17.59s/it]  1%|          | 4/500 [01:10<2:24:08, 17.44s/it]  1%|          | 5/500 [01:28<2:24:00, 17.46s/it]  1%|          | 6/500 [01:45<2:23:59, 17.49s/it]  1%|▏         | 7/500 [02:02<2:20:35, 17.11s/it]  2%|▏         | 8/500 [02:17<2:16:53, 16.69s/it]  2%|▏         | 9/500 [02:34<2:17:15, 16.77s/it]  2%|▏         | 10/500 [02:51<2:17:26, 16.83s/it]  2%|▏         | 11/500 [03:08<2:16:36, 16.76s/it]  2%|▏         | 12/500 [03:25<2:17:49, 16.95s/it]  3%|▎         | 13/500 [03:42<2:17:42, 16.97s/it]  3%|▎         | 14/500 [03:59<2:15:55, 16.78s/it]  3%|▎         | 15/500 [04:15<2:13:49, 16.55s/it]  3%|▎         | 16/500 [04:30<2:11:17, 16.28s/it]  3%|▎         | 17/500 [04:47<2:11:46, 16.37s/it]  4%|▎         | 18/500 [05:03<2:12:07, 16.45s/it]  4%|▍         | 19/500 [05:21<2:13:58, 16.71s/it]  4%|▍         | 20/500 [05:37<2:13:00, 16.63s/it]  4%|▍         | 21/500 [05:54<2:11:57, 16.53s/it]  4%|▍         | 22/500 [06:10<2:12:25, 16.62s/it]  5%|▍         | 23/500 [06:26<2:10:55, 16.47s/it]  5%|▍         | 24/500 [06:44<2:13:11, 16.79s/it]  5%|▍         | 24/500 [06:44<2:13:42, 16.85s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▂▄▄▆▆▇▇▇█▇▇█▆▇▅█▅▅▆▇▇▅▇
wandb:     train_loss ▇▆▄▅▃▇▁▁▄▃▃▇▅▅▃▃▃▃█▃▅▂▂▄
wandb:   val_accuracy ▁▁▃▄▆█▇████▆▇▃▃▂▆▂▂▂▂▃▂▂
wandb:       val_loss ▄▄▃▃▄▂▄▁▂▃▃▄▂▅▇▄▂▂▂▁▂▄█▂
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.70877
wandb:     train_loss 0.94493
wandb:   val_accuracy 0.40222
wandb:       val_loss 0.78528
wandb: 
wandb: 🚀 View run bright-mountain-56 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qhyqn6de
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_045308-qhyqn6de/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_050031-m8lw7dsv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-mountain-57
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/m8lw7dsv
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:34:57, 18.63s/it]  0%|          | 2/500 [00:34<2:20:45, 16.96s/it]  1%|          | 3/500 [00:50<2:15:53, 16.40s/it]  1%|          | 4/500 [01:05<2:12:42, 16.05s/it]  1%|          | 5/500 [01:22<2:13:19, 16.16s/it]  1%|          | 6/500 [01:38<2:14:16, 16.31s/it]  1%|▏         | 7/500 [01:54<2:12:50, 16.17s/it]  2%|▏         | 8/500 [02:11<2:14:26, 16.40s/it]  2%|▏         | 9/500 [02:27<2:14:24, 16.42s/it]  2%|▏         | 10/500 [02:44<2:14:08, 16.42s/it]  2%|▏         | 11/500 [03:01<2:14:49, 16.54s/it]  2%|▏         | 12/500 [03:17<2:15:21, 16.64s/it]  3%|▎         | 13/500 [03:35<2:16:24, 16.81s/it]  3%|▎         | 14/500 [03:50<2:12:44, 16.39s/it]  3%|▎         | 15/500 [04:06<2:10:09, 16.10s/it]  3%|▎         | 16/500 [04:21<2:08:55, 15.98s/it]  3%|▎         | 17/500 [04:37<2:07:39, 15.86s/it]  4%|▎         | 18/500 [04:52<2:06:44, 15.78s/it]  4%|▍         | 19/500 [05:08<2:06:09, 15.74s/it]  4%|▍         | 20/500 [05:25<2:08:06, 16.01s/it]  4%|▍         | 21/500 [05:40<2:07:16, 15.94s/it]  4%|▍         | 22/500 [05:57<2:07:45, 16.04s/it]  5%|▍         | 23/500 [06:12<2:05:52, 15.83s/it]  5%|▍         | 24/500 [06:28<2:05:37, 15.83s/it]  5%|▍         | 24/500 [06:28<2:08:23, 16.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.293 MB of 0.312 MB uploadedwandb: - 0.293 MB of 0.312 MB uploadedwandb: \ 0.293 MB of 0.312 MB uploadedwandb: | 0.293 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▁▅▅▃▇▄▅▂▆▇▇█▇█▆▆█▇▇▅█▂█
wandb:     train_loss ▅▅▃▄▁▅▁▁▅▄▄█▂▂▁▁▆▁▂▂▃▁▂▂
wandb:   val_accuracy ▁▁▆▃▄▇▆▇▄▇▆▆▆▇█▆▆▆▅▅▅▆▂▇
wandb:       val_loss ▃▃▂▂▃▂▂▁▂▃▂▄▄▁▂▃▂▃▂▂▁▂█▃
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.9584
wandb:     train_loss 0.3119
wandb:   val_accuracy 0.76
wandb:       val_loss 0.93325
wandb: 
wandb: 🚀 View run wild-mountain-57 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/m8lw7dsv
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_050031-m8lw7dsv/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_050737-cfr0l7me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-armadillo-58
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cfr0l7me
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:31:15, 18.19s/it]  0%|          | 2/500 [00:35<2:25:57, 17.59s/it]  1%|          | 3/500 [00:51<2:18:57, 16.77s/it]  1%|          | 4/500 [01:07<2:16:23, 16.50s/it]  1%|          | 5/500 [01:22<2:13:24, 16.17s/it]  1%|          | 6/500 [01:38<2:11:45, 16.00s/it]  1%|▏         | 7/500 [01:54<2:11:33, 16.01s/it]  2%|▏         | 8/500 [02:11<2:12:32, 16.16s/it]  2%|▏         | 9/500 [02:26<2:10:59, 16.01s/it]  2%|▏         | 10/500 [02:41<2:08:11, 15.70s/it]  2%|▏         | 11/500 [02:56<2:05:44, 15.43s/it]  2%|▏         | 12/500 [03:16<2:17:52, 16.95s/it]  3%|▎         | 13/500 [03:32<2:13:54, 16.50s/it]  3%|▎         | 14/500 [03:48<2:12:14, 16.33s/it]  3%|▎         | 15/500 [04:03<2:09:46, 16.05s/it]  3%|▎         | 16/500 [04:19<2:09:50, 16.10s/it]  3%|▎         | 17/500 [04:35<2:08:27, 15.96s/it]  4%|▎         | 18/500 [04:52<2:09:20, 16.10s/it]  4%|▍         | 19/500 [05:07<2:07:59, 15.97s/it]  4%|▍         | 20/500 [05:23<2:07:58, 16.00s/it]  4%|▍         | 21/500 [05:40<2:08:23, 16.08s/it]  4%|▍         | 22/500 [05:56<2:09:53, 16.30s/it]  5%|▍         | 23/500 [06:13<2:10:40, 16.44s/it]  5%|▍         | 24/500 [06:29<2:10:20, 16.43s/it]  5%|▌         | 25/500 [06:46<2:10:31, 16.49s/it]  5%|▌         | 26/500 [07:03<2:10:49, 16.56s/it]  5%|▌         | 27/500 [07:19<2:08:34, 16.31s/it]  6%|▌         | 28/500 [07:36<2:10:07, 16.54s/it]  6%|▌         | 29/500 [07:52<2:09:19, 16.48s/it]  6%|▌         | 30/500 [08:08<2:09:06, 16.48s/it]  6%|▌         | 31/500 [08:24<2:07:03, 16.25s/it]  6%|▋         | 32/500 [08:39<2:03:54, 15.89s/it]  7%|▋         | 33/500 [08:55<2:04:16, 15.97s/it]  7%|▋         | 34/500 [09:11<2:03:31, 15.91s/it]  7%|▋         | 35/500 [09:27<2:04:07, 16.02s/it]  7%|▋         | 36/500 [09:44<2:05:25, 16.22s/it]  7%|▋         | 37/500 [10:00<2:05:04, 16.21s/it]  8%|▊         | 38/500 [10:17<2:05:11, 16.26s/it]  8%|▊         | 39/500 [10:34<2:06:57, 16.52s/it]  8%|▊         | 40/500 [10:51<2:08:57, 16.82s/it]  8%|▊         | 41/500 [11:07<2:06:28, 16.53s/it]  8%|▊         | 41/500 [11:07<2:04:34, 16.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.200 MB of 0.314 MB uploadedwandb: - 0.200 MB of 0.314 MB uploadedwandb: \ 0.200 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▆▁▇▇▆▃▂▂▆▅▇▆▇▅▆▆▆▅█▇▆█▇███████████████
wandb:     train_loss ▂█▂▁▁▂▁▂▁▁▃▂▁▁▁▁▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▇▁▇▇▇▄▃▃▇▆▇▆▇▆▇▇▇▆▇▇▇█▇▇█████▇████▇▇█▇
wandb:       val_loss ▂▆▁▅▂▃▇▁▇█▄▂▅▁▄▄▅▄▂▅▁▁▁▅▁▃▁▃▁▂▄▁▁▃▇▃▁▁▄▂
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.90342
wandb:     train_loss 3e-05
wandb:   val_accuracy 0.68667
wandb:       val_loss 0.66195
wandb: 
wandb: 🚀 View run volcanic-armadillo-58 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cfr0l7me
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_050737-cfr0l7me/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_051926-dhj8ps9b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-planet-59
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dhj8ps9b
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:34:23, 18.56s/it]  0%|          | 2/500 [00:35<2:25:49, 17.57s/it]  1%|          | 3/500 [00:51<2:20:19, 16.94s/it]  1%|          | 4/500 [01:08<2:19:02, 16.82s/it]  1%|          | 5/500 [01:24<2:17:39, 16.69s/it]  1%|          | 6/500 [01:41<2:16:49, 16.62s/it]  1%|▏         | 7/500 [01:58<2:19:16, 16.95s/it]  2%|▏         | 8/500 [02:16<2:19:46, 17.05s/it]  2%|▏         | 9/500 [02:32<2:19:07, 17.00s/it]  2%|▏         | 10/500 [02:49<2:16:53, 16.76s/it]  2%|▏         | 11/500 [03:05<2:15:06, 16.58s/it]  2%|▏         | 12/500 [03:21<2:14:51, 16.58s/it]  3%|▎         | 13/500 [03:37<2:13:09, 16.41s/it]  3%|▎         | 14/500 [03:53<2:11:52, 16.28s/it]  3%|▎         | 15/500 [04:16<2:27:24, 18.24s/it]  3%|▎         | 16/500 [04:33<2:24:03, 17.86s/it]  3%|▎         | 17/500 [04:50<2:21:24, 17.57s/it]  4%|▎         | 18/500 [05:07<2:20:33, 17.50s/it]  4%|▍         | 19/500 [05:25<2:19:45, 17.43s/it]  4%|▍         | 20/500 [05:42<2:18:35, 17.32s/it]  4%|▍         | 21/500 [05:58<2:16:47, 17.14s/it]  4%|▍         | 22/500 [06:15<2:16:14, 17.10s/it]  5%|▍         | 23/500 [06:32<2:13:57, 16.85s/it]  5%|▍         | 24/500 [06:48<2:12:33, 16.71s/it]  5%|▌         | 25/500 [07:05<2:12:18, 16.71s/it]  5%|▌         | 26/500 [07:23<2:15:33, 17.16s/it]  5%|▌         | 27/500 [07:40<2:15:43, 17.22s/it]  6%|▌         | 28/500 [07:57<2:13:17, 16.94s/it]  6%|▌         | 29/500 [08:13<2:11:42, 16.78s/it]  6%|▌         | 30/500 [08:29<2:09:56, 16.59s/it]  6%|▌         | 31/500 [08:47<2:11:14, 16.79s/it]  6%|▋         | 32/500 [09:05<2:13:53, 17.17s/it]  7%|▋         | 33/500 [09:21<2:11:22, 16.88s/it]  7%|▋         | 34/500 [09:37<2:09:02, 16.61s/it]  7%|▋         | 35/500 [09:53<2:08:29, 16.58s/it]  7%|▋         | 36/500 [10:09<2:06:51, 16.40s/it]  7%|▋         | 36/500 [10:09<2:10:59, 16.94s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▅▅▆▆▇▆▇▇▇▇▇▇▇▇▇██▇█▇█▇██▇█████▇▇▇
wandb:     train_loss ▃▃▂▂▂▃▂▂▂▂▃▂▂▃▂▃▃▂▂▁▁▁▁▁█▁▄▂▁▁▁▂▃▁▃▃
wandb:   val_accuracy ▁▁▂▃▆▅█▇▆▅▇▆▇▇▇▇▇▇▇▇█▇▆▇▇██▇█▇██▇▇▆▇
wandb:       val_loss ▅▅▅▅▅▅▆▅▆▆▂█▆▃▅▄▂▂▄▁▁▂▃▃▂█▃▇▂▃▃▆▃▆▃▃
wandb: 
wandb: Run summary:
wandb:          epoch 35
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.72214
wandb:     train_loss 1.62996
wandb:   val_accuracy 0.63778
wandb:       val_loss 0.71704
wandb: 
wandb: 🚀 View run misty-planet-59 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dhj8ps9b
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_051926-dhj8ps9b/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_053020-av552v8z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-totem-60
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/av552v8z
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:26:59, 17.67s/it]  0%|          | 2/500 [00:33<2:17:26, 16.56s/it]  1%|          | 3/500 [00:49<2:13:31, 16.12s/it]  1%|          | 4/500 [01:06<2:17:25, 16.62s/it]  1%|          | 5/500 [01:23<2:17:27, 16.66s/it]  1%|          | 6/500 [01:39<2:15:30, 16.46s/it]  1%|▏         | 7/500 [01:56<2:16:21, 16.59s/it]  2%|▏         | 8/500 [02:12<2:15:40, 16.55s/it]  2%|▏         | 9/500 [02:29<2:15:32, 16.56s/it]  2%|▏         | 10/500 [02:50<2:26:30, 17.94s/it]  2%|▏         | 11/500 [03:08<2:26:19, 17.95s/it]  2%|▏         | 12/500 [03:26<2:26:42, 18.04s/it]  3%|▎         | 13/500 [03:44<2:25:28, 17.92s/it]  3%|▎         | 14/500 [04:00<2:22:44, 17.62s/it]  3%|▎         | 15/500 [04:17<2:20:33, 17.39s/it]  3%|▎         | 16/500 [04:34<2:18:29, 17.17s/it]  3%|▎         | 17/500 [04:49<2:13:49, 16.62s/it]  4%|▎         | 18/500 [05:06<2:12:34, 16.50s/it]  4%|▍         | 19/500 [05:31<2:34:29, 19.27s/it]  4%|▍         | 20/500 [05:49<2:30:26, 18.80s/it]  4%|▍         | 21/500 [06:06<2:24:55, 18.15s/it]  4%|▍         | 22/500 [06:21<2:19:02, 17.45s/it]  5%|▍         | 23/500 [06:38<2:16:09, 17.13s/it]  5%|▍         | 24/500 [06:54<2:13:36, 16.84s/it]  5%|▌         | 25/500 [07:11<2:12:32, 16.74s/it]  5%|▌         | 26/500 [07:27<2:10:48, 16.56s/it]  5%|▌         | 27/500 [07:42<2:08:32, 16.30s/it]  6%|▌         | 28/500 [07:58<2:07:25, 16.20s/it]  6%|▌         | 29/500 [08:14<2:06:16, 16.08s/it]  6%|▌         | 30/500 [08:31<2:08:50, 16.45s/it]  6%|▌         | 31/500 [08:48<2:07:49, 16.35s/it]  6%|▋         | 32/500 [09:03<2:05:35, 16.10s/it]  7%|▋         | 33/500 [09:19<2:05:10, 16.08s/it]  7%|▋         | 34/500 [09:35<2:04:49, 16.07s/it]  7%|▋         | 35/500 [09:51<2:04:11, 16.03s/it]  7%|▋         | 36/500 [10:07<2:03:34, 15.98s/it]  7%|▋         | 37/500 [10:22<2:01:48, 15.79s/it]  7%|▋         | 37/500 [10:22<2:09:53, 16.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.294 MB of 0.313 MB uploadedwandb: / 0.294 MB of 0.313 MB uploadedwandb: - 0.294 MB of 0.313 MB uploadedwandb: \ 0.294 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▆▂▆▂▄▁▁▂▂▃▂▅▄▂▂▄▇▆▆▅█▄▇▆▇▆▇▇▆██▇▇▆▇▇
wandb:     train_loss ▂▃▃▂▄▂▅▅▂▂▄█▂▅▂▁▅▁▁▁▁▁▂▇▂▂▃▁▁▃▁▁▂▃▁▁▂
wandb:   val_accuracy ▃█▂▇▁▄▂▃▂▂▄▂▅▅▄▃▄▇▆▆▆▇▅▆▆▇▆▆▇▆▇▇▇▆▆▇▇
wandb:       val_loss ▃▃▄▂▃▃▂█▄▃▂█▅▂▃▅▂▂▁▃▁▁▄▁▂▂▁▁▃▅▃▄▃▇▃▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.80832
wandb:     train_loss 0.60743
wandb:   val_accuracy 0.59556
wandb:       val_loss 0.71102
wandb: 
wandb: 🚀 View run vital-totem-60 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/av552v8z
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_053020-av552v8z/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_054237-tva64nom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-elevator-61
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tva64nom
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:23:47, 31.72s/it]  0%|          | 2/500 [00:56<3:50:54, 27.82s/it]  1%|          | 3/500 [01:23<3:45:10, 27.18s/it]  1%|          | 4/500 [01:46<3:33:23, 25.81s/it]  1%|          | 5/500 [02:10<3:25:33, 24.92s/it]  1%|          | 6/500 [02:34<3:22:42, 24.62s/it]  1%|▏         | 7/500 [02:58<3:20:47, 24.44s/it]  2%|▏         | 8/500 [03:22<3:20:11, 24.41s/it]  2%|▏         | 9/500 [03:46<3:17:41, 24.16s/it]  2%|▏         | 10/500 [04:09<3:15:29, 23.94s/it]  2%|▏         | 11/500 [04:37<3:24:17, 25.07s/it]  2%|▏         | 12/500 [05:01<3:21:20, 24.76s/it]  3%|▎         | 13/500 [05:24<3:17:26, 24.33s/it]  3%|▎         | 14/500 [05:48<3:14:39, 24.03s/it]  3%|▎         | 15/500 [06:11<3:12:38, 23.83s/it]  3%|▎         | 16/500 [06:34<3:11:18, 23.72s/it]  3%|▎         | 17/500 [06:59<3:12:22, 23.90s/it]  4%|▎         | 18/500 [07:22<3:11:09, 23.80s/it]  4%|▍         | 19/500 [07:46<3:10:20, 23.74s/it]  4%|▍         | 20/500 [08:10<3:11:47, 23.97s/it]  4%|▍         | 21/500 [08:35<3:12:59, 24.17s/it]  4%|▍         | 22/500 [09:03<3:22:02, 25.36s/it]  5%|▍         | 23/500 [09:29<3:21:43, 25.38s/it]  5%|▍         | 24/500 [09:54<3:20:54, 25.33s/it]  5%|▌         | 25/500 [10:19<3:19:19, 25.18s/it]  5%|▌         | 26/500 [10:46<3:23:49, 25.80s/it]  5%|▌         | 27/500 [11:09<3:17:40, 25.07s/it]  6%|▌         | 28/500 [11:34<3:15:13, 24.82s/it]  6%|▌         | 29/500 [12:03<3:25:01, 26.12s/it]  6%|▌         | 30/500 [12:27<3:19:36, 25.48s/it]  6%|▌         | 31/500 [12:50<3:14:48, 24.92s/it]  6%|▋         | 32/500 [13:14<3:11:07, 24.50s/it]  7%|▋         | 33/500 [13:38<3:10:17, 24.45s/it]  7%|▋         | 34/500 [14:03<3:11:57, 24.72s/it]  7%|▋         | 35/500 [14:28<3:10:11, 24.54s/it]  7%|▋         | 36/500 [14:57<3:19:57, 25.86s/it]  7%|▋         | 37/500 [15:20<3:13:27, 25.07s/it]  8%|▊         | 38/500 [15:45<3:12:39, 25.02s/it]  8%|▊         | 39/500 [16:08<3:07:43, 24.43s/it]  8%|▊         | 40/500 [16:31<3:05:11, 24.16s/it]  8%|▊         | 40/500 [16:31<3:10:05, 24.79s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.310 MB uploadedwandb: \ 0.010 MB of 0.310 MB uploadedwandb: | 0.301 MB of 0.310 MB uploadedwandb: / 0.301 MB of 0.310 MB uploadedwandb: - 0.301 MB of 0.310 MB uploadedwandb: \ 0.304 MB of 0.310 MB uploadedwandb: | 0.304 MB of 0.310 MB uploadedwandb: / 0.304 MB of 0.310 MB uploadedwandb: - 0.304 MB of 0.310 MB uploadedwandb: \ 0.304 MB of 0.310 MB uploadedwandb: | 0.305 MB of 0.310 MB uploadedwandb: / 0.305 MB of 0.310 MB uploadedwandb: - 0.305 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▇▁▂▁▇▄▇▄▇██▇██▆▇██████████████████████
wandb:     train_loss ▂▁▁▃▂█▁▆▁▄▁▁▁▁▁▁▁▁▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▃▇▃▄▂█▆▆▆█▇▇██▇▆██▇▇▇▇▆▆▇█▆▇█▇▆▆▆▆█▇▇▆▇
wandb:       val_loss ▂▂▁▂▂▃▁▁▁▄▁▁▁▁▁▃▃▁▁▁▁▁▁▁█▁▁▂▂▁▂▁▁▄▇▁▁▁▃▃
wandb: 
wandb: Run summary:
wandb:          epoch 39
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99554
wandb:     train_loss 0.00977
wandb:   val_accuracy 0.77111
wandb:       val_loss 1.80221
wandb: 
wandb: 🚀 View run easy-elevator-61 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tva64nom
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_054237-tva64nom/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_060017-lysjyoan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-plasma-62
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lysjyoan
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:39:37, 26.41s/it]  0%|          | 2/500 [00:50<3:29:50, 25.28s/it]  1%|          | 3/500 [01:17<3:33:10, 25.74s/it]  1%|          | 4/500 [01:41<3:28:16, 25.19s/it]  1%|          | 5/500 [02:10<3:39:48, 26.64s/it]  1%|          | 6/500 [02:35<3:32:42, 25.84s/it]  1%|▏         | 7/500 [02:59<3:28:18, 25.35s/it]  2%|▏         | 8/500 [03:22<3:22:44, 24.73s/it]  2%|▏         | 9/500 [03:46<3:19:31, 24.38s/it]  2%|▏         | 10/500 [04:10<3:17:12, 24.15s/it]  2%|▏         | 11/500 [04:33<3:14:35, 23.88s/it]  2%|▏         | 12/500 [04:57<3:16:06, 24.11s/it]  3%|▎         | 13/500 [05:21<3:14:57, 24.02s/it]  3%|▎         | 14/500 [05:45<3:12:44, 23.80s/it]  3%|▎         | 15/500 [06:08<3:10:26, 23.56s/it]  3%|▎         | 16/500 [06:31<3:09:23, 23.48s/it]  3%|▎         | 17/500 [06:54<3:07:43, 23.32s/it]  4%|▎         | 18/500 [07:17<3:07:51, 23.38s/it]  4%|▍         | 19/500 [07:40<3:06:18, 23.24s/it]  4%|▍         | 20/500 [08:03<3:05:35, 23.20s/it]  4%|▍         | 21/500 [08:26<3:04:14, 23.08s/it]  4%|▍         | 22/500 [08:50<3:05:22, 23.27s/it]  5%|▍         | 23/500 [09:13<3:04:34, 23.22s/it]  5%|▍         | 24/500 [09:36<3:04:11, 23.22s/it]  5%|▌         | 25/500 [09:59<3:03:55, 23.23s/it]  5%|▌         | 26/500 [10:22<3:02:02, 23.04s/it]  5%|▌         | 27/500 [10:45<3:00:34, 22.91s/it]  6%|▌         | 28/500 [11:08<3:00:48, 22.98s/it]  6%|▌         | 29/500 [11:31<3:00:10, 22.95s/it]  6%|▌         | 30/500 [11:53<2:58:50, 22.83s/it]  6%|▌         | 31/500 [12:16<2:58:30, 22.84s/it]  6%|▋         | 32/500 [12:39<2:57:40, 22.78s/it]  7%|▋         | 33/500 [13:01<2:57:18, 22.78s/it]  7%|▋         | 34/500 [13:25<2:58:10, 22.94s/it]  7%|▋         | 35/500 [13:51<3:05:22, 23.92s/it]  7%|▋         | 36/500 [14:14<3:02:48, 23.64s/it]  7%|▋         | 37/500 [14:37<3:00:34, 23.40s/it]  8%|▊         | 38/500 [15:00<2:59:44, 23.34s/it]  8%|▊         | 39/500 [15:23<2:59:41, 23.39s/it]  8%|▊         | 40/500 [15:46<2:58:20, 23.26s/it]  8%|▊         | 40/500 [15:46<3:01:30, 23.67s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.138 MB of 0.315 MB uploadedwandb: \ 0.138 MB of 0.315 MB uploadedwandb: | 0.138 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▄▅▆▆▇▆▆▇▇▇▇▇▇▇▇██████████████████████
wandb:     train_loss ▆▆█▇▇▇▃▃▄▂▆▄▇▃▂▃▁▁▃▂▁▂▂▃▂▂▂▂▁▃▃▂▂▃▂▃▁▂▁▃
wandb:   val_accuracy ▁▁▁▅▇▇▇▅▄▅▆▅▆▆▇▆▆▆▇▆▇▇▇▆▆█▇▆███▇▇▇▇██▇▇▇
wandb:       val_loss ▇▆▇▅▄█▄▃▃█▃▂▅▇▄▂▆▆▄▄▂▄▂▁▇▇▂▄▆▃▄▅▄▃▆▄▇▂▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 39
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.94502
wandb:     train_loss 0.4009
wandb:   val_accuracy 0.7
wandb:       val_loss 0.68722
wandb: 
wandb: 🚀 View run noble-plasma-62 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lysjyoan
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_060017-lysjyoan/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_061655-3uy46pcx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-shadow-63
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/3uy46pcx
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:31:48, 25.47s/it]  0%|          | 2/500 [00:48<3:20:19, 24.14s/it]  1%|          | 3/500 [01:18<3:39:58, 26.56s/it]  1%|          | 4/500 [01:47<3:48:55, 27.69s/it]  1%|          | 5/500 [02:11<3:37:29, 26.36s/it]  1%|          | 6/500 [02:35<3:29:20, 25.43s/it]  1%|▏         | 7/500 [03:03<3:37:27, 26.47s/it]  2%|▏         | 8/500 [03:27<3:30:07, 25.62s/it]  2%|▏         | 9/500 [03:56<3:37:39, 26.60s/it]  2%|▏         | 10/500 [04:19<3:29:46, 25.69s/it]  2%|▏         | 11/500 [04:43<3:24:52, 25.14s/it]  2%|▏         | 12/500 [05:07<3:20:22, 24.64s/it]  3%|▎         | 13/500 [05:30<3:16:48, 24.25s/it]  3%|▎         | 14/500 [05:54<3:14:52, 24.06s/it]  3%|▎         | 15/500 [06:17<3:12:21, 23.80s/it]  3%|▎         | 16/500 [06:40<3:10:26, 23.61s/it]  3%|▎         | 17/500 [07:04<3:09:55, 23.59s/it]  4%|▎         | 18/500 [07:27<3:08:49, 23.50s/it]  4%|▍         | 19/500 [07:50<3:08:01, 23.46s/it]  4%|▍         | 20/500 [08:14<3:07:31, 23.44s/it]  4%|▍         | 21/500 [08:42<3:19:22, 24.97s/it]  4%|▍         | 22/500 [09:11<3:28:06, 26.12s/it]  5%|▍         | 23/500 [09:43<3:40:09, 27.69s/it]  5%|▍         | 24/500 [10:06<3:29:47, 26.44s/it]  5%|▌         | 25/500 [10:34<3:33:23, 26.95s/it]  5%|▌         | 26/500 [11:03<3:36:21, 27.39s/it]  5%|▌         | 27/500 [11:31<3:39:02, 27.78s/it]  6%|▌         | 28/500 [11:59<3:38:47, 27.81s/it]  6%|▌         | 29/500 [12:22<3:27:35, 26.44s/it]  6%|▌         | 30/500 [12:46<3:19:59, 25.53s/it]  6%|▌         | 31/500 [13:09<3:14:30, 24.88s/it]  6%|▋         | 32/500 [13:33<3:11:26, 24.54s/it]  7%|▋         | 33/500 [13:58<3:12:20, 24.71s/it]  7%|▋         | 34/500 [14:22<3:09:28, 24.40s/it]  7%|▋         | 35/500 [14:51<3:20:12, 25.83s/it]  7%|▋         | 36/500 [15:14<3:13:56, 25.08s/it]  7%|▋         | 37/500 [15:43<3:22:33, 26.25s/it]  8%|▊         | 38/500 [16:11<3:26:40, 26.84s/it]  8%|▊         | 39/500 [16:40<3:30:26, 27.39s/it]  8%|▊         | 39/500 [16:47<3:18:28, 25.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.010 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▃▆▂▄▆▆█▆▇▇▇▆▇█▇▇▆███████████████████
wandb:     train_loss ▃▁▂▃▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▄▅▇▅▆▇█▇▇█████▇██▆███▇▇██▇███▇▇█▇██▇▇
wandb:       val_loss ▄▅▃▂▁▃▁▂▁▂▁▁▄▂▁▁█▁▂▄▁▁▁▁▅▁▁▁▃▂▁▁▁▂▄▁▁▁▄
wandb: 
wandb: Run summary:
wandb:          epoch 38
wandb:  learning_rate 6e-05
wandb: train_accuracy 1.0
wandb:     train_loss 0.0
wandb:   val_accuracy 0.77778
wandb:       val_loss 1.10552
wandb: 
wandb: 🚀 View run zesty-shadow-63 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/3uy46pcx
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_061655-3uy46pcx/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_063439-89c7muxp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-tree-64
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/89c7muxp
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:40:10, 26.47s/it]  0%|          | 2/500 [00:50<3:28:53, 25.17s/it]  1%|          | 3/500 [01:14<3:24:33, 24.69s/it]  1%|          | 4/500 [01:41<3:30:53, 25.51s/it]  1%|          | 5/500 [02:14<3:50:58, 28.00s/it]  1%|          | 6/500 [02:38<3:40:18, 26.76s/it]  1%|▏         | 7/500 [03:02<3:33:06, 25.94s/it]  2%|▏         | 8/500 [03:26<3:26:33, 25.19s/it]  2%|▏         | 9/500 [03:54<3:35:00, 26.27s/it]  2%|▏         | 10/500 [04:27<3:51:12, 28.31s/it]  2%|▏         | 11/500 [04:54<3:47:49, 27.95s/it]  2%|▏         | 12/500 [05:24<3:50:17, 28.32s/it]  3%|▎         | 13/500 [05:51<3:47:04, 27.98s/it]  3%|▎         | 14/500 [06:20<3:49:10, 28.29s/it]  3%|▎         | 15/500 [06:44<3:38:17, 27.00s/it]  3%|▎         | 16/500 [07:08<3:30:44, 26.12s/it]  3%|▎         | 17/500 [07:32<3:25:22, 25.51s/it]  4%|▎         | 18/500 [08:01<3:33:50, 26.62s/it]  4%|▍         | 19/500 [08:25<3:27:23, 25.87s/it]  4%|▍         | 20/500 [08:49<3:22:13, 25.28s/it]  4%|▍         | 21/500 [09:14<3:20:14, 25.08s/it]  4%|▍         | 22/500 [09:38<3:17:18, 24.77s/it]  5%|▍         | 23/500 [10:02<3:14:55, 24.52s/it]  5%|▍         | 24/500 [10:26<3:13:39, 24.41s/it]  5%|▌         | 25/500 [10:50<3:12:51, 24.36s/it]  5%|▌         | 26/500 [11:14<3:11:20, 24.22s/it]  5%|▌         | 27/500 [11:46<3:28:22, 26.43s/it]  6%|▌         | 28/500 [12:09<3:21:44, 25.64s/it]  6%|▌         | 29/500 [12:34<3:18:10, 25.25s/it]  6%|▌         | 30/500 [13:02<3:25:45, 26.27s/it]  6%|▌         | 31/500 [13:27<3:20:13, 25.61s/it]  6%|▋         | 32/500 [13:51<3:16:54, 25.24s/it]  7%|▋         | 33/500 [14:15<3:13:41, 24.88s/it]  7%|▋         | 34/500 [14:39<3:10:59, 24.59s/it]  7%|▋         | 35/500 [15:03<3:08:55, 24.38s/it]  7%|▋         | 36/500 [15:27<3:07:33, 24.25s/it]  7%|▋         | 37/500 [15:51<3:07:06, 24.25s/it]  8%|▊         | 38/500 [16:23<3:24:48, 26.60s/it]  8%|▊         | 39/500 [16:47<3:18:54, 25.89s/it]  8%|▊         | 40/500 [17:11<3:13:57, 25.30s/it]  8%|▊         | 41/500 [17:41<3:23:18, 26.58s/it]  8%|▊         | 42/500 [18:10<3:29:12, 27.41s/it]  9%|▊         | 43/500 [18:34<3:21:13, 26.42s/it]  9%|▉         | 44/500 [19:05<3:31:14, 27.80s/it]  9%|▉         | 45/500 [19:39<3:43:55, 29.53s/it]  9%|▉         | 46/500 [20:03<3:31:36, 27.97s/it]  9%|▉         | 47/500 [20:26<3:20:25, 26.55s/it] 10%|▉         | 48/500 [20:50<3:13:46, 25.72s/it] 10%|▉         | 49/500 [21:15<3:11:08, 25.43s/it] 10%|█         | 50/500 [21:39<3:08:03, 25.08s/it] 10%|█         | 51/500 [22:03<3:05:20, 24.77s/it] 10%|█         | 52/500 [22:34<3:19:32, 26.72s/it] 11%|█         | 53/500 [22:58<3:12:54, 25.89s/it] 11%|█         | 54/500 [23:27<3:18:34, 26.71s/it] 11%|█         | 55/500 [23:58<3:27:54, 28.03s/it] 11%|█         | 56/500 [24:30<3:34:56, 29.05s/it] 11%|█▏        | 57/500 [24:54<3:23:28, 27.56s/it] 12%|█▏        | 58/500 [25:23<3:27:54, 28.22s/it] 12%|█▏        | 59/500 [25:53<3:30:34, 28.65s/it] 12%|█▏        | 60/500 [26:23<3:32:20, 28.96s/it] 12%|█▏        | 61/500 [26:47<3:21:20, 27.52s/it] 12%|█▏        | 62/500 [27:11<3:13:05, 26.45s/it] 13%|█▎        | 63/500 [27:35<3:07:04, 25.68s/it] 13%|█▎        | 64/500 [27:59<3:02:31, 25.12s/it] 13%|█▎        | 65/500 [28:22<2:59:28, 24.76s/it] 13%|█▎        | 66/500 [28:46<2:56:54, 24.46s/it] 13%|█▎        | 67/500 [29:10<2:55:18, 24.29s/it] 14%|█▎        | 68/500 [29:42<3:12:07, 26.68s/it] 14%|█▍        | 69/500 [30:06<3:05:45, 25.86s/it] 14%|█▍        | 70/500 [30:30<3:01:33, 25.33s/it] 14%|█▍        | 71/500 [30:54<2:58:04, 24.91s/it] 14%|█▍        | 72/500 [31:23<3:06:19, 26.12s/it] 15%|█▍        | 73/500 [31:53<3:12:39, 27.07s/it] 15%|█▍        | 74/500 [32:22<3:17:00, 27.75s/it] 15%|█▌        | 75/500 [32:46<3:08:56, 26.68s/it] 15%|█▌        | 76/500 [33:10<3:02:36, 25.84s/it] 15%|█▌        | 77/500 [33:34<2:59:10, 25.42s/it] 16%|█▌        | 78/500 [33:59<2:56:33, 25.10s/it] 16%|█▌        | 79/500 [34:23<2:54:20, 24.85s/it] 16%|█▌        | 80/500 [34:47<2:52:29, 24.64s/it] 16%|█▌        | 81/500 [35:11<2:50:55, 24.48s/it] 16%|█▋        | 82/500 [35:40<3:00:20, 25.89s/it] 17%|█▋        | 83/500 [36:10<3:06:51, 26.89s/it] 17%|█▋        | 84/500 [36:34<3:00:13, 25.99s/it] 17%|█▋        | 85/500 [36:58<2:56:19, 25.49s/it] 17%|█▋        | 86/500 [37:22<2:52:52, 25.05s/it] 17%|█▋        | 87/500 [37:46<2:50:26, 24.76s/it] 18%|█▊        | 88/500 [38:10<2:48:16, 24.51s/it] 18%|█▊        | 89/500 [38:39<2:57:37, 25.93s/it] 18%|█▊        | 90/500 [39:03<2:53:15, 25.35s/it] 18%|█▊        | 91/500 [39:27<2:49:41, 24.89s/it] 18%|█▊        | 91/500 [39:32<2:57:43, 26.07s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.019 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████
wandb:  learning_rate ████▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▄▃▇▆▄▇▆█▇█▇██▇▆██████████████████████
wandb:     train_loss ▄▅▁▁█▁▁▁▃▁▁▄▃▁▁▁▃▁▁▁▃▁▁▃▁▁▃▁▁▃▃▁▃▁▁▃▁▁▁▁
wandb:   val_accuracy ▁▂▃▂▃▇▆▅▇▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▆▇▇▇▇█▇▇▇▇▇▇▇▇▇█
wandb:       val_loss ▄▅▂▅█▃▄▃▃▂▂▂▂▁▂▂▂▅▄▅▂▂▄▂▃▂▃▃▂▄▃▄▂▆▇▃▂▂▂▃
wandb: 
wandb: Run summary:
wandb:          epoch 90
wandb:  learning_rate 0.0
wandb: train_accuracy 0.67756
wandb:     train_loss 1.09861
wandb:   val_accuracy 0.54889
wandb:       val_loss 0.65327
wandb: 
wandb: 🚀 View run still-tree-64 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/89c7muxp
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_063439-89c7muxp/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_071454-0cwvke6q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-waterfall-65
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/0cwvke6q
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:44:30, 26.99s/it]  0%|          | 2/500 [00:52<3:35:50, 26.01s/it]  1%|          | 3/500 [01:16<3:27:56, 25.10s/it]  1%|          | 4/500 [01:41<3:27:53, 25.15s/it]  1%|          | 5/500 [02:06<3:28:06, 25.22s/it]  1%|          | 6/500 [02:32<3:27:51, 25.25s/it]  1%|▏         | 7/500 [03:07<3:53:40, 28.44s/it]  2%|▏         | 8/500 [03:32<3:45:06, 27.45s/it]  2%|▏         | 9/500 [03:57<3:38:01, 26.64s/it]  2%|▏         | 10/500 [04:22<3:33:59, 26.20s/it]  2%|▏         | 11/500 [04:51<3:41:17, 27.15s/it]  2%|▏         | 12/500 [05:17<3:35:51, 26.54s/it]  3%|▎         | 13/500 [05:41<3:30:05, 25.88s/it]  3%|▎         | 14/500 [06:05<3:24:58, 25.31s/it]  3%|▎         | 15/500 [06:33<3:30:08, 26.00s/it]  3%|▎         | 16/500 [06:56<3:23:55, 25.28s/it]  3%|▎         | 17/500 [07:20<3:19:59, 24.84s/it]  4%|▎         | 18/500 [07:49<3:29:06, 26.03s/it]  4%|▍         | 19/500 [08:18<3:35:44, 26.91s/it]  4%|▍         | 20/500 [08:41<3:26:54, 25.86s/it]  4%|▍         | 21/500 [09:10<3:33:08, 26.70s/it]  4%|▍         | 22/500 [09:38<3:37:23, 27.29s/it]  5%|▍         | 23/500 [10:07<3:39:53, 27.66s/it]  5%|▍         | 24/500 [10:30<3:29:14, 26.38s/it]  5%|▍         | 24/500 [10:30<3:28:32, 26.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.312 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.168 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▄▂▃▇▇██▃▂▁▁▁▁▂▃▃▄▆▆▆▆▆▆
wandb:     train_loss ▄▅▆▇▆▆▂▃█▄▁▃▁▅▅█▅▄▃▄▄▂▅▄
wandb:   val_accuracy ▄▅▃▄██▇▇▃▂▁▁▁▁▂▂▃▃▄▅▅▅▅▅
wandb:       val_loss ▄▅▄▂▂▃▂▁▂▄▆▇▃▆▄▃▁█▅▅▄▅▅▃
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.64487
wandb:     train_loss 0.94889
wandb:   val_accuracy 0.42667
wandb:       val_loss 0.88551
wandb: 
wandb: 🚀 View run prime-waterfall-65 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/0cwvke6q
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_071454-0cwvke6q/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_072605-10csrz2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-puddle-66
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/10csrz2k
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:37:34, 26.16s/it]  0%|          | 2/500 [00:50<3:26:03, 24.83s/it]  1%|          | 3/500 [01:14<3:25:22, 24.79s/it]  1%|          | 4/500 [01:51<4:04:31, 29.58s/it]  1%|          | 5/500 [02:21<4:03:11, 29.48s/it]  1%|          | 6/500 [02:45<3:48:31, 27.76s/it]  1%|▏         | 7/500 [03:14<3:51:21, 28.16s/it]  2%|▏         | 8/500 [03:43<3:54:04, 28.55s/it]  2%|▏         | 9/500 [04:21<4:16:12, 31.31s/it]  2%|▏         | 10/500 [04:45<3:58:02, 29.15s/it]  2%|▏         | 11/500 [05:09<3:44:46, 27.58s/it]  2%|▏         | 12/500 [05:38<3:47:54, 28.02s/it]  3%|▎         | 13/500 [06:02<3:38:37, 26.94s/it]  3%|▎         | 14/500 [06:26<3:29:32, 25.87s/it]  3%|▎         | 15/500 [06:50<3:25:04, 25.37s/it]  3%|▎         | 16/500 [07:14<3:21:59, 25.04s/it]  3%|▎         | 17/500 [07:39<3:20:12, 24.87s/it]  4%|▎         | 18/500 [08:08<3:30:09, 26.16s/it]  4%|▍         | 19/500 [08:37<3:36:29, 27.01s/it]  4%|▍         | 20/500 [09:06<3:41:11, 27.65s/it]  4%|▍         | 21/500 [09:36<3:45:49, 28.29s/it]  4%|▍         | 22/500 [10:08<3:55:33, 29.57s/it]  5%|▍         | 23/500 [10:33<3:43:34, 28.12s/it]  5%|▍         | 24/500 [11:05<3:52:27, 29.30s/it]  5%|▌         | 25/500 [11:35<3:53:43, 29.52s/it]  5%|▌         | 25/500 [11:40<3:41:58, 28.04s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.309 MB uploadedwandb: / 0.019 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▅▅▄▁▁▂█▇▇██▇▇████████
wandb:     train_loss ▂▂▂▂▂▂▂▂█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▂▁▁▁▃▃▃▂▂▃▇▆▆▆█▆▆▇▇▇▇▆▆▇▆
wandb:       val_loss ▃▂▃▄▂▂▂▅▁▆▁▁█▇▁▂▆▁▃▂▁▁▁▁▆
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.9792
wandb:     train_loss 0.02722
wandb:   val_accuracy 0.65111
wandb:       val_loss 3.40959
wandb: 
wandb: 🚀 View run dauntless-puddle-66 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/10csrz2k
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_072605-10csrz2k/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_073842-8ki32ijs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-wind-67
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8ki32ijs
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:34:34, 25.80s/it]  0%|          | 2/500 [00:49<3:23:56, 24.57s/it]  1%|          | 3/500 [01:16<3:33:05, 25.73s/it]  1%|          | 4/500 [01:40<3:28:04, 25.17s/it]  1%|          | 5/500 [02:13<3:49:55, 27.87s/it]  1%|          | 6/500 [02:37<3:38:17, 26.51s/it]  1%|▏         | 7/500 [03:06<3:45:28, 27.44s/it]  2%|▏         | 8/500 [03:35<3:49:01, 27.93s/it]  2%|▏         | 9/500 [04:05<3:53:13, 28.50s/it]  2%|▏         | 10/500 [04:30<3:42:34, 27.25s/it]  2%|▏         | 11/500 [04:54<3:34:37, 26.33s/it]  2%|▏         | 12/500 [05:18<3:29:19, 25.74s/it]  3%|▎         | 13/500 [05:42<3:25:20, 25.30s/it]  3%|▎         | 14/500 [06:07<3:24:18, 25.22s/it]  3%|▎         | 15/500 [06:38<3:35:54, 26.71s/it]  3%|▎         | 16/500 [07:07<3:41:28, 27.45s/it]  3%|▎         | 17/500 [07:31<3:33:02, 26.47s/it]  4%|▎         | 18/500 [07:55<3:27:23, 25.82s/it]  4%|▍         | 19/500 [08:20<3:25:00, 25.57s/it]  4%|▍         | 20/500 [08:45<3:23:15, 25.41s/it]  4%|▍         | 21/500 [09:13<3:27:15, 25.96s/it]  4%|▍         | 22/500 [09:38<3:25:36, 25.81s/it]  5%|▍         | 23/500 [10:02<3:21:53, 25.40s/it]  5%|▍         | 24/500 [10:27<3:18:20, 25.00s/it]  5%|▌         | 25/500 [10:51<3:17:12, 24.91s/it]  5%|▌         | 26/500 [11:16<3:16:05, 24.82s/it]  5%|▌         | 27/500 [11:40<3:13:25, 24.54s/it]  6%|▌         | 28/500 [12:08<3:21:56, 25.67s/it]  6%|▌         | 29/500 [12:32<3:18:31, 25.29s/it]  6%|▌         | 30/500 [12:57<3:16:32, 25.09s/it]  6%|▌         | 31/500 [13:25<3:23:28, 26.03s/it]  6%|▋         | 32/500 [13:50<3:18:52, 25.50s/it]  7%|▋         | 33/500 [14:13<3:14:40, 25.01s/it]  7%|▋         | 34/500 [14:38<3:14:06, 24.99s/it]  7%|▋         | 35/500 [15:03<3:13:01, 24.91s/it]  7%|▋         | 36/500 [15:33<3:23:36, 26.33s/it]  7%|▋         | 37/500 [16:02<3:30:54, 27.33s/it]  8%|▊         | 38/500 [16:33<3:37:10, 28.20s/it]  8%|▊         | 39/500 [17:01<3:37:44, 28.34s/it]  8%|▊         | 40/500 [17:25<3:27:07, 27.02s/it]  8%|▊         | 41/500 [17:54<3:31:32, 27.65s/it]  8%|▊         | 42/500 [18:18<3:22:15, 26.50s/it]  9%|▊         | 43/500 [18:47<3:27:11, 27.20s/it]  9%|▉         | 44/500 [19:11<3:19:38, 26.27s/it]  9%|▉         | 44/500 [19:16<3:19:46, 26.29s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.308 MB uploadedwandb: / 0.010 MB of 0.308 MB uploadedwandb: - 0.308 MB of 0.308 MB uploadedwandb: \ 0.308 MB of 0.308 MB uploadedwandb: | 0.308 MB of 0.308 MB uploadedwandb: / 0.308 MB of 0.308 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▃▄▇▂█▇█▇█▇▇▇██▆▇▅███████▆▇████▇▇████▇█
wandb:     train_loss ▂▂▂▄▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▃▅▇▄▇▇▇▅▇███▇▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       val_loss ▂▃▂▄▁▄▁▂▁▄▁▅▃▁▁█▃▄▂▂▁▁▄▁▂▁▁▁▂▁▁▄▂▂▃▂▂▅▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 43
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99703
wandb:     train_loss 0.00994
wandb:   val_accuracy 0.68444
wandb:       val_loss 1.01598
wandb: 
wandb: 🚀 View run clean-wind-67 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8ki32ijs
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_073842-8ki32ijs/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_075838-wdca0cqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-lion-68
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wdca0cqc
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:30:30, 25.31s/it]  0%|          | 2/500 [00:49<3:22:15, 24.37s/it]  1%|          | 3/500 [01:15<3:29:01, 25.23s/it]  1%|          | 4/500 [01:47<3:52:36, 28.14s/it]  1%|          | 5/500 [02:11<3:39:54, 26.66s/it]  1%|          | 6/500 [02:35<3:30:51, 25.61s/it]  1%|▏         | 7/500 [03:04<3:39:16, 26.69s/it]  2%|▏         | 8/500 [03:28<3:31:40, 25.81s/it]  2%|▏         | 9/500 [03:52<3:26:10, 25.19s/it]  2%|▏         | 10/500 [04:15<3:21:49, 24.71s/it]  2%|▏         | 11/500 [04:39<3:18:51, 24.40s/it]  2%|▏         | 12/500 [05:03<3:17:09, 24.24s/it]  3%|▎         | 13/500 [05:27<3:15:34, 24.10s/it]  3%|▎         | 14/500 [05:50<3:13:49, 23.93s/it]  3%|▎         | 15/500 [06:14<3:13:12, 23.90s/it]  3%|▎         | 16/500 [06:37<3:11:36, 23.75s/it]  3%|▎         | 17/500 [07:01<3:10:31, 23.67s/it]  4%|▎         | 18/500 [07:25<3:10:23, 23.70s/it]  4%|▍         | 19/500 [07:48<3:10:01, 23.70s/it]  4%|▍         | 20/500 [08:15<3:16:26, 24.55s/it]  4%|▍         | 21/500 [08:39<3:14:48, 24.40s/it]  4%|▍         | 22/500 [09:02<3:11:35, 24.05s/it]  5%|▍         | 23/500 [09:26<3:11:24, 24.08s/it]  5%|▍         | 24/500 [09:56<3:23:22, 25.63s/it]  5%|▌         | 25/500 [10:20<3:19:03, 25.14s/it]  5%|▌         | 26/500 [10:43<3:15:09, 24.70s/it]  5%|▌         | 27/500 [11:13<3:26:09, 26.15s/it]  6%|▌         | 28/500 [11:36<3:19:26, 25.35s/it]  6%|▌         | 29/500 [12:06<3:28:49, 26.60s/it]  6%|▌         | 30/500 [12:30<3:21:39, 25.74s/it]  6%|▌         | 31/500 [12:58<3:27:12, 26.51s/it]  6%|▋         | 32/500 [13:26<3:29:28, 26.86s/it]  7%|▋         | 33/500 [13:54<3:32:37, 27.32s/it]  7%|▋         | 34/500 [14:22<3:35:04, 27.69s/it]  7%|▋         | 35/500 [14:51<3:37:02, 28.01s/it]  7%|▋         | 36/500 [15:15<3:26:33, 26.71s/it]  7%|▋         | 37/500 [15:38<3:18:44, 25.75s/it]  8%|▊         | 38/500 [16:02<3:13:08, 25.08s/it]  8%|▊         | 39/500 [16:26<3:10:30, 24.80s/it]  8%|▊         | 40/500 [16:50<3:08:07, 24.54s/it]  8%|▊         | 40/500 [16:55<3:14:41, 25.40s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.019 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▂▄▆▆▆▇▇▇▇▇▇▇█▇▇▇██████████████████████
wandb:     train_loss ▆▇▇▇▇█▃▂▃▃▃▃▃▂▂▅▁▃▅▂▁▂▂▆▆▃▂▃▁▄▂▂█▂▂▅▂▁▁▄
wandb:   val_accuracy ▁▃▁▅██▆▇▆▅▇▆▇▆▇▆▆▆▇▅▆▆▆▅▅▆▅▆▆▆▆▅▆▆▅▆▆▅▆▆
wandb:       val_loss ▂▂▂▂▁▁▁▁▁▂▁▁▄▂▁▁▂▂▄▄▁▂▁▁▂▂▂▂▂▂▁▁█▁▂▄▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 39
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.95542
wandb:     train_loss 0.53975
wandb:   val_accuracy 0.61778
wandb:       val_loss 0.59225
wandb: 
wandb: 🚀 View run solar-lion-68 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wdca0cqc
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_075838-wdca0cqc/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_081617-6xskj56u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-dragon-69
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6xskj56u
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:29<4:01:28, 29.04s/it]  0%|          | 2/500 [00:52<3:31:52, 25.53s/it]  1%|          | 3/500 [01:15<3:23:26, 24.56s/it]  1%|          | 4/500 [01:38<3:18:01, 23.95s/it]  1%|          | 5/500 [02:01<3:14:52, 23.62s/it]  1%|          | 6/500 [02:29<3:27:34, 25.21s/it]  1%|▏         | 7/500 [02:53<3:22:08, 24.60s/it]  2%|▏         | 8/500 [03:16<3:17:55, 24.14s/it]  2%|▏         | 9/500 [03:49<3:41:30, 27.07s/it]  2%|▏         | 10/500 [04:12<3:30:48, 25.81s/it]  2%|▏         | 11/500 [04:35<3:23:03, 24.91s/it]  2%|▏         | 12/500 [04:58<3:18:03, 24.35s/it]  3%|▎         | 13/500 [05:21<3:14:34, 23.97s/it]  3%|▎         | 14/500 [05:48<3:20:42, 24.78s/it]  3%|▎         | 15/500 [06:11<3:16:07, 24.26s/it]  3%|▎         | 16/500 [06:34<3:12:23, 23.85s/it]  3%|▎         | 17/500 [06:57<3:09:13, 23.51s/it]  4%|▎         | 18/500 [07:19<3:07:01, 23.28s/it]  4%|▍         | 19/500 [07:42<3:05:48, 23.18s/it]  4%|▍         | 20/500 [08:06<3:05:47, 23.22s/it]  4%|▍         | 21/500 [08:29<3:05:48, 23.28s/it]  4%|▍         | 22/500 [08:57<3:16:48, 24.70s/it]  5%|▍         | 23/500 [09:20<3:12:21, 24.20s/it]  5%|▍         | 24/500 [09:43<3:08:08, 23.71s/it]  5%|▌         | 25/500 [10:06<3:06:00, 23.50s/it]  5%|▌         | 26/500 [10:29<3:04:14, 23.32s/it]  5%|▌         | 27/500 [10:56<3:13:57, 24.60s/it]  6%|▌         | 28/500 [11:24<3:21:36, 25.63s/it]  6%|▌         | 29/500 [11:53<3:28:48, 26.60s/it]  6%|▌         | 30/500 [12:21<3:31:56, 27.06s/it]  6%|▌         | 31/500 [12:49<3:32:27, 27.18s/it]  6%|▋         | 32/500 [13:12<3:21:39, 25.85s/it]  7%|▋         | 33/500 [13:39<3:25:31, 26.41s/it]  7%|▋         | 34/500 [14:02<3:16:55, 25.35s/it]  7%|▋         | 35/500 [14:29<3:19:27, 25.74s/it]  7%|▋         | 36/500 [14:52<3:12:07, 24.84s/it]  7%|▋         | 37/500 [15:15<3:07:41, 24.32s/it]  8%|▊         | 38/500 [15:43<3:15:33, 25.40s/it]  8%|▊         | 39/500 [16:10<3:20:04, 26.04s/it]  8%|▊         | 39/500 [16:10<3:11:12, 24.89s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.310 MB uploadedwandb: - 0.010 MB of 0.310 MB uploadedwandb: \ 0.107 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▃▁▅▃▁▁▆▅▆▇▆▇▆▇▅██▆█▇███████████████████
wandb:     train_loss ▃▁▂▄▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▂▁▅▃▁▃█▇▇▇▇███▆▆▇▇▇▇▇▆▇▆▆▇▇▆▇▇▆▆▆▆▆▇▆▆▆
wandb:       val_loss ▃▃▂▃▂▂▁▁▁▂▂▁▂▁▂▂█▁▁▂▁▁▁▁▅▃▁▁▃▁▂▁▁▁▅▁▁▂▅
wandb: 
wandb: Run summary:
wandb:          epoch 38
wandb:  learning_rate 6e-05
wandb: train_accuracy 1.0
wandb:     train_loss 1e-05
wandb:   val_accuracy 0.72444
wandb:       val_loss 2.2134
wandb: 
wandb: 🚀 View run icy-dragon-69 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6xskj56u
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_081617-6xskj56u/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_083306-luhlbhc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-butterfly-70
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/luhlbhc5
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:31<4:25:06, 31.88s/it]  0%|          | 2/500 [01:01<4:13:01, 30.49s/it]  1%|          | 3/500 [01:25<3:49:11, 27.67s/it]  1%|          | 4/500 [01:54<3:53:00, 28.19s/it]  1%|          | 5/500 [02:18<3:39:53, 26.65s/it]  1%|          | 6/500 [02:42<3:32:02, 25.75s/it]  1%|▏         | 7/500 [03:06<3:27:11, 25.22s/it]  2%|▏         | 8/500 [03:32<3:28:58, 25.48s/it]  2%|▏         | 9/500 [04:02<3:39:37, 26.84s/it]  2%|▏         | 10/500 [04:26<3:32:48, 26.06s/it]  2%|▏         | 11/500 [04:51<3:28:22, 25.57s/it]  2%|▏         | 12/500 [05:29<3:59:01, 29.39s/it]  3%|▎         | 13/500 [05:54<3:47:07, 27.98s/it]  3%|▎         | 14/500 [06:23<3:49:33, 28.34s/it]  3%|▎         | 15/500 [06:52<3:52:04, 28.71s/it]  3%|▎         | 16/500 [07:17<3:40:45, 27.37s/it]  3%|▎         | 17/500 [07:45<3:43:19, 27.74s/it]  4%|▎         | 18/500 [08:14<3:46:04, 28.14s/it]  4%|▍         | 19/500 [08:43<3:46:57, 28.31s/it]  4%|▍         | 20/500 [09:12<3:48:17, 28.54s/it]  4%|▍         | 21/500 [09:37<3:37:47, 27.28s/it]  4%|▍         | 22/500 [10:07<3:44:05, 28.13s/it]  5%|▍         | 23/500 [10:36<3:46:56, 28.55s/it]  5%|▍         | 24/500 [11:00<3:34:54, 27.09s/it]  5%|▌         | 25/500 [11:24<3:28:04, 26.28s/it]  5%|▌         | 25/500 [11:24<3:36:50, 27.39s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.311 MB uploadedwandb: \ 0.019 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▂▃▁▁▂▂▁▁▁▃█▆▅▆█▆▆▇█▆████▇
wandb:     train_loss ▂▂▁▁▂▁▅█▇▄▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂
wandb:   val_accuracy ▁▁▁▁▂▂▁▁▂▃█▇▅▇▇▇▇▇█▇█▇▇▇▇
wandb:       val_loss ▂▂▄▇▂▃▄█▁▅▁▁▇█▁▄▇▁▂▂▁▁▁▁▅
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.88559
wandb:     train_loss 1.61726
wandb:   val_accuracy 0.66444
wandb:       val_loss 4.60722
wandb: 
wandb: 🚀 View run smooth-butterfly-70 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/luhlbhc5
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_083306-luhlbhc5/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_084513-2xhmjyp9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-haze-71
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2xhmjyp9
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:42:27, 26.75s/it]  0%|          | 2/500 [00:50<3:25:00, 24.70s/it]  1%|          | 3/500 [01:13<3:19:06, 24.04s/it]  1%|          | 4/500 [01:36<3:16:20, 23.75s/it]  1%|          | 5/500 [02:01<3:18:00, 24.00s/it]  1%|          | 6/500 [02:29<3:29:29, 25.44s/it]  1%|▏         | 7/500 [02:52<3:22:53, 24.69s/it]  2%|▏         | 8/500 [03:19<3:29:47, 25.58s/it]  2%|▏         | 9/500 [03:42<3:22:15, 24.72s/it]  2%|▏         | 10/500 [04:05<3:17:28, 24.18s/it]  2%|▏         | 11/500 [04:28<3:14:42, 23.89s/it]  2%|▏         | 12/500 [04:59<3:30:51, 25.92s/it]  3%|▎         | 13/500 [05:28<3:36:49, 26.71s/it]  3%|▎         | 14/500 [05:55<3:38:03, 26.92s/it]  3%|▎         | 15/500 [06:22<3:38:19, 27.01s/it]  3%|▎         | 16/500 [06:49<3:38:08, 27.04s/it]  3%|▎         | 17/500 [07:17<3:38:26, 27.14s/it]  4%|▎         | 18/500 [07:40<3:28:36, 25.97s/it]  4%|▍         | 19/500 [08:03<3:20:51, 25.06s/it]  4%|▍         | 20/500 [08:28<3:20:44, 25.09s/it]  4%|▍         | 21/500 [08:51<3:16:27, 24.61s/it]  4%|▍         | 22/500 [09:20<3:25:37, 25.81s/it]  5%|▍         | 23/500 [09:48<3:30:04, 26.42s/it]  5%|▍         | 24/500 [10:11<3:21:28, 25.40s/it]  5%|▍         | 24/500 [10:15<3:23:34, 25.66s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.019 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▃▂▄▆▇▇▇▇▇▇▇▇███████████
wandb:     train_loss ▄▅█▅▆▇▂▅▃▅▅▄▇▃▂▂▁▄▄▁▁▅▄▅
wandb:   val_accuracy ▁▂▁▄▇▇▇▇▇██▇██▇▆▆▇▇▇▇▇▇▆
wandb:       val_loss ▆▇█▄▃▂▃▁▄▃▃▃▃▄▁▁▂▅▃▁▃▄▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 23
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.7682
wandb:     train_loss 1.03307
wandb:   val_accuracy 0.58
wandb:       val_loss 0.65426
wandb: 
wandb: 🚀 View run young-haze-71 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2xhmjyp9
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_084513-2xhmjyp9/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_085610-zi5qd7q8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-frost-72
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/zi5qd7q8
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:24<3:27:44, 24.98s/it]  0%|          | 2/500 [00:48<3:22:02, 24.34s/it]  1%|          | 3/500 [01:12<3:18:41, 23.99s/it]  1%|          | 4/500 [01:36<3:17:18, 23.87s/it]  1%|          | 5/500 [02:04<3:30:34, 25.53s/it]  1%|          | 6/500 [02:32<3:37:43, 26.44s/it]  1%|▏         | 7/500 [02:56<3:29:29, 25.50s/it]  2%|▏         | 8/500 [03:24<3:36:29, 26.40s/it]  2%|▏         | 9/500 [03:48<3:29:51, 25.65s/it]  2%|▏         | 10/500 [04:12<3:24:51, 25.08s/it]  2%|▏         | 11/500 [04:38<3:27:35, 25.47s/it]  2%|▏         | 12/500 [05:02<3:23:10, 24.98s/it]  3%|▎         | 13/500 [05:31<3:32:52, 26.23s/it]  3%|▎         | 14/500 [06:00<3:38:17, 26.95s/it]  3%|▎         | 15/500 [06:29<3:42:58, 27.58s/it]  3%|▎         | 16/500 [06:52<3:32:13, 26.31s/it]  3%|▎         | 17/500 [07:21<3:36:25, 26.88s/it]  4%|▎         | 18/500 [07:44<3:28:33, 25.96s/it]  4%|▍         | 19/500 [08:08<3:22:33, 25.27s/it]  4%|▍         | 20/500 [08:32<3:19:08, 24.89s/it]  4%|▍         | 21/500 [08:56<3:15:33, 24.49s/it]  4%|▍         | 22/500 [09:19<3:13:29, 24.29s/it]  5%|▍         | 23/500 [09:49<3:24:32, 25.73s/it]  5%|▍         | 24/500 [10:18<3:32:47, 26.82s/it]  5%|▌         | 25/500 [10:47<3:37:22, 27.46s/it]  5%|▌         | 25/500 [10:54<3:27:13, 26.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.310 MB uploadedwandb: \ 0.019 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▄▁▄▅▃▃▁█▆▇▇█▄▆█▇█████▇
wandb:     train_loss ▃▁▂▁▄▁▁▅█▃▁▃▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▇▃▁▅▆▄▄▂▇▇▇▇█▅▇█▇▇███▇▇
wandb:       val_loss ▂█▂▂▃▁▁▄▁▆▁▁▆▄▁▃█▁▃▃▁▁▁▁▄
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.93759
wandb:     train_loss 0.11205
wandb:   val_accuracy 0.66
wandb:       val_loss 3.41393
wandb: 
wandb: 🚀 View run sweet-frost-72 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/zi5qd7q8
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_085610-zi5qd7q8/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_090801-8wk3r23x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-voice-73
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8wk3r23x
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:30<4:14:15, 30.57s/it]  0%|          | 2/500 [00:54<3:43:43, 26.95s/it]  1%|          | 3/500 [01:18<3:31:02, 25.48s/it]  1%|          | 4/500 [01:47<3:40:23, 26.66s/it]  1%|          | 5/500 [02:11<3:32:25, 25.75s/it]  1%|          | 6/500 [02:40<3:40:19, 26.76s/it]  1%|▏         | 7/500 [03:03<3:30:39, 25.64s/it]  2%|▏         | 8/500 [03:26<3:24:26, 24.93s/it]  2%|▏         | 9/500 [03:52<3:26:31, 25.24s/it]  2%|▏         | 10/500 [04:21<3:36:06, 26.46s/it]  2%|▏         | 11/500 [04:45<3:29:39, 25.72s/it]  2%|▏         | 12/500 [05:15<3:37:42, 26.77s/it]  3%|▎         | 13/500 [05:38<3:29:25, 25.80s/it]  3%|▎         | 14/500 [06:07<3:36:31, 26.73s/it]  3%|▎         | 15/500 [06:36<3:41:30, 27.40s/it]  3%|▎         | 16/500 [07:05<3:44:58, 27.89s/it]  3%|▎         | 17/500 [07:29<3:34:43, 26.67s/it]  4%|▎         | 18/500 [08:07<4:02:50, 30.23s/it]  4%|▍         | 19/500 [08:31<3:47:10, 28.34s/it]  4%|▍         | 20/500 [09:00<3:47:30, 28.44s/it]  4%|▍         | 21/500 [09:24<3:35:35, 27.00s/it]  4%|▍         | 22/500 [09:52<3:38:25, 27.42s/it]  5%|▍         | 23/500 [10:25<3:51:03, 29.06s/it]  5%|▍         | 24/500 [10:49<3:38:27, 27.54s/it]  5%|▌         | 25/500 [11:19<3:44:53, 28.41s/it]  5%|▌         | 26/500 [11:44<3:34:36, 27.16s/it]  5%|▌         | 27/500 [12:12<3:37:55, 27.64s/it]  6%|▌         | 28/500 [12:42<3:41:04, 28.10s/it]  6%|▌         | 29/500 [13:10<3:42:18, 28.32s/it]  6%|▌         | 30/500 [13:39<3:43:38, 28.55s/it]  6%|▌         | 31/500 [14:03<3:32:05, 27.13s/it]  6%|▋         | 32/500 [14:33<3:36:50, 27.80s/it]  7%|▋         | 33/500 [14:57<3:27:23, 26.65s/it]  7%|▋         | 34/500 [15:20<3:19:39, 25.71s/it]  7%|▋         | 35/500 [15:44<3:14:31, 25.10s/it]  7%|▋         | 36/500 [16:08<3:10:54, 24.69s/it]  7%|▋         | 37/500 [16:31<3:08:17, 24.40s/it]  8%|▊         | 38/500 [16:58<3:13:08, 25.08s/it]  8%|▊         | 39/500 [17:22<3:09:45, 24.70s/it]  8%|▊         | 40/500 [17:51<3:19:02, 25.96s/it]  8%|▊         | 41/500 [18:14<3:13:14, 25.26s/it]  8%|▊         | 42/500 [18:44<3:23:46, 26.69s/it]  9%|▊         | 43/500 [19:08<3:17:33, 25.94s/it]  9%|▉         | 44/500 [19:32<3:12:17, 25.30s/it]  9%|▉         | 45/500 [19:56<3:09:09, 24.94s/it]  9%|▉         | 46/500 [20:21<3:07:38, 24.80s/it]  9%|▉         | 47/500 [20:48<3:13:34, 25.64s/it] 10%|▉         | 48/500 [21:13<3:09:34, 25.17s/it] 10%|▉         | 49/500 [21:42<3:18:20, 26.39s/it] 10%|█         | 50/500 [22:05<3:11:43, 25.56s/it] 10%|█         | 51/500 [22:29<3:07:04, 25.00s/it] 10%|█         | 52/500 [22:53<3:03:45, 24.61s/it] 11%|█         | 53/500 [23:17<3:01:42, 24.39s/it] 11%|█         | 54/500 [23:40<2:59:27, 24.14s/it] 11%|█         | 55/500 [24:04<2:58:01, 24.00s/it] 11%|█         | 56/500 [24:27<2:56:19, 23.83s/it] 11%|█▏        | 57/500 [24:51<2:55:06, 23.72s/it] 12%|█▏        | 58/500 [25:14<2:54:18, 23.66s/it] 12%|█▏        | 59/500 [25:38<2:53:33, 23.61s/it] 12%|█▏        | 60/500 [26:01<2:52:55, 23.58s/it] 12%|█▏        | 61/500 [26:25<2:52:42, 23.60s/it] 12%|█▏        | 61/500 [26:25<3:10:10, 25.99s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.029 MB uploadedwandb: / 0.010 MB of 0.313 MB uploadedwandb: - 0.019 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▅▄▁█▆█▄██▆█▇███████████████████████████
wandb:     train_loss ▄▂▁█▁▅▁▃▁▁▁▁▁▁▁▃▃▅▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁
wandb:   val_accuracy ▁▆▃▂▇▅██▇█▇▇█▇▇█▇█▇██▇▇██▇▇█▇█████▇▇█▇▇▇
wandb:       val_loss ▂▂▅▃▁▄▁▁▅▁▅█▁▁▁▁▅▁▁▄▁▁▃▁▁▄▂▃▁▁▂▁▁▁▅▁▃▃▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 60
wandb:  learning_rate 2e-05
wandb: train_accuracy 0.9792
wandb:     train_loss 0.04413
wandb:   val_accuracy 0.74444
wandb:       val_loss 0.00053
wandb: 
wandb: 🚀 View run smooth-voice-73 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8wk3r23x
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_090801-8wk3r23x/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_093520-sq89lxpn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-donkey-74
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sq89lxpn
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:30:16, 32.50s/it]  0%|          | 2/500 [00:56<3:46:24, 27.28s/it]  1%|          | 3/500 [01:19<3:32:19, 25.63s/it]  1%|          | 4/500 [01:43<3:25:28, 24.85s/it]  1%|          | 5/500 [02:06<3:21:07, 24.38s/it]  1%|          | 6/500 [02:37<3:37:56, 26.47s/it]  1%|▏         | 7/500 [03:01<3:30:02, 25.56s/it]  2%|▏         | 8/500 [03:31<3:41:33, 27.02s/it]  2%|▏         | 9/500 [03:59<3:44:49, 27.47s/it]  2%|▏         | 10/500 [04:23<3:33:41, 26.17s/it]  2%|▏         | 11/500 [04:46<3:25:35, 25.23s/it]  2%|▏         | 12/500 [05:18<3:43:51, 27.52s/it]  3%|▎         | 13/500 [05:41<3:32:15, 26.15s/it]  3%|▎         | 14/500 [06:09<3:36:04, 26.68s/it]  3%|▎         | 15/500 [06:37<3:37:14, 26.88s/it]  3%|▎         | 16/500 [07:10<3:52:36, 28.84s/it]  3%|▎         | 17/500 [07:33<3:38:39, 27.16s/it]  4%|▎         | 18/500 [08:01<3:39:22, 27.31s/it]  4%|▍         | 19/500 [08:30<3:42:18, 27.73s/it]  4%|▍         | 20/500 [08:58<3:43:55, 27.99s/it]  4%|▍         | 21/500 [09:32<3:56:18, 29.60s/it]  4%|▍         | 22/500 [09:55<3:40:38, 27.70s/it]  5%|▍         | 23/500 [10:23<3:40:04, 27.68s/it]  5%|▍         | 24/500 [10:46<3:29:04, 26.35s/it]  5%|▌         | 25/500 [11:09<3:20:52, 25.37s/it]  5%|▌         | 26/500 [11:32<3:14:49, 24.66s/it]  5%|▌         | 27/500 [11:55<3:11:22, 24.28s/it]  6%|▌         | 28/500 [12:19<3:09:12, 24.05s/it]  6%|▌         | 29/500 [12:42<3:06:25, 23.75s/it]  6%|▌         | 30/500 [13:10<3:15:55, 25.01s/it]  6%|▌         | 31/500 [13:38<3:23:11, 25.99s/it]  6%|▋         | 32/500 [14:06<3:27:15, 26.57s/it]  7%|▋         | 33/500 [14:29<3:17:45, 25.41s/it]  7%|▋         | 34/500 [14:51<3:10:17, 24.50s/it]  7%|▋         | 35/500 [15:19<3:18:31, 25.62s/it]  7%|▋         | 36/500 [15:49<3:26:49, 26.74s/it]  7%|▋         | 37/500 [16:17<3:29:38, 27.17s/it]  8%|▊         | 38/500 [16:40<3:19:51, 25.95s/it]  8%|▊         | 39/500 [17:03<3:12:19, 25.03s/it]  8%|▊         | 40/500 [17:26<3:07:09, 24.41s/it]  8%|▊         | 41/500 [17:49<3:03:25, 23.98s/it]  8%|▊         | 42/500 [18:16<3:11:31, 25.09s/it]  9%|▊         | 43/500 [18:39<3:06:16, 24.46s/it]  9%|▉         | 44/500 [19:07<3:12:50, 25.37s/it]  9%|▉         | 45/500 [19:35<3:19:35, 26.32s/it]  9%|▉         | 46/500 [19:59<3:11:57, 25.37s/it]  9%|▉         | 47/500 [20:22<3:05:58, 24.63s/it] 10%|▉         | 48/500 [20:45<3:02:08, 24.18s/it] 10%|▉         | 49/500 [21:07<2:58:43, 23.78s/it] 10%|█         | 50/500 [21:30<2:56:30, 23.53s/it] 10%|█         | 51/500 [21:53<2:54:32, 23.32s/it] 10%|█         | 52/500 [22:16<2:53:08, 23.19s/it] 11%|█         | 53/500 [22:41<2:56:28, 23.69s/it] 11%|█         | 54/500 [23:04<2:54:44, 23.51s/it] 11%|█         | 55/500 [23:32<3:05:07, 24.96s/it] 11%|█         | 56/500 [23:55<3:00:09, 24.35s/it] 11%|█▏        | 57/500 [24:19<2:57:24, 24.03s/it] 12%|█▏        | 58/500 [24:42<2:54:40, 23.71s/it] 12%|█▏        | 59/500 [25:05<2:53:24, 23.59s/it] 12%|█▏        | 60/500 [25:28<2:52:08, 23.47s/it] 12%|█▏        | 61/500 [25:58<3:05:08, 25.30s/it] 12%|█▏        | 61/500 [25:58<3:06:53, 25.54s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.010 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▃▅▇▆███▇▆▃▆▇▆▆▅█▇▇▇▇▇▇█▇▆█▆█▇▇▇█▆▅▇▇▆▆
wandb:     train_loss ▅▇█▇▄▇▆▆▆▆▅▄▄▂▆▆▃▆▄▇▇▄▇▅▄▁▇▇▆▂▄▅▃██▄▁██▅
wandb:   val_accuracy ▁▃▁▂▇▃█▇▇▆▄▂▆▆▅▅▅▇▇▇▇▆▆▇▇▇▆▇▆▇▇▆▇▇▆▆▆▇▅▆
wandb:       val_loss ▆▆▅▅▅▅▄▆▅▆▃▆▄▃▃▃█▃▃▃▅▄▄▅▆▄▆▅▄▁▃▅▃▃▄▃▄▅▆▃
wandb: 
wandb: Run summary:
wandb:          epoch 60
wandb:  learning_rate 0.0
wandb: train_accuracy 0.60624
wandb:     train_loss 0.78264
wandb:   val_accuracy 0.54889
wandb:       val_loss 0.6002
wandb: 
wandb: 🚀 View run proud-donkey-74 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sq89lxpn
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_093520-sq89lxpn/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_100204-ybw1mm8y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-glade-75
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ybw1mm8y
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:30:05, 25.26s/it]  0%|          | 2/500 [00:50<3:29:35, 25.25s/it]  1%|          | 3/500 [01:19<3:44:13, 27.07s/it]  1%|          | 4/500 [01:43<3:32:52, 25.75s/it]  1%|          | 5/500 [02:18<4:01:31, 29.28s/it]  1%|          | 6/500 [02:42<3:46:09, 27.47s/it]  1%|▏         | 7/500 [03:06<3:34:55, 26.16s/it]  2%|▏         | 8/500 [03:40<3:54:00, 28.54s/it]  2%|▏         | 9/500 [04:09<3:54:35, 28.67s/it]  2%|▏         | 10/500 [04:35<3:49:38, 28.12s/it]  2%|▏         | 11/500 [04:59<3:37:56, 26.74s/it]  2%|▏         | 12/500 [05:30<3:47:04, 27.92s/it]  3%|▎         | 13/500 [05:58<3:47:17, 28.00s/it]  3%|▎         | 14/500 [06:27<3:48:59, 28.27s/it]  3%|▎         | 15/500 [06:50<3:36:41, 26.81s/it]  3%|▎         | 16/500 [07:14<3:28:02, 25.79s/it]  3%|▎         | 17/500 [07:41<3:32:37, 26.41s/it]  4%|▎         | 18/500 [08:04<3:23:30, 25.33s/it]  4%|▍         | 19/500 [08:27<3:16:34, 24.52s/it]  4%|▍         | 20/500 [08:50<3:11:52, 23.98s/it]  4%|▍         | 21/500 [09:13<3:09:17, 23.71s/it]  4%|▍         | 22/500 [09:45<3:29:42, 26.32s/it]  5%|▍         | 23/500 [10:08<3:21:46, 25.38s/it]  5%|▍         | 24/500 [10:36<3:27:45, 26.19s/it]  5%|▌         | 25/500 [11:00<3:20:40, 25.35s/it]  5%|▌         | 25/500 [11:05<3:30:38, 26.61s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.230 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▃▅▄▄▃▄▅▇▅▆▅▆▇▇▇▇▇▇██▇▇█▇
wandb:     train_loss ▃▂▃▃▃█▁▂▄▂▂▂▁▁▁▂▁▂▁▁▂▂▁▁▁
wandb:   val_accuracy ▁▁▇▅▄▃▄▆█▅▆▅▇▆▇█▆▇▇▇▇█▇▇▇
wandb:       val_loss ▃▄▂▃▂▃▃▂▁▃▃▅▅▂▃▁█▂▃▃▃▁▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.87964
wandb:     train_loss 0.09287
wandb:   val_accuracy 0.67333
wandb:       val_loss 0.28729
wandb: 
wandb: 🚀 View run dark-glade-75 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ybw1mm8y
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_100204-ybw1mm8y/logs
Successfully processed 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101358-fw0x8mzl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-meadow-76
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fw0x8mzl
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.017 MB of 0.038 MB uploaded (0.004 MB deduped)wandb: / 0.027 MB of 0.038 MB uploaded (0.004 MB deduped)wandb: - 0.038 MB of 0.038 MB uploaded (0.004 MB deduped)wandb: 🚀 View run tough-meadow-76 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fw0x8mzl
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101358-fw0x8mzl/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101433-eshi1q0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-disco-77
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eshi1q0c
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.019 MB of 0.031 MB uploadedwandb: - 0.026 MB of 0.031 MB uploadedwandb: 🚀 View run dandy-disco-77 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eshi1q0c
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101433-eshi1q0c/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101515-az6brxo2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-smoke-78
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/az6brxo2
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.031 MB uploadedwandb: \ 0.025 MB of 0.031 MB uploadedwandb: | 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run celestial-smoke-78 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/az6brxo2
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101515-az6brxo2/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101553-aqw77szv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-shape-79
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aqw77szv
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.019 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run solar-shape-79 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aqw77szv
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101553-aqw77szv/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101624-kr6yli2e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-wave-80
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/kr6yli2e
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.019 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run soft-wave-80 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/kr6yli2e
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101624-kr6yli2e/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101659-5irkyiji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-lake-81
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5irkyiji
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.019 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run iconic-lake-81 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/5irkyiji
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101659-5irkyiji/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101740-70mc73g6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hearty-sky-82
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/70mc73g6
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.019 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run hearty-sky-82 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/70mc73g6
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101740-70mc73g6/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101815-66trei8t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-glade-83
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/66trei8t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.026 MB of 0.031 MB uploadedwandb: 🚀 View run proud-glade-83 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/66trei8t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101815-66trei8t/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101846-rp9uq51s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-snowball-84
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rp9uq51s
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.031 MB uploadedwandb: \ 0.011 MB of 0.031 MB uploadedwandb: | 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run divine-snowball-84 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rp9uq51s
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101846-rp9uq51s/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101921-x5fq95l8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-plasma-85
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x5fq95l8
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:00<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.021 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run glowing-plasma-85 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x5fq95l8
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101921-x5fq95l8/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_101955-ntvbo7u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-firebrand-86
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ntvbo7u1
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.021 MB of 0.031 MB uploadedwandb: 🚀 View run giddy-firebrand-86 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ntvbo7u1
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_101955-ntvbo7u1/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_102028-j2rhalry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-firebrand-87
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/j2rhalry
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.025 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run glamorous-firebrand-87 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/j2rhalry
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_102028-j2rhalry/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_102112-7bnyqpz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-surf-88
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/7bnyqpz9
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.025 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run icy-surf-88 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/7bnyqpz9
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_102112-7bnyqpz9/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_102153-2q226end
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-frost-89
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2q226end
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.025 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run polished-frost-89 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2q226end
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_102153-2q226end/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_102235-aiirbxjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-water-90
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aiirbxjj
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.021 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run elated-water-90 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/aiirbxjj
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_102235-aiirbxjj/logs
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 0 has a total capacity of 23.68 GiB of which 1.81 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 1_20131027
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_102321-9va4vd64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-eon-91
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9va4vd64
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<1:58:10, 14.21s/it]  0%|          | 2/500 [00:26<1:49:18, 13.17s/it]  1%|          | 3/500 [00:38<1:44:18, 12.59s/it]  1%|          | 4/500 [00:50<1:42:21, 12.38s/it]  1%|          | 5/500 [01:02<1:40:56, 12.24s/it]  1%|          | 6/500 [01:14<1:40:56, 12.26s/it]  1%|▏         | 7/500 [01:27<1:41:34, 12.36s/it]  2%|▏         | 8/500 [01:40<1:42:27, 12.50s/it]  2%|▏         | 9/500 [01:52<1:41:29, 12.40s/it]  2%|▏         | 10/500 [02:04<1:41:24, 12.42s/it]  2%|▏         | 11/500 [02:17<1:41:12, 12.42s/it]  2%|▏         | 12/500 [02:29<1:40:51, 12.40s/it]  3%|▎         | 13/500 [02:42<1:40:55, 12.43s/it]  3%|▎         | 14/500 [02:54<1:40:37, 12.42s/it]  3%|▎         | 15/500 [03:07<1:40:37, 12.45s/it]  3%|▎         | 16/500 [03:19<1:40:48, 12.50s/it]  3%|▎         | 17/500 [03:32<1:41:01, 12.55s/it]  4%|▎         | 18/500 [03:44<1:40:52, 12.56s/it]  4%|▍         | 19/500 [03:56<1:39:21, 12.39s/it]  4%|▍         | 20/500 [04:09<1:39:15, 12.41s/it]  4%|▍         | 21/500 [04:22<1:40:59, 12.65s/it]  4%|▍         | 22/500 [04:34<1:39:26, 12.48s/it]  5%|▍         | 23/500 [04:46<1:38:39, 12.41s/it]  5%|▍         | 24/500 [04:59<1:38:04, 12.36s/it]  5%|▌         | 25/500 [05:12<1:39:04, 12.51s/it]  5%|▌         | 26/500 [05:24<1:38:24, 12.46s/it]  5%|▌         | 27/500 [05:36<1:37:20, 12.35s/it]  6%|▌         | 28/500 [05:48<1:36:33, 12.27s/it]  6%|▌         | 29/500 [06:01<1:37:15, 12.39s/it]  6%|▌         | 30/500 [06:14<1:37:54, 12.50s/it]  6%|▌         | 30/500 [06:14<1:37:39, 12.47s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.027 MB uploadedwandb: / 0.010 MB of 0.309 MB uploadedwandb: - 0.021 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▂▁▂▁▁▆▂▁▁▃▁▁▂█▁▁▂▃▇▂▆▃▄▂█▂▇▅█▇
wandb:     train_loss ▁▂▁█▆▁▁▁▆▁▅▄▂▁▁▄▁▁▁▂▁▁▁▁▁▂▁▁▁▁
wandb:   val_accuracy ▁▂▁▃▃▅▇▂▂▃▃▃▃▇▃▄▃▇▅▇█▄▄▃▅▇▇█▅▇
wandb:       val_loss ▁▁▂▄▃▂▁▂▅▂▄▃▂▁▅▅▃▂▁▁▂█▄▅▃▄▅▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 29
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.87519
wandb:     train_loss 1.47602
wandb:   val_accuracy 0.52444
wandb:       val_loss 0.00225
wandb: 
wandb: 🚀 View run scarlet-eon-91 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9va4vd64
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_102321-9va4vd64/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_103110-1x4ni3sb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-leaf-92
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1x4ni3sb
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:16:13, 16.38s/it]  0%|          | 2/500 [00:29<1:58:02, 14.22s/it]  1%|          | 3/500 [00:41<1:50:18, 13.32s/it]  1%|          | 4/500 [00:53<1:46:46, 12.92s/it]  1%|          | 5/500 [01:05<1:42:46, 12.46s/it]  1%|          | 6/500 [01:17<1:40:50, 12.25s/it]  1%|▏         | 7/500 [01:34<1:53:08, 13.77s/it]  2%|▏         | 8/500 [01:45<1:47:43, 13.14s/it]  2%|▏         | 9/500 [01:57<1:43:20, 12.63s/it]  2%|▏         | 10/500 [02:09<1:41:10, 12.39s/it]  2%|▏         | 11/500 [02:20<1:38:05, 12.04s/it]  2%|▏         | 12/500 [02:32<1:37:39, 12.01s/it]  3%|▎         | 13/500 [02:43<1:36:27, 11.88s/it]  3%|▎         | 14/500 [02:55<1:35:37, 11.81s/it]  3%|▎         | 15/500 [03:07<1:35:58, 11.87s/it]  3%|▎         | 16/500 [03:19<1:35:02, 11.78s/it]  3%|▎         | 17/500 [03:30<1:34:36, 11.75s/it]  4%|▎         | 18/500 [03:42<1:34:25, 11.75s/it]  4%|▍         | 19/500 [03:54<1:33:56, 11.72s/it]  4%|▍         | 20/500 [04:05<1:33:15, 11.66s/it]  4%|▍         | 21/500 [04:17<1:34:02, 11.78s/it]  4%|▍         | 22/500 [04:28<1:32:17, 11.59s/it]  5%|▍         | 23/500 [04:39<1:30:35, 11.39s/it]  5%|▍         | 24/500 [04:51<1:30:05, 11.36s/it]  5%|▌         | 25/500 [05:02<1:29:58, 11.36s/it]  5%|▌         | 26/500 [05:13<1:29:52, 11.38s/it]  5%|▌         | 27/500 [05:25<1:30:28, 11.48s/it]  6%|▌         | 28/500 [05:37<1:30:23, 11.49s/it]  6%|▌         | 28/500 [05:37<1:34:44, 12.04s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.021 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▁▃▂▄▃▂▅▁▁▁▄█▁▃▇█▂▁█▇▁▂▆▄▂
wandb:     train_loss ▂▂▂▂▂▂▂▂▃▂▇▅▆▂▁▁▃▁▃▅█▁▂▁▃▂▃▄
wandb:   val_accuracy ▄▄█▃▇▅▄▄▁▅▃▁▂▄▄▃▄▄▄▂▂▄▄▂▂▅▅▂
wandb:       val_loss ▁▁▁▂▂▂▁▁▁▃▄▁▂▅▃▂▁█▁▃▆▂▃▂▅▄▄▃
wandb: 
wandb: Run summary:
wandb:          epoch 27
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.36256
wandb:     train_loss 2.44093
wandb:   val_accuracy 0.29556
wandb:       val_loss 4.67202
wandb: 
wandb: 🚀 View run stoic-leaf-92 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/1x4ni3sb
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_103110-1x4ni3sb/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_103731-4uprivop
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-water-93
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4uprivop
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:26:11, 17.58s/it]  0%|          | 2/500 [00:29<1:59:12, 14.36s/it]  1%|          | 3/500 [00:41<1:47:42, 13.00s/it]  1%|          | 4/500 [00:53<1:44:30, 12.64s/it]  1%|          | 5/500 [01:04<1:39:43, 12.09s/it]  1%|          | 6/500 [01:16<1:38:36, 11.98s/it]  1%|▏         | 7/500 [01:27<1:36:44, 11.77s/it]  2%|▏         | 8/500 [01:40<1:38:47, 12.05s/it]  2%|▏         | 9/500 [01:53<1:42:15, 12.50s/it]  2%|▏         | 10/500 [02:06<1:42:57, 12.61s/it]  2%|▏         | 11/500 [02:19<1:44:43, 12.85s/it]  2%|▏         | 12/500 [02:31<1:42:59, 12.66s/it]  3%|▎         | 13/500 [02:43<1:40:12, 12.35s/it]  3%|▎         | 14/500 [02:55<1:38:28, 12.16s/it]  3%|▎         | 15/500 [03:06<1:36:33, 11.94s/it]  3%|▎         | 16/500 [03:18<1:36:32, 11.97s/it]  3%|▎         | 17/500 [03:30<1:35:44, 11.89s/it]  4%|▎         | 18/500 [03:41<1:34:17, 11.74s/it]  4%|▍         | 19/500 [03:53<1:33:39, 11.68s/it]  4%|▍         | 20/500 [04:05<1:33:36, 11.70s/it]  4%|▍         | 21/500 [04:17<1:34:38, 11.86s/it]  4%|▍         | 22/500 [04:28<1:32:51, 11.66s/it]  5%|▍         | 23/500 [04:40<1:34:11, 11.85s/it]  5%|▍         | 24/500 [04:52<1:32:43, 11.69s/it]  5%|▌         | 25/500 [05:03<1:32:34, 11.69s/it]  5%|▌         | 25/500 [05:03<1:36:14, 12.16s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.310 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.229 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▅▁▂▇▄▇▇▆█▇▇▇▇███▇█▇███
wandb:     train_loss ▄▃▆▂█▁▁▁▂▁▁▃▁▁▁█▂▁▇▂▃▁▃▁▁
wandb:   val_accuracy ▃▅▁▃▆▇▄▂▇▇▇▇▇█▅██▇▆█▇▆███
wandb:       val_loss ▂▄▂▃▁▄▂▃▁▂▁▄▅▆▅▁▃▇▁▃▆██▆▅
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.97325
wandb:     train_loss 0.00085
wandb:   val_accuracy 0.49778
wandb:       val_loss 3.77094
wandb: 
wandb: 🚀 View run fast-water-93 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4uprivop
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_103731-4uprivop/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_104321-tzzd13km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-voice-94
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tzzd13km
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:30:59, 25.37s/it]  0%|          | 2/500 [00:37<2:28:12, 17.86s/it]  1%|          | 3/500 [00:50<2:09:08, 15.59s/it]  1%|          | 4/500 [01:03<1:58:45, 14.37s/it]  1%|          | 5/500 [01:15<1:52:03, 13.58s/it]  1%|          | 6/500 [01:28<1:49:32, 13.31s/it]  1%|▏         | 7/500 [01:41<1:47:42, 13.11s/it]  2%|▏         | 8/500 [01:52<1:44:32, 12.75s/it]  2%|▏         | 9/500 [02:05<1:42:53, 12.57s/it]  2%|▏         | 10/500 [02:17<1:42:19, 12.53s/it]  2%|▏         | 11/500 [02:30<1:42:06, 12.53s/it]  2%|▏         | 12/500 [02:42<1:42:41, 12.63s/it]  3%|▎         | 13/500 [02:55<1:43:22, 12.74s/it]  3%|▎         | 14/500 [03:08<1:43:45, 12.81s/it]  3%|▎         | 15/500 [03:21<1:42:15, 12.65s/it]  3%|▎         | 16/500 [03:33<1:41:11, 12.54s/it]  3%|▎         | 17/500 [03:46<1:41:10, 12.57s/it]  4%|▎         | 18/500 [03:58<1:41:00, 12.57s/it]  4%|▍         | 19/500 [04:11<1:40:15, 12.51s/it]  4%|▍         | 20/500 [04:23<1:38:38, 12.33s/it]  4%|▍         | 21/500 [04:35<1:38:33, 12.35s/it]  4%|▍         | 22/500 [04:47<1:38:15, 12.33s/it]  5%|▍         | 23/500 [05:00<1:39:08, 12.47s/it]  5%|▍         | 24/500 [05:12<1:37:35, 12.30s/it]  5%|▌         | 25/500 [05:25<1:38:18, 12.42s/it]  5%|▌         | 26/500 [05:37<1:36:59, 12.28s/it]  5%|▌         | 27/500 [05:49<1:36:29, 12.24s/it]  6%|▌         | 28/500 [06:01<1:37:35, 12.41s/it]  6%|▌         | 29/500 [06:14<1:37:43, 12.45s/it]  6%|▌         | 30/500 [06:26<1:37:02, 12.39s/it]  6%|▌         | 31/500 [06:38<1:36:02, 12.29s/it]  6%|▋         | 32/500 [06:51<1:36:49, 12.41s/it]  7%|▋         | 33/500 [07:03<1:36:09, 12.35s/it]  7%|▋         | 34/500 [07:16<1:37:12, 12.52s/it]  7%|▋         | 35/500 [07:29<1:37:34, 12.59s/it]  7%|▋         | 36/500 [07:41<1:37:17, 12.58s/it]  7%|▋         | 37/500 [07:54<1:37:36, 12.65s/it]  8%|▊         | 38/500 [08:06<1:36:03, 12.47s/it]  8%|▊         | 39/500 [08:18<1:34:56, 12.36s/it]  8%|▊         | 40/500 [08:31<1:34:35, 12.34s/it]  8%|▊         | 41/500 [08:44<1:35:38, 12.50s/it]  8%|▊         | 42/500 [08:56<1:36:14, 12.61s/it]  9%|▊         | 43/500 [09:09<1:36:32, 12.67s/it]  9%|▉         | 44/500 [09:22<1:37:12, 12.79s/it]  9%|▉         | 45/500 [09:36<1:38:14, 12.96s/it]  9%|▉         | 46/500 [09:48<1:36:40, 12.78s/it]  9%|▉         | 47/500 [10:01<1:37:08, 12.87s/it] 10%|▉         | 48/500 [10:13<1:35:31, 12.68s/it] 10%|▉         | 49/500 [10:26<1:36:06, 12.79s/it] 10%|█         | 50/500 [10:39<1:35:19, 12.71s/it] 10%|█         | 51/500 [10:52<1:35:03, 12.70s/it] 10%|█         | 52/500 [11:04<1:34:20, 12.63s/it] 11%|█         | 53/500 [11:17<1:35:03, 12.76s/it] 11%|█         | 53/500 [11:17<1:35:15, 12.79s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.019 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▄▆▅▇▇▇██████████▇███████████████████
wandb:     train_loss ▄▃█▆█▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▃▁▁▂▄▅▅▇▇██▇▇███▇▇▇▇█▇█▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:       val_loss ▂▄▂▂▂▁▁▅▁▁▁▃▂▃▁▁▃▅▁▂▇▁▃▁▇▂▁▁▁▂█▃▁▁▃▄▂▇▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 52
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.97177
wandb:     train_loss 0.01894
wandb:   val_accuracy 0.71778
wandb:       val_loss 0.86017
wandb: 
wandb: 🚀 View run happy-voice-94 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tzzd13km
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_104321-tzzd13km/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_105522-x2ruixep
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-glitter-95
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x2ruixep
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:16:31, 16.41s/it]  0%|          | 2/500 [00:30<2:05:21, 15.10s/it]  1%|          | 3/500 [00:44<2:00:35, 14.56s/it]  1%|          | 4/500 [00:57<1:54:27, 13.85s/it]  1%|          | 5/500 [01:09<1:50:26, 13.39s/it]  1%|          | 6/500 [01:22<1:49:31, 13.30s/it]  1%|▏         | 7/500 [01:35<1:48:01, 13.15s/it]  2%|▏         | 8/500 [01:49<1:48:04, 13.18s/it]  2%|▏         | 9/500 [02:02<1:47:15, 13.11s/it]  2%|▏         | 10/500 [02:15<1:46:54, 13.09s/it]  2%|▏         | 11/500 [02:27<1:45:39, 12.96s/it]  2%|▏         | 12/500 [02:40<1:45:21, 12.95s/it]  3%|▎         | 13/500 [02:53<1:44:49, 12.92s/it]  3%|▎         | 14/500 [03:06<1:43:38, 12.79s/it]  3%|▎         | 15/500 [03:18<1:41:48, 12.59s/it]  3%|▎         | 16/500 [03:30<1:40:18, 12.44s/it]  3%|▎         | 17/500 [03:42<1:39:27, 12.36s/it]  4%|▎         | 18/500 [03:55<1:40:09, 12.47s/it]  4%|▍         | 19/500 [04:08<1:42:34, 12.80s/it]  4%|▍         | 20/500 [04:21<1:43:09, 12.90s/it]  4%|▍         | 21/500 [04:38<1:52:15, 14.06s/it]  4%|▍         | 22/500 [04:52<1:50:58, 13.93s/it]  5%|▍         | 23/500 [05:05<1:48:37, 13.66s/it]  5%|▍         | 24/500 [05:18<1:46:52, 13.47s/it]  5%|▌         | 25/500 [05:30<1:44:47, 13.24s/it]  5%|▌         | 26/500 [05:44<1:44:49, 13.27s/it]  5%|▌         | 27/500 [05:57<1:44:23, 13.24s/it]  6%|▌         | 28/500 [06:10<1:44:16, 13.26s/it]  6%|▌         | 29/500 [06:23<1:43:26, 13.18s/it]  6%|▌         | 30/500 [06:36<1:42:35, 13.10s/it]  6%|▌         | 31/500 [06:49<1:41:33, 12.99s/it]  6%|▋         | 32/500 [07:02<1:41:17, 12.99s/it]  7%|▋         | 33/500 [07:15<1:40:48, 12.95s/it]  7%|▋         | 34/500 [07:28<1:40:54, 12.99s/it]  7%|▋         | 35/500 [07:41<1:40:29, 12.97s/it]  7%|▋         | 35/500 [07:41<1:42:08, 13.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.021 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▂▂▃▃▁▄▃▁▁▁▃▆▁▃▃▄▆▁▃▆▂▂█▄▁▃▃▄▂▄██
wandb:     train_loss ▂▂▂▂▂▂▂▁▂▃▅▅█▂▁▁▃▃▂▂█▃▃▁▄▁▃▅▃▁▃▁▁▂▁
wandb:   val_accuracy ▃▂█▂▆▃▃▂▂▃▂▁▂▃▁▂▄▄▃▄▂▄▅▁▁▄▄▁▂▁▄▂▄▃▄
wandb:       val_loss ▁▁▁▁▂▂▁▂▁▂▃▂▂▃▃▄▁█▁▂▄▂▂▂▃▆▃▂▂▂▅▃▃█▁
wandb: 
wandb: Run summary:
wandb:          epoch 34
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.8321
wandb:     train_loss 0.24276
wandb:   val_accuracy 0.36222
wandb:       val_loss 0.50109
wandb: 
wandb: 🚀 View run stellar-glitter-95 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x2ruixep
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_105522-x2ruixep/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_110349-jbpbh0a5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-puddle-96
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jbpbh0a5
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:20:36, 16.91s/it]  0%|          | 2/500 [00:29<1:58:36, 14.29s/it]  1%|          | 3/500 [00:40<1:46:51, 12.90s/it]  1%|          | 4/500 [00:51<1:40:58, 12.21s/it]  1%|          | 5/500 [01:02<1:37:24, 11.81s/it]  1%|          | 6/500 [01:13<1:34:09, 11.44s/it]  1%|▏         | 7/500 [01:24<1:32:45, 11.29s/it]  2%|▏         | 8/500 [01:35<1:31:23, 11.15s/it]  2%|▏         | 9/500 [01:46<1:31:10, 11.14s/it]  2%|▏         | 10/500 [01:57<1:30:34, 11.09s/it]  2%|▏         | 11/500 [02:08<1:29:33, 10.99s/it]  2%|▏         | 12/500 [02:19<1:29:17, 10.98s/it]  3%|▎         | 13/500 [02:29<1:28:12, 10.87s/it]  3%|▎         | 14/500 [02:40<1:27:49, 10.84s/it]  3%|▎         | 15/500 [02:51<1:26:47, 10.74s/it]  3%|▎         | 16/500 [03:01<1:26:33, 10.73s/it]  3%|▎         | 17/500 [03:11<1:24:17, 10.47s/it]  4%|▎         | 18/500 [03:22<1:24:11, 10.48s/it]  4%|▍         | 19/500 [03:33<1:25:33, 10.67s/it]  4%|▍         | 20/500 [03:44<1:26:17, 10.79s/it]  4%|▍         | 21/500 [03:56<1:28:12, 11.05s/it]  4%|▍         | 22/500 [04:08<1:31:18, 11.46s/it]  5%|▍         | 23/500 [04:20<1:32:47, 11.67s/it]  5%|▍         | 24/500 [04:31<1:31:23, 11.52s/it]  5%|▌         | 25/500 [04:42<1:29:16, 11.28s/it]  5%|▌         | 26/500 [04:53<1:28:12, 11.17s/it]  5%|▌         | 27/500 [05:04<1:27:10, 11.06s/it]  6%|▌         | 28/500 [05:14<1:26:09, 10.95s/it]  6%|▌         | 29/500 [05:25<1:25:40, 10.91s/it]  6%|▌         | 30/500 [05:36<1:24:50, 10.83s/it]  6%|▌         | 31/500 [05:47<1:24:47, 10.85s/it]  6%|▋         | 32/500 [05:57<1:24:20, 10.81s/it]  7%|▋         | 33/500 [06:08<1:23:44, 10.76s/it]  7%|▋         | 34/500 [06:19<1:23:31, 10.75s/it]  7%|▋         | 35/500 [06:30<1:23:06, 10.72s/it]  7%|▋         | 36/500 [06:41<1:24:05, 10.87s/it]  7%|▋         | 37/500 [06:52<1:23:50, 10.87s/it]  8%|▊         | 38/500 [07:02<1:23:45, 10.88s/it]  8%|▊         | 39/500 [07:13<1:22:53, 10.79s/it]  8%|▊         | 40/500 [07:24<1:22:24, 10.75s/it]  8%|▊         | 41/500 [07:34<1:22:05, 10.73s/it]  8%|▊         | 42/500 [07:45<1:20:53, 10.60s/it]  9%|▊         | 43/500 [07:55<1:20:35, 10.58s/it]  9%|▉         | 44/500 [08:06<1:19:54, 10.51s/it]  9%|▉         | 45/500 [08:16<1:19:49, 10.53s/it]  9%|▉         | 46/500 [08:27<1:19:48, 10.55s/it]  9%|▉         | 47/500 [08:38<1:20:47, 10.70s/it] 10%|▉         | 48/500 [08:48<1:19:34, 10.56s/it] 10%|▉         | 49/500 [08:58<1:18:06, 10.39s/it] 10%|█         | 50/500 [09:08<1:17:39, 10.35s/it] 10%|█         | 51/500 [09:19<1:17:41, 10.38s/it] 10%|█         | 52/500 [09:30<1:19:09, 10.60s/it] 11%|█         | 53/500 [09:41<1:19:25, 10.66s/it] 11%|█         | 54/500 [09:52<1:20:27, 10.82s/it] 11%|█         | 55/500 [10:02<1:19:40, 10.74s/it] 11%|█         | 56/500 [10:13<1:19:41, 10.77s/it] 11%|█▏        | 57/500 [10:24<1:20:24, 10.89s/it] 12%|█▏        | 58/500 [10:35<1:19:26, 10.78s/it] 12%|█▏        | 59/500 [10:46<1:19:14, 10.78s/it] 12%|█▏        | 60/500 [10:56<1:18:24, 10.69s/it] 12%|█▏        | 61/500 [11:07<1:17:47, 10.63s/it] 12%|█▏        | 62/500 [11:17<1:17:39, 10.64s/it] 13%|█▎        | 63/500 [11:28<1:17:24, 10.63s/it] 13%|█▎        | 64/500 [11:39<1:18:37, 10.82s/it] 13%|█▎        | 65/500 [11:50<1:18:15, 10.79s/it] 13%|█▎        | 66/500 [12:01<1:17:48, 10.76s/it] 13%|█▎        | 67/500 [12:11<1:17:24, 10.73s/it] 14%|█▎        | 68/500 [12:22<1:16:30, 10.63s/it] 14%|█▍        | 69/500 [12:32<1:15:51, 10.56s/it] 14%|█▍        | 70/500 [12:43<1:16:03, 10.61s/it] 14%|█▍        | 71/500 [12:54<1:16:09, 10.65s/it] 14%|█▍        | 72/500 [13:04<1:15:27, 10.58s/it] 15%|█▍        | 73/500 [13:15<1:15:09, 10.56s/it] 15%|█▍        | 74/500 [13:25<1:14:34, 10.50s/it] 15%|█▍        | 74/500 [13:25<1:17:16, 10.88s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.010 MB of 0.312 MB uploadedwandb: - 0.234 MB of 0.312 MB uploadedwandb: \ 0.234 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▇▆▇█▇▇██▇█▇▇▇▇█▇███████▇█████████▇███
wandb:     train_loss ▄▄█▂▁▁▂▁▁▂▃▂▅▁▂▁▆▄▂▁▁▁▁▂▁▁▂▁▂▁▁▁▂▁▁▁█▁▁▂
wandb:   val_accuracy ▁▃▁▁▇▆▇▇▇██▇▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇▇█▇▇
wandb:       val_loss ▂▃▁▄▁▃▃▆▃▅▁▄▆█▅▁▃▁█▇▄▃▄▁▁▂▄▇▂▁▁▅▅▄▂▁▁▅▆▅
wandb: 
wandb: Run summary:
wandb:          epoch 73
wandb:  learning_rate 0.0
wandb: train_accuracy 0.97623
wandb:     train_loss 0.22211
wandb:   val_accuracy 0.53556
wandb:       val_loss 6.61594
wandb: 
wandb: 🚀 View run cerulean-puddle-96 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jbpbh0a5
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_110349-jbpbh0a5/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_111805-vklx1fjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-firebrand-97
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/vklx1fjp
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:14:28, 16.17s/it]  0%|          | 2/500 [00:30<2:03:54, 14.93s/it]  1%|          | 3/500 [00:42<1:55:21, 13.93s/it]  1%|          | 4/500 [00:57<1:55:30, 13.97s/it]  1%|          | 5/500 [01:10<1:53:54, 13.81s/it]  1%|          | 6/500 [01:23<1:51:43, 13.57s/it]  1%|▏         | 7/500 [01:37<1:53:35, 13.82s/it]  2%|▏         | 8/500 [01:52<1:54:17, 13.94s/it]  2%|▏         | 9/500 [02:06<1:55:01, 14.06s/it]  2%|▏         | 10/500 [02:21<1:56:30, 14.27s/it]  2%|▏         | 11/500 [02:36<1:57:40, 14.44s/it]  2%|▏         | 12/500 [02:50<1:56:23, 14.31s/it]  3%|▎         | 13/500 [03:04<1:55:24, 14.22s/it]  3%|▎         | 14/500 [03:17<1:54:24, 14.12s/it]  3%|▎         | 15/500 [03:32<1:55:29, 14.29s/it]  3%|▎         | 16/500 [03:47<1:55:50, 14.36s/it]  3%|▎         | 17/500 [04:01<1:55:00, 14.29s/it]  4%|▎         | 18/500 [04:16<1:56:48, 14.54s/it]  4%|▍         | 19/500 [04:32<1:59:19, 14.89s/it]  4%|▍         | 20/500 [04:47<1:59:43, 14.97s/it]  4%|▍         | 21/500 [05:02<1:59:28, 14.96s/it]  4%|▍         | 22/500 [05:17<1:59:18, 14.98s/it]  5%|▍         | 23/500 [05:31<1:57:34, 14.79s/it]  5%|▍         | 24/500 [05:46<1:58:10, 14.90s/it]  5%|▌         | 25/500 [06:01<1:57:37, 14.86s/it]  5%|▌         | 26/500 [06:16<1:56:54, 14.80s/it]  5%|▌         | 26/500 [06:16<1:54:17, 14.47s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.305 MB uploadedwandb: / 0.010 MB of 0.305 MB uploadedwandb: - 0.230 MB of 0.305 MB uploadedwandb: \ 0.305 MB of 0.305 MB uploadedwandb: | 0.305 MB of 0.305 MB uploadedwandb: / 0.305 MB of 0.305 MB uploadedwandb: - 0.305 MB of 0.305 MB uploadedwandb: \ 0.305 MB of 0.305 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁
wandb: train_accuracy ▁▆▂▃▂▄▁▇▂▅▃▄▇▃▇▅▅█▅▃▇▆▆█▇█
wandb:     train_loss ▃▃▃▆▆▁▁▁▁▁▃▄▂▂▁▁▅▁▂█▂▁▂▁▁▁
wandb:   val_accuracy ▁▆▃▃▂▆▁▇▅█▅▂▅▂▅▂▇▆▇▆▇▇▅█▇█
wandb:       val_loss ▂▂▃▂▁▂▇▁▁▁▁▃▃█▁▅▄▄▂▄▁▆▇▅▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 25
wandb:  learning_rate 0.00025
wandb: train_accuracy 0.93759
wandb:     train_loss 0.06844
wandb:   val_accuracy 0.56
wandb:       val_loss 0.34956
wandb: 
wandb: 🚀 View run peach-firebrand-97 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/vklx1fjp
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_111805-vklx1fjp/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_112508-tynmhtcl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-morning-98
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tynmhtcl
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:11:19, 15.79s/it]  0%|          | 2/500 [00:29<1:59:41, 14.42s/it]  1%|          | 3/500 [00:42<1:53:56, 13.75s/it]  1%|          | 4/500 [00:54<1:50:09, 13.33s/it]  1%|          | 5/500 [01:07<1:48:59, 13.21s/it]  1%|          | 6/500 [01:20<1:47:33, 13.06s/it]  1%|▏         | 7/500 [01:33<1:45:37, 12.86s/it]  2%|▏         | 8/500 [01:46<1:45:47, 12.90s/it]  2%|▏         | 9/500 [01:58<1:44:12, 12.73s/it]  2%|▏         | 10/500 [02:10<1:42:18, 12.53s/it]  2%|▏         | 11/500 [02:23<1:42:56, 12.63s/it]  2%|▏         | 12/500 [02:35<1:42:14, 12.57s/it]  3%|▎         | 13/500 [02:48<1:41:19, 12.48s/it]  3%|▎         | 14/500 [03:00<1:39:51, 12.33s/it]  3%|▎         | 15/500 [03:12<1:40:21, 12.42s/it]  3%|▎         | 16/500 [03:24<1:38:54, 12.26s/it]  3%|▎         | 17/500 [03:37<1:39:43, 12.39s/it]  4%|▎         | 18/500 [03:49<1:40:07, 12.46s/it]  4%|▍         | 19/500 [04:01<1:38:56, 12.34s/it]  4%|▍         | 20/500 [04:14<1:38:04, 12.26s/it]  4%|▍         | 21/500 [04:26<1:37:52, 12.26s/it]  4%|▍         | 22/500 [04:39<1:39:39, 12.51s/it]  5%|▍         | 23/500 [04:52<1:40:15, 12.61s/it]  5%|▍         | 24/500 [05:04<1:40:06, 12.62s/it]  5%|▌         | 25/500 [05:16<1:37:53, 12.37s/it]  5%|▌         | 26/500 [05:29<1:38:07, 12.42s/it]  5%|▌         | 27/500 [05:41<1:36:49, 12.28s/it]  6%|▌         | 28/500 [05:52<1:35:20, 12.12s/it]  6%|▌         | 29/500 [06:05<1:37:18, 12.40s/it]  6%|▌         | 30/500 [06:19<1:40:39, 12.85s/it]  6%|▌         | 31/500 [06:32<1:41:06, 12.94s/it]  6%|▋         | 32/500 [06:46<1:42:38, 13.16s/it]  7%|▋         | 33/500 [07:00<1:43:13, 13.26s/it]  7%|▋         | 34/500 [07:13<1:42:16, 13.17s/it]  7%|▋         | 35/500 [07:27<1:44:37, 13.50s/it]  7%|▋         | 36/500 [07:40<1:43:32, 13.39s/it]  7%|▋         | 37/500 [07:54<1:44:36, 13.56s/it]  8%|▊         | 38/500 [08:08<1:44:36, 13.59s/it]  8%|▊         | 39/500 [08:21<1:43:33, 13.48s/it]  8%|▊         | 40/500 [08:34<1:41:40, 13.26s/it]  8%|▊         | 41/500 [08:47<1:41:51, 13.32s/it]  8%|▊         | 42/500 [09:00<1:41:53, 13.35s/it]  9%|▊         | 43/500 [09:14<1:42:31, 13.46s/it]  9%|▉         | 44/500 [09:27<1:41:37, 13.37s/it]  9%|▉         | 45/500 [09:41<1:41:10, 13.34s/it]  9%|▉         | 46/500 [09:55<1:42:56, 13.61s/it]  9%|▉         | 47/500 [10:08<1:42:39, 13.60s/it] 10%|▉         | 48/500 [10:22<1:42:40, 13.63s/it] 10%|▉         | 49/500 [10:35<1:41:19, 13.48s/it] 10%|█         | 50/500 [10:48<1:39:42, 13.29s/it] 10%|█         | 51/500 [11:02<1:40:31, 13.43s/it] 10%|█         | 52/500 [11:16<1:41:10, 13.55s/it] 11%|█         | 53/500 [11:30<1:41:39, 13.65s/it] 11%|█         | 54/500 [11:43<1:41:30, 13.66s/it] 11%|█         | 55/500 [11:58<1:43:00, 13.89s/it] 11%|█         | 56/500 [12:11<1:41:34, 13.73s/it] 11%|█▏        | 57/500 [12:25<1:42:18, 13.86s/it] 12%|█▏        | 58/500 [12:39<1:41:54, 13.83s/it] 12%|█▏        | 59/500 [12:53<1:41:15, 13.78s/it] 12%|█▏        | 60/500 [13:07<1:42:32, 13.98s/it] 12%|█▏        | 61/500 [13:21<1:42:05, 13.95s/it] 12%|█▏        | 62/500 [13:35<1:42:33, 14.05s/it] 12%|█▏        | 62/500 [13:35<1:36:02, 13.16s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.317 MB uploadedwandb: | 0.019 MB of 0.317 MB uploadedwandb: / 0.317 MB of 0.317 MB uploadedwandb: - 0.317 MB of 0.317 MB uploadedwandb: \ 0.317 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ██████▄▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▃▄▅▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇███████▇███████████
wandb:     train_loss ▇▄▆▇▆▇▆▃▆▇▇▂▇█▄▅▇▇▅▅█▁▂▄▂▄▄▄▁▇▂█▇▄▇▂▅▄▅█
wandb:   val_accuracy ▂▁▅▇▆▆▆▆▆▆▆▆▆▆▆▇▆▇▆▇▇▇█▇▇▇▇█▇▇█▇▇▇███▇█▇
wandb:       val_loss ▁▂▁▂▂▁▄▂▁▂▃▃▁▄▇▃▃▂▂▃▁▅▄▃▄▁▅▆▄▁▆▂█▁▃▁▂▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 61
wandb:  learning_rate 0.0
wandb: train_accuracy 0.67608
wandb:     train_loss 1.2662
wandb:   val_accuracy 0.46889
wandb:       val_loss 2.55034
wandb: 
wandb: 🚀 View run tough-morning-98 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/tynmhtcl
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_112508-tynmhtcl/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_113926-r1g5rp13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-moon-99
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/r1g5rp13
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:42:48, 19.58s/it]  0%|          | 2/500 [00:33<2:14:13, 16.17s/it]  1%|          | 3/500 [00:47<2:06:33, 15.28s/it]  1%|          | 4/500 [01:01<2:02:50, 14.86s/it]  1%|          | 5/500 [01:15<1:58:02, 14.31s/it]  1%|          | 6/500 [01:30<1:59:36, 14.53s/it]  1%|▏         | 7/500 [01:44<1:58:20, 14.40s/it]  2%|▏         | 8/500 [01:57<1:53:53, 13.89s/it]  2%|▏         | 9/500 [02:09<1:50:27, 13.50s/it]  2%|▏         | 10/500 [02:22<1:49:32, 13.41s/it]  2%|▏         | 11/500 [02:36<1:49:16, 13.41s/it]  2%|▏         | 12/500 [02:49<1:48:18, 13.32s/it]  3%|▎         | 13/500 [03:02<1:47:49, 13.29s/it]  3%|▎         | 14/500 [03:15<1:46:48, 13.19s/it]  3%|▎         | 15/500 [03:29<1:47:23, 13.29s/it]  3%|▎         | 16/500 [03:43<1:50:47, 13.73s/it]  3%|▎         | 17/500 [03:56<1:47:46, 13.39s/it]  4%|▎         | 18/500 [04:10<1:49:18, 13.61s/it]  4%|▍         | 19/500 [04:24<1:51:00, 13.85s/it]  4%|▍         | 20/500 [04:38<1:51:14, 13.91s/it]  4%|▍         | 21/500 [04:52<1:49:41, 13.74s/it]  4%|▍         | 22/500 [05:05<1:48:05, 13.57s/it]  5%|▍         | 23/500 [05:18<1:47:40, 13.54s/it]  5%|▍         | 24/500 [05:30<1:43:08, 13.00s/it]  5%|▌         | 25/500 [05:41<1:38:33, 12.45s/it]  5%|▌         | 26/500 [05:53<1:37:19, 12.32s/it]  5%|▌         | 27/500 [06:06<1:38:40, 12.52s/it]  6%|▌         | 28/500 [06:19<1:38:51, 12.57s/it]  6%|▌         | 29/500 [06:32<1:38:53, 12.60s/it]  6%|▌         | 30/500 [06:44<1:38:06, 12.52s/it]  6%|▌         | 31/500 [06:57<1:38:26, 12.59s/it]  6%|▋         | 32/500 [07:11<1:41:08, 12.97s/it]  6%|▋         | 32/500 [07:11<1:45:06, 13.48s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.028 MB uploadedwandb: - 0.010 MB of 0.313 MB uploadedwandb: \ 0.021 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁
wandb: train_accuracy ▁▁▄▂▃▅▄▅▇▇▇▇█▆█▆▇▇▇▇▇▇▇███▇▇▇▇██
wandb:     train_loss ▄▄▃▁▅▃▂▁▁▁▁▆▁▁▂█▂▁▂▂▂▁▂▁▁▁▂▁▁▁▁▂
wandb:   val_accuracy ▁▃▃▁▁▁▂▂▅▆▆▄█▄█▆█▇▇▅▇▇▇▇▇▆▆▆▇▆▇▆
wandb:       val_loss ▁▁▁▂▂▁▁▁▁▂▁▃▅▃▅▁▁▄▁▂▂▁▂▃▃▁▄█▁▂▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 31
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.96434
wandb:     train_loss 0.43045
wandb:   val_accuracy 0.49111
wandb:       val_loss 0.00368
wandb: 
wandb: 🚀 View run rare-moon-99 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/r1g5rp13
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_113926-r1g5rp13/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_114731-4erraxjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-monkey-100
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4erraxjj
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:20<2:49:23, 20.37s/it]  0%|          | 2/500 [00:33<2:14:22, 16.19s/it]  1%|          | 3/500 [00:46<2:01:26, 14.66s/it]  1%|          | 4/500 [00:59<1:56:01, 14.03s/it]  1%|          | 5/500 [01:12<1:52:22, 13.62s/it]  1%|          | 6/500 [01:24<1:48:50, 13.22s/it]  1%|▏         | 7/500 [01:37<1:48:07, 13.16s/it]  2%|▏         | 8/500 [01:51<1:49:34, 13.36s/it]  2%|▏         | 9/500 [02:04<1:48:07, 13.21s/it]  2%|▏         | 10/500 [02:17<1:46:42, 13.07s/it]  2%|▏         | 11/500 [02:30<1:46:18, 13.04s/it]  2%|▏         | 12/500 [02:43<1:45:25, 12.96s/it]  3%|▎         | 13/500 [02:55<1:44:38, 12.89s/it]  3%|▎         | 14/500 [03:08<1:44:23, 12.89s/it]  3%|▎         | 15/500 [03:21<1:43:07, 12.76s/it]  3%|▎         | 16/500 [03:32<1:39:57, 12.39s/it]  3%|▎         | 17/500 [03:43<1:36:19, 11.96s/it]  4%|▎         | 18/500 [03:54<1:33:35, 11.65s/it]  4%|▍         | 19/500 [04:05<1:31:10, 11.37s/it]  4%|▍         | 20/500 [04:16<1:31:38, 11.45s/it]  4%|▍         | 21/500 [04:30<1:35:31, 11.97s/it]  4%|▍         | 22/500 [04:41<1:33:58, 11.80s/it]  5%|▍         | 23/500 [04:53<1:33:07, 11.71s/it]  5%|▍         | 24/500 [05:04<1:32:41, 11.68s/it]  5%|▌         | 25/500 [05:16<1:32:10, 11.64s/it]  5%|▌         | 26/500 [05:27<1:31:41, 11.61s/it]  5%|▌         | 27/500 [05:39<1:31:51, 11.65s/it]  6%|▌         | 28/500 [05:50<1:31:19, 11.61s/it]  6%|▌         | 29/500 [06:02<1:31:58, 11.72s/it]  6%|▌         | 30/500 [06:15<1:33:02, 11.88s/it]  6%|▌         | 31/500 [06:27<1:33:01, 11.90s/it]  6%|▋         | 32/500 [06:39<1:33:36, 12.00s/it]  7%|▋         | 33/500 [06:51<1:33:39, 12.03s/it]  7%|▋         | 34/500 [07:02<1:32:03, 11.85s/it]  7%|▋         | 35/500 [07:14<1:31:11, 11.77s/it]  7%|▋         | 36/500 [07:26<1:30:42, 11.73s/it]  7%|▋         | 37/500 [07:37<1:29:40, 11.62s/it]  8%|▊         | 38/500 [07:48<1:29:01, 11.56s/it]  8%|▊         | 39/500 [08:00<1:28:02, 11.46s/it]  8%|▊         | 40/500 [08:11<1:27:02, 11.35s/it]  8%|▊         | 41/500 [08:22<1:27:09, 11.39s/it]  8%|▊         | 42/500 [08:34<1:27:17, 11.44s/it]  9%|▊         | 43/500 [08:45<1:26:50, 11.40s/it]  9%|▉         | 44/500 [08:56<1:26:18, 11.36s/it]  9%|▉         | 45/500 [09:08<1:27:39, 11.56s/it]  9%|▉         | 46/500 [09:20<1:27:22, 11.55s/it]  9%|▉         | 47/500 [09:32<1:27:42, 11.62s/it] 10%|▉         | 48/500 [09:44<1:27:56, 11.67s/it] 10%|▉         | 49/500 [09:55<1:26:53, 11.56s/it] 10%|█         | 50/500 [10:06<1:26:45, 11.57s/it] 10%|█         | 51/500 [10:18<1:25:47, 11.46s/it] 10%|█         | 52/500 [10:29<1:25:41, 11.48s/it] 11%|█         | 53/500 [10:40<1:25:03, 11.42s/it] 11%|█         | 53/500 [10:40<1:30:05, 12.09s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.138 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▄▆▇▅▅▇▇▇▇███▇▇█▇█▇▇▇▇█▇▇█▇▇▇█▇██▇████▇
wandb:     train_loss ▄▄▄▃▁▂▁▁▃▁▁▆▂▁▂▁▁▂▁▁▂▁▂▃▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▃▂▅▅▄▇▇▇▇▇▇▇▆▇█▆▇▇▆▆▆▇▇▇▇█▇▆▇▇▇▇▇▇▇▇▆▇
wandb:       val_loss ▁▂▁▂▂▁▂▃▁▁▃▃▁█▁▁▂▁▁▁▂▁▄▁▄▃▁▁▁▁▃▁▁▁▁▃▁▂▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 52
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.87964
wandb:     train_loss 0.05923
wandb:   val_accuracy 0.70222
wandb:       val_loss 0.32663
wandb: 
wandb: 🚀 View run stilted-monkey-100 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/4erraxjj
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_114731-4erraxjj/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_115902-6j5pzmja
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-yogurt-101
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6j5pzmja
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:42:12, 19.50s/it]  0%|          | 2/500 [00:34<2:19:03, 16.75s/it]  1%|          | 3/500 [00:48<2:08:24, 15.50s/it]  1%|          | 4/500 [01:01<1:59:14, 14.43s/it]  1%|          | 5/500 [01:13<1:52:48, 13.67s/it]  1%|          | 6/500 [01:26<1:51:20, 13.52s/it]  1%|▏         | 7/500 [01:39<1:47:59, 13.14s/it]  2%|▏         | 8/500 [01:51<1:46:30, 12.99s/it]  2%|▏         | 9/500 [02:05<1:48:42, 13.28s/it]  2%|▏         | 10/500 [02:18<1:47:11, 13.13s/it]  2%|▏         | 11/500 [02:31<1:47:37, 13.20s/it]  2%|▏         | 12/500 [02:44<1:46:40, 13.12s/it]  3%|▎         | 13/500 [02:57<1:46:43, 13.15s/it]  3%|▎         | 14/500 [03:11<1:47:13, 13.24s/it]  3%|▎         | 15/500 [03:24<1:46:45, 13.21s/it]  3%|▎         | 16/500 [03:37<1:46:43, 13.23s/it]  3%|▎         | 17/500 [03:52<1:50:00, 13.66s/it]  4%|▎         | 18/500 [04:05<1:47:49, 13.42s/it]  4%|▍         | 19/500 [04:18<1:47:35, 13.42s/it]  4%|▍         | 20/500 [04:34<1:52:24, 14.05s/it]  4%|▍         | 21/500 [04:48<1:53:03, 14.16s/it]  4%|▍         | 22/500 [05:03<1:53:15, 14.22s/it]  5%|▍         | 23/500 [05:17<1:52:45, 14.18s/it]  5%|▍         | 24/500 [05:31<1:52:23, 14.17s/it]  5%|▌         | 25/500 [05:44<1:50:31, 13.96s/it]  5%|▌         | 26/500 [05:59<1:51:28, 14.11s/it]  5%|▌         | 27/500 [06:13<1:50:33, 14.02s/it]  6%|▌         | 28/500 [06:27<1:50:27, 14.04s/it]  6%|▌         | 29/500 [06:40<1:48:03, 13.77s/it]  6%|▌         | 30/500 [06:54<1:48:05, 13.80s/it]  6%|▌         | 31/500 [07:07<1:46:27, 13.62s/it]  6%|▋         | 32/500 [07:20<1:45:27, 13.52s/it]  7%|▋         | 33/500 [07:34<1:46:36, 13.70s/it]  7%|▋         | 34/500 [07:48<1:46:03, 13.66s/it]  7%|▋         | 35/500 [08:01<1:45:10, 13.57s/it]  7%|▋         | 36/500 [08:14<1:43:32, 13.39s/it]  7%|▋         | 37/500 [08:28<1:43:20, 13.39s/it]  8%|▊         | 38/500 [08:42<1:45:32, 13.71s/it]  8%|▊         | 39/500 [08:56<1:46:14, 13.83s/it]  8%|▊         | 40/500 [09:10<1:47:05, 13.97s/it]  8%|▊         | 41/500 [09:24<1:46:56, 13.98s/it]  8%|▊         | 42/500 [09:37<1:44:18, 13.67s/it]  9%|▊         | 43/500 [09:51<1:43:24, 13.58s/it]  9%|▉         | 44/500 [10:04<1:42:03, 13.43s/it]  9%|▉         | 45/500 [10:19<1:46:34, 14.05s/it]  9%|▉         | 46/500 [10:35<1:50:53, 14.65s/it]  9%|▉         | 47/500 [10:50<1:49:50, 14.55s/it] 10%|▉         | 48/500 [11:03<1:47:17, 14.24s/it] 10%|▉         | 48/500 [11:03<1:44:09, 13.83s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.316 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.138 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ████████▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▂▂▃▅▂▄▆▇▇▇▆▆▇▃▂▂▁▃▆█▇▂▄█▆▄█▆▅█▄▄███▆▆▆
wandb:     train_loss ▅▅▅▅▅▅▅▄▃▃▄▄▄▆▆██▅▁▅▄▂▅▆▅▃▇▃▅▃▄▂▄▅▃▃▃▃▅▂
wandb:   val_accuracy ▃▃▁▄▄▆▄▇▇▆▇▆▆▆▆▆▄▅▃▅▆▇▆▆▆█▆▆█▆▆▇▆▆▇██▆▆▆
wandb:       val_loss ▂▂▂▂▂▁▂▁█▂▂▄▄▂▁▁▃▃▅▆▃█▃▂▂▁▁▂▂▁▂▂▆▃▅▅▁▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 47
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.67608
wandb:     train_loss 0.4627
wandb:   val_accuracy 0.39556
wandb:       val_loss 0.94338
wandb: 
wandb: 🚀 View run gallant-yogurt-101 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6j5pzmja
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_115902-6j5pzmja/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_121054-9rzb9emn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-plant-102
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9rzb9emn
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:12:11, 15.90s/it]  0%|          | 2/500 [00:31<2:09:59, 15.66s/it]  1%|          | 3/500 [00:45<2:04:27, 15.02s/it]  1%|          | 4/500 [00:58<1:57:37, 14.23s/it]  1%|          | 5/500 [01:12<1:56:41, 14.14s/it]  1%|          | 6/500 [01:25<1:51:31, 13.55s/it]  1%|▏         | 7/500 [01:40<1:56:20, 14.16s/it]  2%|▏         | 8/500 [01:53<1:53:24, 13.83s/it]  2%|▏         | 9/500 [02:06<1:51:13, 13.59s/it]  2%|▏         | 10/500 [02:21<1:53:30, 13.90s/it]  2%|▏         | 11/500 [02:35<1:54:37, 14.06s/it]  2%|▏         | 12/500 [02:49<1:52:53, 13.88s/it]  3%|▎         | 13/500 [03:02<1:51:39, 13.76s/it]  3%|▎         | 14/500 [03:16<1:51:01, 13.71s/it]  3%|▎         | 15/500 [03:31<1:54:10, 14.13s/it]  3%|▎         | 16/500 [03:44<1:52:23, 13.93s/it]  3%|▎         | 17/500 [03:57<1:49:14, 13.57s/it]  4%|▎         | 18/500 [04:10<1:48:06, 13.46s/it]  4%|▍         | 19/500 [04:25<1:52:07, 13.99s/it]  4%|▍         | 20/500 [04:41<1:56:29, 14.56s/it]  4%|▍         | 21/500 [04:57<1:58:52, 14.89s/it]  4%|▍         | 22/500 [05:11<1:57:01, 14.69s/it]  5%|▍         | 23/500 [05:27<1:59:13, 15.00s/it]  5%|▍         | 24/500 [05:41<1:57:15, 14.78s/it]  5%|▌         | 25/500 [05:53<1:49:35, 13.84s/it]  5%|▌         | 26/500 [06:05<1:44:17, 13.20s/it]  5%|▌         | 27/500 [06:17<1:41:10, 12.83s/it]  6%|▌         | 28/500 [06:29<1:39:29, 12.65s/it]  6%|▌         | 29/500 [06:43<1:44:02, 13.25s/it]  6%|▌         | 30/500 [06:56<1:42:49, 13.13s/it]  6%|▌         | 31/500 [07:10<1:43:56, 13.30s/it]  6%|▋         | 32/500 [07:22<1:41:49, 13.06s/it]  7%|▋         | 33/500 [07:35<1:39:30, 12.78s/it]  7%|▋         | 34/500 [07:48<1:39:36, 12.83s/it]  7%|▋         | 35/500 [08:01<1:40:15, 12.94s/it]  7%|▋         | 36/500 [08:13<1:39:25, 12.86s/it]  7%|▋         | 37/500 [08:26<1:38:15, 12.73s/it]  8%|▊         | 38/500 [08:38<1:36:56, 12.59s/it]  8%|▊         | 39/500 [08:51<1:37:05, 12.64s/it]  8%|▊         | 40/500 [09:04<1:37:35, 12.73s/it]  8%|▊         | 41/500 [09:17<1:39:20, 12.99s/it]  8%|▊         | 41/500 [09:17<1:44:05, 13.61s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.310 MB uploadedwandb: - 0.021 MB of 0.310 MB uploadedwandb: \ 0.231 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb: / 0.310 MB of 0.310 MB uploadedwandb: - 0.310 MB of 0.310 MB uploadedwandb: \ 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▂▁▂▂▁▃▁▂▁▁▃▁▁█▁▁▁▁▁█▃█▂▅▁█▄█▇▃▂▇▃█▄█▇▄▄
wandb:     train_loss ▂▂▂▁▁▁▁█▁▂▅▃▁▅▁▅▅▁█▅▁▁▁▃▂▃▁▁▁▂▂▄▁▃▁▄▁▁▁▁
wandb:   val_accuracy ▁▄▂▁▆▂▂▂▆▂▂▂▂▁▆▄▂▁▂▃▇▆█▃▇▃▇▆▅▇▅▅▇▆▇▆▇▇▆▆
wandb:       val_loss ▁▃▂▂▁▅▁▄▁▂▄▃▅▇▃▃▄▇█▃▁▃▂▄▁▂▃▃▃▂▄▁▃▄▁▅▁▁▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.50966
wandb:     train_loss 0.00015
wandb:   val_accuracy 0.51556
wandb:       val_loss 0.30751
wandb: 
wandb: 🚀 View run eternal-plant-102 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9rzb9emn
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_121054-9rzb9emn/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_122103-6nepfdxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-moon-103
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6nepfdxy
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:11:53, 15.86s/it]  0%|          | 2/500 [00:29<1:59:58, 14.45s/it]  1%|          | 3/500 [00:41<1:52:47, 13.62s/it]  1%|          | 4/500 [00:54<1:49:04, 13.19s/it]  1%|          | 5/500 [01:07<1:47:13, 13.00s/it]  1%|          | 6/500 [01:19<1:45:05, 12.76s/it]  1%|▏         | 7/500 [01:30<1:40:44, 12.26s/it]  2%|▏         | 8/500 [01:41<1:36:52, 11.81s/it]  2%|▏         | 9/500 [01:52<1:34:27, 11.54s/it]  2%|▏         | 10/500 [02:05<1:37:04, 11.89s/it]  2%|▏         | 11/500 [02:17<1:37:44, 11.99s/it]  2%|▏         | 12/500 [02:33<1:48:34, 13.35s/it]  3%|▎         | 13/500 [02:46<1:46:45, 13.15s/it]  3%|▎         | 14/500 [02:59<1:46:55, 13.20s/it]  3%|▎         | 15/500 [03:12<1:44:37, 12.94s/it]  3%|▎         | 16/500 [03:25<1:44:14, 12.92s/it]  3%|▎         | 17/500 [03:37<1:42:40, 12.76s/it]  4%|▎         | 18/500 [03:49<1:41:59, 12.70s/it]  4%|▍         | 19/500 [04:02<1:41:00, 12.60s/it]  4%|▍         | 20/500 [04:14<1:40:15, 12.53s/it]  4%|▍         | 21/500 [04:27<1:40:31, 12.59s/it]  4%|▍         | 22/500 [04:40<1:41:39, 12.76s/it]  5%|▍         | 23/500 [04:53<1:41:06, 12.72s/it]  5%|▍         | 24/500 [05:05<1:39:21, 12.52s/it]  5%|▌         | 25/500 [05:18<1:40:05, 12.64s/it]  5%|▌         | 26/500 [05:30<1:38:41, 12.49s/it]  5%|▌         | 27/500 [05:43<1:39:39, 12.64s/it]  6%|▌         | 28/500 [05:56<1:40:42, 12.80s/it]  6%|▌         | 29/500 [06:10<1:42:20, 13.04s/it]  6%|▌         | 30/500 [06:22<1:40:34, 12.84s/it]  6%|▌         | 31/500 [06:35<1:40:28, 12.85s/it]  6%|▋         | 32/500 [06:48<1:40:33, 12.89s/it]  7%|▋         | 33/500 [07:00<1:37:48, 12.57s/it]  7%|▋         | 34/500 [07:12<1:37:29, 12.55s/it]  7%|▋         | 35/500 [07:24<1:36:31, 12.45s/it]  7%|▋         | 36/500 [07:38<1:38:10, 12.69s/it]  7%|▋         | 37/500 [07:50<1:36:25, 12.50s/it]  8%|▊         | 38/500 [08:02<1:36:10, 12.49s/it]  8%|▊         | 39/500 [08:16<1:37:54, 12.74s/it]  8%|▊         | 40/500 [08:28<1:37:46, 12.75s/it]  8%|▊         | 41/500 [08:40<1:36:15, 12.58s/it]  8%|▊         | 42/500 [08:53<1:35:06, 12.46s/it]  9%|▊         | 43/500 [09:03<1:30:57, 11.94s/it]  9%|▉         | 44/500 [09:14<1:28:17, 11.62s/it]  9%|▉         | 45/500 [09:25<1:26:43, 11.44s/it]  9%|▉         | 46/500 [09:37<1:27:55, 11.62s/it]  9%|▉         | 47/500 [09:49<1:27:39, 11.61s/it] 10%|▉         | 48/500 [10:01<1:29:09, 11.83s/it] 10%|▉         | 49/500 [10:14<1:31:05, 12.12s/it] 10%|█         | 50/500 [10:26<1:31:02, 12.14s/it] 10%|█         | 51/500 [10:39<1:32:33, 12.37s/it] 10%|█         | 52/500 [10:51<1:32:00, 12.32s/it] 11%|█         | 53/500 [11:04<1:33:05, 12.49s/it] 11%|█         | 54/500 [11:18<1:35:54, 12.90s/it] 11%|█         | 55/500 [11:31<1:36:36, 13.03s/it] 11%|█         | 56/500 [11:45<1:38:04, 13.25s/it] 11%|█▏        | 57/500 [11:59<1:38:18, 13.31s/it] 12%|█▏        | 58/500 [12:10<1:34:40, 12.85s/it] 12%|█▏        | 59/500 [12:23<1:34:45, 12.89s/it] 12%|█▏        | 59/500 [12:23<1:32:40, 12.61s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.130 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▄▇▃▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ▁▁▁▃▁▃▁▅▁▁▂▂▇▂▃▃▆▃▂▅▆▄▅██▇▁▁▇▇▁▇▇▆▃▃▁▃▆▁
wandb:   val_accuracy ▂▁▁▃█▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃
wandb:       val_loss ▁▁▁▃▁▂▅▅▄▁▃▆▄▃▁▃▄▄▃▁▄▇▃▅▅▄▄▁▁▆▆▄▇█▃▄▄▄▄█
wandb: 
wandb: Run summary:
wandb:          epoch 58
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.31055
wandb:     train_loss 0.0
wandb:   val_accuracy 0.34667
wandb:       val_loss 120.93709
wandb: 
wandb: 🚀 View run happy-moon-103 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6nepfdxy
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_122103-6nepfdxy/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_123417-b2fwj5r9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-armadillo-104
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/b2fwj5r9
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:10:36, 15.70s/it]  0%|          | 2/500 [00:28<1:54:47, 13.83s/it]  1%|          | 3/500 [00:41<1:51:06, 13.41s/it]  1%|          | 4/500 [00:53<1:46:44, 12.91s/it]  1%|          | 5/500 [01:07<1:51:29, 13.51s/it]  1%|          | 6/500 [01:21<1:51:22, 13.53s/it]  1%|▏         | 7/500 [01:33<1:48:27, 13.20s/it]  2%|▏         | 8/500 [01:47<1:49:03, 13.30s/it]  2%|▏         | 9/500 [02:00<1:49:07, 13.33s/it]  2%|▏         | 10/500 [02:12<1:45:22, 12.90s/it]  2%|▏         | 11/500 [02:24<1:43:08, 12.66s/it]  2%|▏         | 12/500 [02:38<1:44:45, 12.88s/it]  3%|▎         | 13/500 [02:51<1:46:20, 13.10s/it]  3%|▎         | 14/500 [03:05<1:47:23, 13.26s/it]  3%|▎         | 15/500 [03:17<1:44:37, 12.94s/it]  3%|▎         | 16/500 [03:31<1:45:49, 13.12s/it]  3%|▎         | 17/500 [03:42<1:41:58, 12.67s/it]  4%|▎         | 18/500 [03:55<1:41:31, 12.64s/it]  4%|▍         | 19/500 [04:07<1:40:24, 12.53s/it]  4%|▍         | 20/500 [04:20<1:39:54, 12.49s/it]  4%|▍         | 21/500 [04:33<1:41:11, 12.68s/it]  4%|▍         | 22/500 [04:45<1:40:14, 12.58s/it]  5%|▍         | 23/500 [04:59<1:42:33, 12.90s/it]  5%|▍         | 24/500 [05:11<1:41:39, 12.81s/it]  5%|▌         | 25/500 [05:26<1:45:55, 13.38s/it]  5%|▌         | 26/500 [05:39<1:45:44, 13.39s/it]  5%|▌         | 27/500 [05:51<1:41:11, 12.84s/it]  6%|▌         | 28/500 [06:04<1:42:07, 12.98s/it]  6%|▌         | 29/500 [06:16<1:39:32, 12.68s/it]  6%|▌         | 30/500 [06:30<1:41:51, 13.00s/it]  6%|▌         | 31/500 [06:42<1:39:19, 12.71s/it]  6%|▋         | 32/500 [06:54<1:37:38, 12.52s/it]  7%|▋         | 33/500 [07:08<1:39:47, 12.82s/it]  7%|▋         | 34/500 [07:21<1:40:31, 12.94s/it]  7%|▋         | 35/500 [07:34<1:41:35, 13.11s/it]  7%|▋         | 36/500 [07:48<1:41:57, 13.18s/it]  7%|▋         | 37/500 [08:01<1:42:30, 13.28s/it]  8%|▊         | 38/500 [08:14<1:41:51, 13.23s/it]  8%|▊         | 39/500 [08:28<1:41:46, 13.25s/it]  8%|▊         | 40/500 [08:41<1:42:38, 13.39s/it]  8%|▊         | 41/500 [08:55<1:42:33, 13.41s/it]  8%|▊         | 42/500 [09:07<1:39:05, 12.98s/it]  9%|▊         | 43/500 [09:19<1:36:03, 12.61s/it]  9%|▉         | 44/500 [09:30<1:33:55, 12.36s/it]  9%|▉         | 45/500 [09:44<1:36:43, 12.75s/it]  9%|▉         | 46/500 [09:56<1:33:50, 12.40s/it]  9%|▉         | 47/500 [10:09<1:36:06, 12.73s/it] 10%|▉         | 48/500 [10:21<1:34:20, 12.52s/it] 10%|▉         | 49/500 [10:32<1:31:17, 12.15s/it] 10%|█         | 50/500 [10:45<1:32:36, 12.35s/it] 10%|█         | 51/500 [10:58<1:32:56, 12.42s/it] 10%|█         | 51/500 [10:58<1:36:35, 12.91s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.317 MB uploadedwandb: / 0.010 MB of 0.317 MB uploadedwandb: - 0.138 MB of 0.317 MB uploadedwandb: \ 0.317 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb: / 0.317 MB of 0.317 MB uploadedwandb: - 0.317 MB of 0.317 MB uploadedwandb: \ 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▄█▆▇▆▆▆▆▆▁▂▂█▂▂▂▂█▅▄▅▄▂▆▇▅▂▆▂▃▂▅▄▅▇▅
wandb:     train_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▄▄▃▁▃▇▄▃▄▄▄▄▄▃▄▃█▄▄▄▄█▃▆▃▃▃▅▆▇▅▇▄▃▃▃▃▃▅▃
wandb:       val_loss ▁▁▁▁▁▁▁▁▁▁▁▁▁█▂▁▂▁▁▁▂▂▁▂▂▂▂▁▁▁▁▂▁▂▁▁▁▂▁▃
wandb: 
wandb: Run summary:
wandb:          epoch 50
wandb:  learning_rate 0.0
wandb: train_accuracy 0.52155
wandb:     train_loss 0.28595
wandb:   val_accuracy 0.32889
wandb:       val_loss 4.0924
wandb: 
wandb: 🚀 View run frosty-armadillo-104 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/b2fwj5r9
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_123417-b2fwj5r9/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_124603-q36qhnt0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-snow-105
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q36qhnt0
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:48:34, 13.05s/it]  0%|          | 2/500 [00:24<1:41:15, 12.20s/it]  1%|          | 3/500 [00:37<1:42:20, 12.35s/it]  1%|          | 4/500 [00:49<1:42:15, 12.37s/it]  1%|          | 5/500 [01:01<1:40:31, 12.18s/it]  1%|          | 6/500 [01:13<1:39:12, 12.05s/it]  1%|▏         | 7/500 [01:25<1:38:46, 12.02s/it]  2%|▏         | 8/500 [01:36<1:37:45, 11.92s/it]  2%|▏         | 9/500 [01:49<1:38:29, 12.04s/it]  2%|▏         | 10/500 [02:00<1:37:34, 11.95s/it]  2%|▏         | 11/500 [02:12<1:37:30, 11.96s/it]  2%|▏         | 12/500 [02:25<1:39:13, 12.20s/it]  3%|▎         | 13/500 [02:39<1:42:50, 12.67s/it]  3%|▎         | 14/500 [02:53<1:45:44, 13.06s/it]  3%|▎         | 15/500 [03:05<1:44:14, 12.90s/it]  3%|▎         | 16/500 [03:18<1:42:16, 12.68s/it]  3%|▎         | 17/500 [03:29<1:40:07, 12.44s/it]  4%|▎         | 18/500 [03:42<1:39:38, 12.40s/it]  4%|▍         | 19/500 [03:54<1:39:13, 12.38s/it]  4%|▍         | 20/500 [04:07<1:39:21, 12.42s/it]  4%|▍         | 21/500 [04:19<1:38:54, 12.39s/it]  4%|▍         | 22/500 [04:33<1:41:55, 12.79s/it]  5%|▍         | 23/500 [04:45<1:40:59, 12.70s/it]  5%|▍         | 24/500 [04:58<1:40:24, 12.66s/it]  5%|▌         | 25/500 [05:09<1:37:59, 12.38s/it]  5%|▌         | 26/500 [05:20<1:34:29, 11.96s/it]  5%|▌         | 27/500 [05:32<1:33:15, 11.83s/it]  6%|▌         | 28/500 [05:44<1:34:13, 11.98s/it]  6%|▌         | 29/500 [05:57<1:36:28, 12.29s/it]  6%|▌         | 30/500 [06:11<1:38:33, 12.58s/it]  6%|▌         | 31/500 [06:23<1:38:46, 12.64s/it]  6%|▋         | 32/500 [06:36<1:39:12, 12.72s/it]  7%|▋         | 33/500 [06:50<1:40:48, 12.95s/it]  7%|▋         | 34/500 [07:02<1:39:17, 12.79s/it]  7%|▋         | 35/500 [07:17<1:44:10, 13.44s/it]  7%|▋         | 36/500 [07:30<1:43:44, 13.42s/it]  7%|▋         | 37/500 [07:43<1:42:28, 13.28s/it]  8%|▊         | 38/500 [07:57<1:41:49, 13.22s/it]  8%|▊         | 39/500 [08:10<1:41:40, 13.23s/it]  8%|▊         | 40/500 [08:24<1:44:11, 13.59s/it]  8%|▊         | 41/500 [08:39<1:46:35, 13.93s/it]  8%|▊         | 41/500 [08:39<1:36:55, 12.67s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.312 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.231 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▂▆▁▁▁▇▁▆▅▁▅▆█▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ▁▁▁▂▃▁▁▂▁▁▂▁▁▁▄▂▃▃▃▃▄▅▃▅▇▄▄▁▅▆▃▅▅▄▆█▁▆▁▁
wandb:   val_accuracy ▁▃▁▁▁▁▄▁██▃▇█▇▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:       val_loss ▁▁▁▁▂▃▁▁▁▁▂▂▂▁▃▂▃▃▄▃▁▄▃▄▁▄▄▅▁▃█▅▄▇▂▄▅▃▄▁
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.31055
wandb:     train_loss 0.0
wandb:   val_accuracy 0.34667
wandb:       val_loss 0.0
wandb: 
wandb: 🚀 View run earnest-snow-105 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/q36qhnt0
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_124603-q36qhnt0/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_125526-m4w7r3xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-snowflake-106
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/m4w7r3xb
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:39:13, 19.15s/it]  0%|          | 2/500 [00:36<2:28:03, 17.84s/it]  1%|          | 3/500 [00:53<2:26:20, 17.67s/it]  1%|          | 4/500 [01:09<2:20:54, 17.05s/it]  1%|          | 5/500 [01:25<2:16:18, 16.52s/it]  1%|          | 6/500 [01:40<2:12:39, 16.11s/it]  1%|▏         | 7/500 [01:55<2:10:09, 15.84s/it]  2%|▏         | 8/500 [02:12<2:12:04, 16.11s/it]  2%|▏         | 9/500 [02:28<2:11:37, 16.09s/it]  2%|▏         | 10/500 [02:45<2:12:23, 16.21s/it]  2%|▏         | 11/500 [03:00<2:11:15, 16.11s/it]  2%|▏         | 12/500 [03:17<2:13:14, 16.38s/it]  3%|▎         | 13/500 [03:34<2:12:29, 16.32s/it]  3%|▎         | 14/500 [03:50<2:12:46, 16.39s/it]  3%|▎         | 15/500 [04:07<2:14:34, 16.65s/it]  3%|▎         | 16/500 [04:24<2:14:33, 16.68s/it]  3%|▎         | 17/500 [04:40<2:13:05, 16.53s/it]  4%|▎         | 18/500 [04:57<2:12:41, 16.52s/it]  4%|▍         | 19/500 [05:14<2:13:42, 16.68s/it]  4%|▍         | 20/500 [05:30<2:12:48, 16.60s/it]  4%|▍         | 21/500 [05:49<2:16:42, 17.12s/it]  4%|▍         | 22/500 [06:06<2:16:51, 17.18s/it]  5%|▍         | 23/500 [06:23<2:16:57, 17.23s/it]  5%|▍         | 24/500 [06:41<2:16:44, 17.24s/it]  5%|▌         | 25/500 [06:57<2:15:15, 17.08s/it]  5%|▌         | 26/500 [07:14<2:13:49, 16.94s/it]  5%|▌         | 27/500 [07:31<2:14:31, 17.06s/it]  6%|▌         | 28/500 [07:49<2:14:59, 17.16s/it]  6%|▌         | 29/500 [08:06<2:14:48, 17.17s/it]  6%|▌         | 30/500 [08:24<2:17:14, 17.52s/it]  6%|▌         | 31/500 [08:41<2:15:06, 17.28s/it]  6%|▋         | 32/500 [08:58<2:15:32, 17.38s/it]  7%|▋         | 33/500 [09:14<2:09:56, 16.69s/it]  7%|▋         | 34/500 [09:29<2:06:04, 16.23s/it]  7%|▋         | 35/500 [09:45<2:04:55, 16.12s/it]  7%|▋         | 36/500 [10:02<2:07:48, 16.53s/it]  7%|▋         | 37/500 [10:18<2:06:39, 16.41s/it]  7%|▋         | 37/500 [10:18<2:09:02, 16.72s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.133 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▅▃▄▅▄▄▃▇▇▇▆▇▆▇█▅▇███████▇█████████
wandb:     train_loss ▂▃▂▂▁▁▁▁▆▁█▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁
wandb:   val_accuracy ▁▁▂▄▄▄▅▅▄▅▆▇▆▇█▆▇▇▆▇▇▇▇▇▇█▇▆▇▇▇▇▇▇▇▇▇
wandb:       val_loss ▂▂▁▂▂▂▄▁▁▄▃▁▅▁▁▃▅▅▃▁▁▁▁▃▁▄▁▄▁▂▄▁▁▄█▅▃
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.99406
wandb:     train_loss 0.0311
wandb:   val_accuracy 0.71333
wandb:       val_loss 3.8589
wandb: 
wandb: 🚀 View run astral-snowflake-106 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/m4w7r3xb
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_125526-m4w7r3xb/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_130627-h7qxhn2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-plasma-107
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h7qxhn2r
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:32:57, 18.39s/it]  0%|          | 2/500 [00:34<2:20:51, 16.97s/it]  1%|          | 3/500 [00:50<2:16:42, 16.50s/it]  1%|          | 4/500 [01:06<2:14:38, 16.29s/it]  1%|          | 5/500 [01:22<2:13:39, 16.20s/it]  1%|          | 6/500 [01:38<2:13:06, 16.17s/it]  1%|▏         | 7/500 [01:54<2:12:24, 16.11s/it]  2%|▏         | 8/500 [02:10<2:10:59, 15.97s/it]  2%|▏         | 9/500 [02:26<2:12:51, 16.24s/it]  2%|▏         | 10/500 [02:44<2:16:03, 16.66s/it]  2%|▏         | 11/500 [03:00<2:15:10, 16.59s/it]  2%|▏         | 12/500 [03:16<2:12:46, 16.32s/it]  3%|▎         | 13/500 [03:32<2:12:00, 16.26s/it]  3%|▎         | 14/500 [03:48<2:11:16, 16.21s/it]  3%|▎         | 15/500 [04:04<2:10:00, 16.08s/it]  3%|▎         | 16/500 [04:20<2:09:03, 16.00s/it]  3%|▎         | 17/500 [04:36<2:08:41, 15.99s/it]  4%|▎         | 18/500 [04:52<2:08:23, 15.98s/it]  4%|▍         | 19/500 [05:08<2:08:30, 16.03s/it]  4%|▍         | 20/500 [05:24<2:07:10, 15.90s/it]  4%|▍         | 21/500 [05:40<2:08:04, 16.04s/it]  4%|▍         | 22/500 [05:56<2:07:53, 16.05s/it]  5%|▍         | 23/500 [06:12<2:06:31, 15.91s/it]  5%|▍         | 23/500 [06:12<2:08:39, 16.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.137 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb: train_accuracy ▁▁▂▃▄▆▇▇▇▇█████████████
wandb:     train_loss █▇▅▇▅▅▃▂▅▅▄▇▃▁▅▅▃▄▇▂▅█▅
wandb:   val_accuracy ▂▁▃▇█▇█▇▆▆▆▅▆▇▇▆▆▅▅██▆█
wandb:       val_loss ▂▂▂▅▂▁▁▁▂▃▂▁▂▂▂▂▃▂▃▃█▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 22
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.83952
wandb:     train_loss 0.78566
wandb:   val_accuracy 0.42667
wandb:       val_loss 0.26009
wandb: 
wandb: 🚀 View run clean-plasma-107 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h7qxhn2r
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_130627-h7qxhn2r/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_131325-n9vyk699
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-plant-108
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/n9vyk699
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:21<2:58:37, 21.48s/it]  0%|          | 2/500 [00:36<2:27:07, 17.73s/it]  1%|          | 3/500 [00:51<2:16:01, 16.42s/it]  1%|          | 4/500 [01:08<2:16:12, 16.48s/it]  1%|          | 5/500 [01:23<2:13:08, 16.14s/it]  1%|          | 6/500 [01:39<2:11:19, 15.95s/it]  1%|▏         | 7/500 [01:54<2:08:54, 15.69s/it]  2%|▏         | 8/500 [02:09<2:06:34, 15.44s/it]  2%|▏         | 9/500 [02:23<2:03:58, 15.15s/it]  2%|▏         | 10/500 [02:37<2:01:26, 14.87s/it]  2%|▏         | 11/500 [02:52<1:59:12, 14.63s/it]  2%|▏         | 12/500 [03:07<2:00:53, 14.86s/it]  3%|▎         | 13/500 [03:23<2:02:51, 15.14s/it]  3%|▎         | 14/500 [03:38<2:03:26, 15.24s/it]  3%|▎         | 15/500 [03:53<2:03:23, 15.26s/it]  3%|▎         | 16/500 [04:09<2:04:29, 15.43s/it]  3%|▎         | 17/500 [04:25<2:04:49, 15.51s/it]  4%|▎         | 18/500 [04:42<2:07:34, 15.88s/it]  4%|▍         | 19/500 [04:57<2:06:22, 15.76s/it]  4%|▍         | 20/500 [05:12<2:03:59, 15.50s/it]  4%|▍         | 21/500 [05:28<2:04:32, 15.60s/it]  4%|▍         | 22/500 [05:43<2:03:23, 15.49s/it]  5%|▍         | 23/500 [06:00<2:05:40, 15.81s/it]  5%|▍         | 24/500 [06:16<2:05:32, 15.82s/it]  5%|▌         | 25/500 [06:31<2:03:26, 15.59s/it]  5%|▌         | 26/500 [06:46<2:02:07, 15.46s/it]  5%|▌         | 27/500 [07:03<2:05:06, 15.87s/it]  6%|▌         | 28/500 [07:20<2:09:12, 16.43s/it]  6%|▌         | 29/500 [07:38<2:12:13, 16.84s/it]  6%|▌         | 29/500 [07:38<2:04:09, 15.82s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.314 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.137 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▃▃▆▃▃▃▆▅▅▇▇▇▇▇▆▆▇███▇███▆▇
wandb:     train_loss ▃▃▂▃▂▃▇▇▃▂▁▅▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▂
wandb:   val_accuracy ▁▄▇▃▄▇▅▄▄█▇▅▆▆▆▆▅▆▇▄▇▆▆▆█▇▇▆▇
wandb:       val_loss ▁▂▂▁▁▁▁▃▂▁▄▁▁▁▁▁▂▁▁▁█▂▁▂▁▁▁▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 28
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.86627
wandb:     train_loss 0.63018
wandb:   val_accuracy 0.58222
wandb:       val_loss 8.12836
wandb: 
wandb: 🚀 View run noble-plant-108 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/n9vyk699
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_131325-n9vyk699/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_132151-2vn2six4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-totem-109
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2vn2six4
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:30:29, 18.09s/it]  0%|          | 2/500 [00:33<2:15:22, 16.31s/it]  1%|          | 3/500 [00:48<2:10:52, 15.80s/it]  1%|          | 4/500 [01:03<2:07:49, 15.46s/it]  1%|          | 5/500 [01:18<2:06:33, 15.34s/it]  1%|          | 6/500 [01:33<2:05:55, 15.29s/it]  1%|▏         | 7/500 [01:48<2:04:40, 15.17s/it]  2%|▏         | 8/500 [02:03<2:03:59, 15.12s/it]  2%|▏         | 9/500 [02:18<2:03:01, 15.03s/it]  2%|▏         | 10/500 [02:34<2:04:17, 15.22s/it]  2%|▏         | 11/500 [02:49<2:03:46, 15.19s/it]  2%|▏         | 12/500 [03:04<2:02:51, 15.11s/it]  3%|▎         | 13/500 [03:19<2:04:08, 15.29s/it]  3%|▎         | 14/500 [03:34<2:03:00, 15.19s/it]  3%|▎         | 15/500 [03:49<2:02:16, 15.13s/it]  3%|▎         | 16/500 [04:09<2:12:09, 16.38s/it]  3%|▎         | 17/500 [04:23<2:08:13, 15.93s/it]  4%|▎         | 18/500 [04:38<2:05:13, 15.59s/it]  4%|▍         | 19/500 [04:53<2:03:35, 15.42s/it]  4%|▍         | 20/500 [05:08<2:02:25, 15.30s/it]  4%|▍         | 21/500 [05:24<2:02:26, 15.34s/it]  4%|▍         | 22/500 [05:38<2:00:08, 15.08s/it]  5%|▍         | 23/500 [05:57<2:09:08, 16.24s/it]  5%|▍         | 24/500 [06:11<2:03:58, 15.63s/it]  5%|▌         | 25/500 [06:26<2:01:52, 15.40s/it]  5%|▌         | 26/500 [06:41<2:00:27, 15.25s/it]  5%|▌         | 27/500 [06:56<2:00:11, 15.25s/it]  6%|▌         | 28/500 [07:11<1:58:55, 15.12s/it]  6%|▌         | 29/500 [07:26<1:59:00, 15.16s/it]  6%|▌         | 30/500 [07:42<1:59:49, 15.30s/it]  6%|▌         | 31/500 [07:57<1:59:09, 15.24s/it]  6%|▋         | 32/500 [08:12<1:58:43, 15.22s/it]  7%|▋         | 33/500 [08:27<1:58:13, 15.19s/it]  7%|▋         | 34/500 [08:43<1:58:48, 15.30s/it]  7%|▋         | 35/500 [08:58<1:58:54, 15.34s/it]  7%|▋         | 36/500 [09:14<1:58:17, 15.30s/it]  7%|▋         | 37/500 [09:29<1:57:24, 15.22s/it]  8%|▊         | 38/500 [09:44<1:57:46, 15.29s/it]  8%|▊         | 39/500 [10:00<1:58:20, 15.40s/it]  8%|▊         | 40/500 [10:17<2:01:22, 15.83s/it]  8%|▊         | 41/500 [10:32<2:01:19, 15.86s/it]  8%|▊         | 42/500 [10:47<1:59:03, 15.60s/it]  9%|▊         | 43/500 [11:02<1:57:26, 15.42s/it]  9%|▊         | 43/500 [11:03<1:57:26, 15.42s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.019 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▂▅▂▁▅▁▇▅▆▇▆▇▇▃██▇███▇█▇█████████████
wandb:     train_loss ▃▅▂▆▁▁▁▁▁█▁▄▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▁▃▃▄▃▃▆▄▇▄▇█▆▆▇▅█▇███▇██▇▇██████▇▇██▇█
wandb:       val_loss ▂▂▁▂▆▂▃▁▃▄▁▁▅▂▃▆▄▃▃▁▁▁▂▁▅▁▁▃▄▁▁▄█▃▃▁▇▁▄▁
wandb: 
wandb: Run summary:
wandb:          epoch 42
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99108
wandb:     train_loss 0.01274
wandb:   val_accuracy 0.71333
wandb:       val_loss 0.06651
wandb: 
wandb: 🚀 View run lyric-totem-109 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2vn2six4
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_132151-2vn2six4/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_133342-mi1hddxw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-resonance-110
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mi1hddxw
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:31:58, 18.27s/it]  0%|          | 2/500 [00:34<2:20:05, 16.88s/it]  1%|          | 3/500 [00:50<2:16:32, 16.48s/it]  1%|          | 4/500 [01:06<2:14:57, 16.33s/it]  1%|          | 5/500 [01:22<2:14:21, 16.29s/it]  1%|          | 6/500 [01:38<2:12:30, 16.09s/it]  1%|▏         | 7/500 [01:54<2:11:40, 16.03s/it]  2%|▏         | 8/500 [02:09<2:11:00, 15.98s/it]  2%|▏         | 9/500 [02:25<2:09:57, 15.88s/it]  2%|▏         | 10/500 [02:41<2:08:37, 15.75s/it]  2%|▏         | 11/500 [02:57<2:10:19, 15.99s/it]  2%|▏         | 12/500 [03:13<2:09:48, 15.96s/it]  3%|▎         | 13/500 [03:29<2:10:02, 16.02s/it]  3%|▎         | 14/500 [03:45<2:10:01, 16.05s/it]  3%|▎         | 15/500 [04:01<2:09:51, 16.07s/it]  3%|▎         | 16/500 [04:18<2:10:35, 16.19s/it]  3%|▎         | 17/500 [04:35<2:12:27, 16.45s/it]  4%|▎         | 18/500 [04:51<2:10:58, 16.30s/it]  4%|▍         | 19/500 [05:07<2:10:20, 16.26s/it]  4%|▍         | 20/500 [05:23<2:09:47, 16.22s/it]  4%|▍         | 21/500 [05:40<2:11:07, 16.42s/it]  4%|▍         | 22/500 [05:56<2:09:18, 16.23s/it]  5%|▍         | 23/500 [06:12<2:08:15, 16.13s/it]  5%|▍         | 23/500 [06:12<2:08:41, 16.19s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.021 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb: train_accuracy ▁▁▃▃▅▅▅▆▇▇████▇██▇█████
wandb:     train_loss █▅▆▇▅▅▄▃▅▄▄▅▄▁▆▄▃▄▇▂▇█▄
wandb:   val_accuracy ▂▁▅█▇▆▇▆▆█▇▇█▇▆▆▇▆▇▇▇▆▇
wandb:       val_loss ▂▂▂▄▁▁▁▁▂▁▃▁▂▁▁▂▃▂▂▂█▃▂
wandb: 
wandb: Run summary:
wandb:          epoch 22
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.80535
wandb:     train_loss 0.69927
wandb:   val_accuracy 0.43111
wandb:       val_loss 1.60136
wandb: 
wandb: 🚀 View run autumn-resonance-110 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mi1hddxw
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_133342-mi1hddxw/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_134050-2g9ahexz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-breeze-111
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2g9ahexz
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:22:10, 17.10s/it]  0%|          | 2/500 [00:32<2:14:26, 16.20s/it]  1%|          | 3/500 [00:47<2:09:35, 15.64s/it]  1%|          | 4/500 [01:02<2:08:17, 15.52s/it]  1%|          | 5/500 [01:18<2:07:00, 15.40s/it]  1%|          | 6/500 [01:34<2:08:30, 15.61s/it]  1%|▏         | 7/500 [01:50<2:09:30, 15.76s/it]  2%|▏         | 8/500 [02:06<2:10:47, 15.95s/it]  2%|▏         | 9/500 [02:22<2:11:12, 16.03s/it]  2%|▏         | 10/500 [02:38<2:10:44, 16.01s/it]  2%|▏         | 11/500 [02:55<2:11:06, 16.09s/it]  2%|▏         | 12/500 [03:11<2:12:40, 16.31s/it]  3%|▎         | 13/500 [03:27<2:11:50, 16.24s/it]  3%|▎         | 14/500 [03:43<2:10:23, 16.10s/it]  3%|▎         | 15/500 [03:59<2:09:32, 16.03s/it]  3%|▎         | 16/500 [04:15<2:08:15, 15.90s/it]  3%|▎         | 17/500 [04:31<2:08:54, 16.01s/it]  4%|▎         | 18/500 [04:47<2:08:16, 15.97s/it]  4%|▍         | 19/500 [05:03<2:07:42, 15.93s/it]  4%|▍         | 20/500 [05:19<2:07:35, 15.95s/it]  4%|▍         | 21/500 [05:35<2:08:14, 16.06s/it]  4%|▍         | 22/500 [05:51<2:07:25, 15.99s/it]  5%|▍         | 23/500 [06:07<2:08:21, 16.15s/it]  5%|▍         | 24/500 [06:24<2:09:15, 16.29s/it]  5%|▌         | 25/500 [06:40<2:08:48, 16.27s/it]  5%|▌         | 26/500 [06:56<2:07:11, 16.10s/it]  5%|▌         | 27/500 [07:12<2:07:40, 16.20s/it]  6%|▌         | 28/500 [07:29<2:08:30, 16.33s/it]  6%|▌         | 29/500 [07:45<2:08:09, 16.33s/it]  6%|▌         | 30/500 [08:01<2:05:52, 16.07s/it]  6%|▌         | 31/500 [08:17<2:05:47, 16.09s/it]  6%|▋         | 32/500 [08:33<2:06:00, 16.15s/it]  7%|▋         | 33/500 [08:49<2:05:28, 16.12s/it]  7%|▋         | 34/500 [09:05<2:04:39, 16.05s/it]  7%|▋         | 35/500 [09:21<2:04:13, 16.03s/it]  7%|▋         | 36/500 [09:37<2:04:28, 16.10s/it]  7%|▋         | 37/500 [09:54<2:06:04, 16.34s/it]  8%|▊         | 38/500 [10:10<2:04:46, 16.20s/it]  8%|▊         | 39/500 [10:26<2:03:35, 16.09s/it]  8%|▊         | 40/500 [10:43<2:04:31, 16.24s/it]  8%|▊         | 41/500 [10:59<2:05:41, 16.43s/it]  8%|▊         | 42/500 [11:17<2:08:40, 16.86s/it]  9%|▊         | 43/500 [11:35<2:09:33, 17.01s/it]  9%|▉         | 44/500 [11:51<2:07:37, 16.79s/it]  9%|▉         | 45/500 [12:07<2:06:40, 16.70s/it]  9%|▉         | 46/500 [12:25<2:08:20, 16.96s/it]  9%|▉         | 47/500 [12:42<2:08:05, 16.97s/it] 10%|▉         | 48/500 [12:59<2:08:28, 17.05s/it] 10%|▉         | 49/500 [13:16<2:08:26, 17.09s/it] 10%|█         | 50/500 [13:34<2:10:10, 17.36s/it] 10%|█         | 51/500 [13:51<2:08:03, 17.11s/it] 10%|█         | 52/500 [14:08<2:07:46, 17.11s/it] 11%|█         | 53/500 [14:25<2:07:29, 17.11s/it] 11%|█         | 54/500 [14:41<2:05:27, 16.88s/it] 11%|█         | 55/500 [14:58<2:04:33, 16.79s/it] 11%|█         | 55/500 [14:58<2:01:10, 16.34s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.232 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▂▃▄▄▃▄▆▇▇█▇█▇████▇████████████████████
wandb:     train_loss ▂▂▁▂▁▁▆█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▂▂▂▂▃▂▄▅▆▆▇▆▇▇▇▇▆▇██▇███▇▇███▇██▇▇▇██▇█
wandb:       val_loss ▁▁▁▁▁▁▁▁▁▁▁▁▃▁▁█▁▁▁▁▁▁▁▁▂▃▁▂▁▁▁▁▁▁▁▂▂▂▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 54
wandb:  learning_rate 2e-05
wandb: train_accuracy 0.98514
wandb:     train_loss 0.00089
wandb:   val_accuracy 0.62444
wandb:       val_loss 1.33139
wandb: 
wandb: 🚀 View run glorious-breeze-111 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2g9ahexz
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_134050-2g9ahexz/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_135638-u9yvc5ng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-butterfly-112
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/u9yvc5ng
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:22<3:09:13, 22.75s/it]  0%|          | 2/500 [00:39<2:40:42, 19.36s/it]  1%|          | 3/500 [00:57<2:32:49, 18.45s/it]  1%|          | 4/500 [01:14<2:28:58, 18.02s/it]  1%|          | 5/500 [01:30<2:24:13, 17.48s/it]  1%|          | 6/500 [01:48<2:23:11, 17.39s/it]  1%|▏         | 7/500 [02:05<2:23:31, 17.47s/it]  2%|▏         | 8/500 [02:27<2:34:52, 18.89s/it]  2%|▏         | 9/500 [02:44<2:28:02, 18.09s/it]  2%|▏         | 10/500 [03:00<2:23:47, 17.61s/it]  2%|▏         | 11/500 [03:18<2:22:57, 17.54s/it]  2%|▏         | 12/500 [03:39<2:33:32, 18.88s/it]  3%|▎         | 13/500 [03:55<2:26:14, 18.02s/it]  3%|▎         | 14/500 [04:11<2:20:33, 17.35s/it]  3%|▎         | 15/500 [04:28<2:18:14, 17.10s/it]  3%|▎         | 16/500 [04:44<2:15:41, 16.82s/it]  3%|▎         | 17/500 [05:00<2:13:09, 16.54s/it]  4%|▎         | 18/500 [05:16<2:12:10, 16.45s/it]  4%|▍         | 19/500 [05:32<2:10:45, 16.31s/it]  4%|▍         | 20/500 [05:48<2:09:43, 16.22s/it]  4%|▍         | 21/500 [06:09<2:20:42, 17.63s/it]  4%|▍         | 22/500 [06:26<2:17:55, 17.31s/it]  5%|▍         | 23/500 [06:42<2:14:44, 16.95s/it]  5%|▍         | 24/500 [06:58<2:13:44, 16.86s/it]  5%|▌         | 25/500 [07:15<2:11:49, 16.65s/it]  5%|▌         | 26/500 [07:31<2:11:41, 16.67s/it]  5%|▌         | 27/500 [07:48<2:10:34, 16.56s/it]  6%|▌         | 28/500 [08:04<2:10:38, 16.61s/it]  6%|▌         | 29/500 [08:21<2:11:44, 16.78s/it]  6%|▌         | 30/500 [08:38<2:09:58, 16.59s/it]  6%|▌         | 31/500 [08:54<2:09:04, 16.51s/it]  6%|▋         | 32/500 [09:10<2:07:55, 16.40s/it]  7%|▋         | 33/500 [09:26<2:06:50, 16.30s/it]  7%|▋         | 34/500 [09:42<2:06:42, 16.32s/it]  7%|▋         | 35/500 [09:59<2:06:53, 16.37s/it]  7%|▋         | 36/500 [10:15<2:06:08, 16.31s/it]  7%|▋         | 37/500 [10:32<2:06:53, 16.44s/it]  8%|▊         | 38/500 [10:49<2:06:59, 16.49s/it]  8%|▊         | 39/500 [11:05<2:07:33, 16.60s/it]  8%|▊         | 40/500 [11:22<2:06:18, 16.47s/it]  8%|▊         | 41/500 [11:38<2:04:52, 16.32s/it]  8%|▊         | 42/500 [11:54<2:05:41, 16.47s/it]  9%|▊         | 43/500 [12:11<2:05:59, 16.54s/it]  9%|▊         | 43/500 [12:11<2:09:35, 17.01s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.044 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▂▂▁▂▅▃▄▇▅▇▇▇█▆▆███████▇█████████████
wandb:     train_loss ▂▂▁▃▁█▁▁▁▁▆▁▃▁▁▁▁▂▃▁▁▁▁▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▁▂▃▄▃▄▄▆▆▆▇▅█▇▇▇▇▇███████▇▇██▇█▇▇█▇▇▇██
wandb:       val_loss ▂▂▂▂▃▂▄▁▄▅▃▁▅▁▃▅▅▃▄▁▁▁▁▂▆▁▁▄▄▁▁▂█▆▃▁▁▁▃▁
wandb: 
wandb: Run summary:
wandb:          epoch 42
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.99554
wandb:     train_loss 0.00755
wandb:   val_accuracy 0.72667
wandb:       val_loss 0.01592
wandb: 
wandb: 🚀 View run restful-butterfly-112 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/u9yvc5ng
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_135638-u9yvc5ng/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_140943-zznorer2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-snowball-113
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/zznorer2
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:38:48, 19.09s/it]  0%|          | 2/500 [00:35<2:24:23, 17.40s/it]  1%|          | 3/500 [00:51<2:21:12, 17.05s/it]  1%|          | 4/500 [01:08<2:17:54, 16.68s/it]  1%|          | 5/500 [01:24<2:15:46, 16.46s/it]  1%|          | 6/500 [01:39<2:13:10, 16.17s/it]  1%|▏         | 7/500 [01:55<2:12:50, 16.17s/it]  2%|▏         | 8/500 [02:12<2:12:28, 16.16s/it]  2%|▏         | 9/500 [02:28<2:12:29, 16.19s/it]  2%|▏         | 10/500 [02:48<2:23:16, 17.54s/it]  2%|▏         | 11/500 [03:05<2:20:40, 17.26s/it]  2%|▏         | 12/500 [03:22<2:18:55, 17.08s/it]  3%|▎         | 13/500 [03:38<2:15:52, 16.74s/it]  3%|▎         | 14/500 [03:53<2:13:20, 16.46s/it]  3%|▎         | 15/500 [04:10<2:12:35, 16.40s/it]  3%|▎         | 16/500 [04:26<2:12:37, 16.44s/it]  3%|▎         | 17/500 [04:43<2:13:39, 16.60s/it]  4%|▎         | 18/500 [05:00<2:12:40, 16.52s/it]  4%|▍         | 19/500 [05:15<2:10:43, 16.31s/it]  4%|▍         | 20/500 [05:36<2:21:48, 17.73s/it]  4%|▍         | 21/500 [05:53<2:18:28, 17.35s/it]  4%|▍         | 22/500 [06:09<2:14:30, 16.88s/it]  5%|▍         | 23/500 [06:25<2:13:03, 16.74s/it]  5%|▍         | 24/500 [06:43<2:14:41, 16.98s/it]  5%|▌         | 25/500 [07:03<2:22:13, 17.97s/it]  5%|▌         | 26/500 [07:19<2:17:24, 17.39s/it]  5%|▌         | 27/500 [07:34<2:12:24, 16.80s/it]  6%|▌         | 28/500 [07:55<2:21:00, 17.92s/it]  6%|▌         | 28/500 [07:55<2:13:33, 16.98s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▃▄▄▅▆▅▇▇▇██▇██▇███▇██████
wandb:     train_loss █▇▆▇▆▅▄▃▄▅▅▆▅▂▅▄▄▅▇▂▆█▃▆▇▄▁▁
wandb:   val_accuracy ▂▁▅▇▆▆▅▄█▇▇▇▆▇▆▆▇▆▇██▇█▇▇▇▇▇
wandb:       val_loss ▂▂▂▁▂▂▁▁▂▃▃▁▂▂▂▂▃▂▄▂█▅▃▅▁▃▂▅
wandb: 
wandb: Run summary:
wandb:          epoch 27
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.8425
wandb:     train_loss 0.15848
wandb:   val_accuracy 0.41778
wandb:       val_loss 4.02358
wandb: 
wandb: 🚀 View run fragrant-snowball-113 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/zznorer2
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_140943-zznorer2/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_141820-j2byygjk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-dawn-114
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/j2byygjk
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:21:31, 17.02s/it]  0%|          | 2/500 [00:32<2:13:37, 16.10s/it]  1%|          | 3/500 [00:48<2:11:27, 15.87s/it]  1%|          | 4/500 [01:03<2:10:44, 15.82s/it]  1%|          | 5/500 [01:19<2:10:30, 15.82s/it]  1%|          | 6/500 [01:35<2:11:33, 15.98s/it]  1%|▏         | 7/500 [01:52<2:11:45, 16.04s/it]  2%|▏         | 8/500 [02:07<2:10:40, 15.94s/it]  2%|▏         | 9/500 [02:23<2:10:10, 15.91s/it]  2%|▏         | 10/500 [02:39<2:10:30, 15.98s/it]  2%|▏         | 11/500 [02:54<2:07:43, 15.67s/it]  2%|▏         | 12/500 [03:09<2:05:46, 15.46s/it]  3%|▎         | 13/500 [03:25<2:05:11, 15.42s/it]  3%|▎         | 14/500 [03:40<2:06:08, 15.57s/it]  3%|▎         | 15/500 [03:56<2:06:13, 15.61s/it]  3%|▎         | 16/500 [04:12<2:06:49, 15.72s/it]  3%|▎         | 17/500 [04:28<2:07:33, 15.84s/it]  4%|▎         | 18/500 [04:49<2:19:37, 17.38s/it]  4%|▍         | 19/500 [05:06<2:17:30, 17.15s/it]  4%|▍         | 20/500 [05:22<2:15:06, 16.89s/it]  4%|▍         | 21/500 [05:39<2:13:55, 16.78s/it]  4%|▍         | 22/500 [05:55<2:12:36, 16.65s/it]  5%|▍         | 23/500 [06:12<2:12:44, 16.70s/it]  5%|▍         | 24/500 [06:28<2:11:39, 16.60s/it]  5%|▌         | 25/500 [06:45<2:12:03, 16.68s/it]  5%|▌         | 26/500 [07:01<2:10:13, 16.49s/it]  5%|▌         | 27/500 [07:17<2:08:22, 16.28s/it]  6%|▌         | 28/500 [07:33<2:08:49, 16.38s/it]  6%|▌         | 29/500 [07:50<2:08:06, 16.32s/it]  6%|▌         | 30/500 [08:06<2:06:57, 16.21s/it]  6%|▌         | 31/500 [08:22<2:08:05, 16.39s/it]  6%|▋         | 32/500 [08:38<2:06:41, 16.24s/it]  7%|▋         | 33/500 [08:55<2:06:48, 16.29s/it]  7%|▋         | 34/500 [09:11<2:07:09, 16.37s/it]  7%|▋         | 35/500 [09:27<2:06:26, 16.32s/it]  7%|▋         | 36/500 [09:44<2:06:53, 16.41s/it]  7%|▋         | 37/500 [10:00<2:06:19, 16.37s/it]  8%|▊         | 38/500 [10:16<2:05:07, 16.25s/it]  8%|▊         | 39/500 [10:34<2:07:16, 16.56s/it]  8%|▊         | 40/500 [10:51<2:08:39, 16.78s/it]  8%|▊         | 41/500 [11:08<2:08:09, 16.75s/it]  8%|▊         | 42/500 [11:24<2:06:51, 16.62s/it]  9%|▊         | 43/500 [11:41<2:08:06, 16.82s/it]  9%|▉         | 44/500 [11:58<2:06:35, 16.66s/it]  9%|▉         | 45/500 [12:14<2:06:57, 16.74s/it]  9%|▉         | 46/500 [12:31<2:05:44, 16.62s/it]  9%|▉         | 47/500 [12:48<2:05:47, 16.66s/it]  9%|▉         | 47/500 [12:48<2:03:27, 16.35s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.232 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▄▂▂▄▃▅▆▆▆▆▇▆▇▇▆██▇██▇▇█▇██▇▇▇█▇█▇▇████
wandb:     train_loss ▃▃▃▃▅▂█▂▂▂▁▁▁▁▂▁█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁
wandb:   val_accuracy ▁▃▇▁▂▆▃▆▅▆▆▆▇▆▇▆▆▇▇▆▇█▆▇▇▇██▇▇▇██▇████▇█
wandb:       val_loss ▂▂▂▅▂▂▅▇▁▃▁▁▅▁▂▂▂█▃▁▃▁▁▃▁▇▁▁▁▂▁▁▅▁▃▁▅█▄▂
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.99851
wandb:     train_loss 0.00803
wandb:   val_accuracy 0.62667
wandb:       val_loss 0.70058
wandb: 
wandb: 🚀 View run silvery-dawn-114 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/j2byygjk
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_141820-j2byygjk/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_143153-o41pesin
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-voice-115
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/o41pesin
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:43:10, 19.62s/it]  0%|          | 2/500 [00:35<2:26:00, 17.59s/it]  1%|          | 3/500 [00:51<2:17:34, 16.61s/it]  1%|          | 4/500 [01:06<2:13:23, 16.14s/it]  1%|          | 5/500 [01:22<2:11:31, 15.94s/it]  1%|          | 6/500 [01:37<2:08:43, 15.63s/it]  1%|▏         | 7/500 [01:52<2:08:04, 15.59s/it]  2%|▏         | 8/500 [02:07<2:06:37, 15.44s/it]  2%|▏         | 9/500 [02:23<2:05:36, 15.35s/it]  2%|▏         | 10/500 [02:38<2:05:13, 15.33s/it]  2%|▏         | 11/500 [02:53<2:05:17, 15.37s/it]  2%|▏         | 12/500 [03:09<2:05:03, 15.38s/it]  3%|▎         | 13/500 [03:24<2:04:02, 15.28s/it]  3%|▎         | 14/500 [03:40<2:05:56, 15.55s/it]  3%|▎         | 15/500 [03:55<2:04:36, 15.41s/it]  3%|▎         | 16/500 [04:12<2:07:03, 15.75s/it]  3%|▎         | 17/500 [04:26<2:04:40, 15.49s/it]  4%|▎         | 18/500 [04:42<2:03:47, 15.41s/it]  4%|▍         | 19/500 [04:58<2:04:46, 15.56s/it]  4%|▍         | 20/500 [05:13<2:03:54, 15.49s/it]  4%|▍         | 21/500 [05:28<2:03:04, 15.42s/it]  4%|▍         | 22/500 [05:44<2:03:12, 15.46s/it]  5%|▍         | 23/500 [05:59<2:03:10, 15.49s/it]  5%|▍         | 24/500 [06:15<2:02:36, 15.46s/it]  5%|▌         | 25/500 [06:30<2:02:29, 15.47s/it]  5%|▌         | 26/500 [06:46<2:03:22, 15.62s/it]  5%|▌         | 27/500 [07:02<2:04:26, 15.78s/it]  6%|▌         | 28/500 [07:17<2:02:39, 15.59s/it]  6%|▌         | 29/500 [07:35<2:06:59, 16.18s/it]  6%|▌         | 30/500 [07:51<2:05:11, 15.98s/it]  6%|▌         | 31/500 [08:05<2:02:33, 15.68s/it]  6%|▋         | 32/500 [08:21<2:02:21, 15.69s/it]  7%|▋         | 33/500 [08:37<2:02:51, 15.78s/it]  7%|▋         | 34/500 [08:52<2:01:19, 15.62s/it]  7%|▋         | 35/500 [09:08<2:01:28, 15.67s/it]  7%|▋         | 36/500 [09:23<1:59:35, 15.46s/it]  7%|▋         | 37/500 [09:39<1:59:33, 15.49s/it]  8%|▊         | 38/500 [09:55<2:00:33, 15.66s/it]  8%|▊         | 39/500 [10:10<1:59:12, 15.52s/it]  8%|▊         | 40/500 [10:25<1:57:16, 15.30s/it]  8%|▊         | 41/500 [10:40<1:56:10, 15.19s/it]  8%|▊         | 42/500 [10:55<1:56:40, 15.28s/it]  9%|▊         | 43/500 [11:10<1:55:22, 15.15s/it]  9%|▊         | 43/500 [11:10<1:58:47, 15.60s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.019 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▃▂▃█▂▃▃▃▆▆▅▇▆▇▆▇▆▇███▇██▇▇▇████▇██▇▇██
wandb:     train_loss ▂▂▂▁▁▁▂▁▁▁▇▁▁▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▁▃▂▂▆▆▄▅▆▆▆▇▆▇▆▇▆▇▆▇█▇▇▇██▆▇▇█▇█▇▇▇█▇▇▇█
wandb:       val_loss ▂▂▁▂▂▂▄▁▄▅▃▁▆▃▄▄▄▃▄▁▁▁▁▁▄▁▁▃▄▁▁▃█▄▁▃▁▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 42
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.97474
wandb:     train_loss 0.00768
wandb:   val_accuracy 0.75111
wandb:       val_loss 0.07805
wandb: 
wandb: 🚀 View run charmed-voice-115 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/o41pesin
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_143153-o41pesin/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_144404-pmj1i7pw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-totem-116
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/pmj1i7pw
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:21<3:00:40, 21.72s/it]  0%|          | 2/500 [00:37<2:31:51, 18.30s/it]  1%|          | 3/500 [00:53<2:23:01, 17.27s/it]  1%|          | 4/500 [01:09<2:18:26, 16.75s/it]  1%|          | 5/500 [01:25<2:15:22, 16.41s/it]  1%|          | 6/500 [01:41<2:12:51, 16.14s/it]  1%|▏         | 7/500 [01:56<2:11:14, 15.97s/it]  2%|▏         | 8/500 [02:12<2:10:27, 15.91s/it]  2%|▏         | 9/500 [02:28<2:10:21, 15.93s/it]  2%|▏         | 10/500 [02:44<2:10:56, 16.03s/it]  2%|▏         | 11/500 [03:00<2:10:20, 15.99s/it]  2%|▏         | 12/500 [03:16<2:10:22, 16.03s/it]  3%|▎         | 13/500 [03:33<2:12:10, 16.28s/it]  3%|▎         | 14/500 [03:49<2:12:00, 16.30s/it]  3%|▎         | 15/500 [04:06<2:11:55, 16.32s/it]  3%|▎         | 16/500 [04:22<2:11:40, 16.32s/it]  3%|▎         | 17/500 [04:39<2:12:01, 16.40s/it]  4%|▎         | 18/500 [04:55<2:11:20, 16.35s/it]  4%|▍         | 19/500 [05:11<2:10:31, 16.28s/it]  4%|▍         | 20/500 [05:28<2:12:06, 16.51s/it]  4%|▍         | 21/500 [05:44<2:11:10, 16.43s/it]  4%|▍         | 22/500 [06:01<2:11:52, 16.55s/it]  5%|▍         | 23/500 [06:18<2:12:01, 16.61s/it]  5%|▍         | 24/500 [06:34<2:10:46, 16.48s/it]  5%|▌         | 25/500 [06:51<2:11:15, 16.58s/it]  5%|▌         | 26/500 [07:07<2:10:13, 16.48s/it]  5%|▌         | 26/500 [07:07<2:09:56, 16.45s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.313 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.137 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▂▂▂▃▃▅▄▆▇▇▇█▇▇▇██▇▇▇▇▇██
wandb:     train_loss ▇▅▄▇▄▆▅▅█▇▅▅▅▄▅▃▅▇▅▄▁▂▂▁▂▁
wandb:   val_accuracy ▁▁▂▃▃▃▅▅▄▆██▇█████▇▆▆▆▆▆▇▆
wandb:       val_loss ▁▁▁▁▁▁▁▁▁▁▃▁▁▁▂▁▁▁▂▂▂▇▆█▁▂
wandb: 
wandb: Run summary:
wandb:          epoch 25
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.76374
wandb:     train_loss 0.36944
wandb:   val_accuracy 0.49111
wandb:       val_loss 1.91093
wandb: 
wandb: 🚀 View run noble-totem-116 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/pmj1i7pw
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_144404-pmj1i7pw/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_145151-2rsepuc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-totem-117
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2rsepuc6
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:31:47, 18.25s/it]  0%|          | 2/500 [00:35<2:26:19, 17.63s/it]  1%|          | 3/500 [00:52<2:25:11, 17.53s/it]  1%|          | 4/500 [01:15<2:42:18, 19.63s/it]  1%|          | 5/500 [01:32<2:33:29, 18.60s/it]  1%|          | 6/500 [01:49<2:28:45, 18.07s/it]  1%|▏         | 7/500 [02:07<2:27:05, 17.90s/it]  2%|▏         | 8/500 [02:24<2:26:23, 17.85s/it]  2%|▏         | 9/500 [02:42<2:24:23, 17.64s/it]  2%|▏         | 10/500 [02:59<2:22:31, 17.45s/it]  2%|▏         | 11/500 [03:15<2:20:03, 17.19s/it]  2%|▏         | 12/500 [03:32<2:18:53, 17.08s/it]  3%|▎         | 13/500 [03:49<2:18:21, 17.05s/it]  3%|▎         | 14/500 [04:06<2:17:53, 17.02s/it]  3%|▎         | 15/500 [04:23<2:18:25, 17.12s/it]  3%|▎         | 16/500 [04:40<2:17:57, 17.10s/it]  3%|▎         | 17/500 [04:57<2:17:22, 17.06s/it]  4%|▎         | 18/500 [05:13<2:15:00, 16.81s/it]  4%|▍         | 19/500 [05:31<2:15:59, 16.96s/it]  4%|▍         | 20/500 [05:48<2:15:53, 16.99s/it]  4%|▍         | 21/500 [06:05<2:15:36, 16.99s/it]  4%|▍         | 22/500 [06:22<2:15:29, 17.01s/it]  5%|▍         | 23/500 [06:39<2:15:09, 17.00s/it]  5%|▍         | 24/500 [06:56<2:15:29, 17.08s/it]  5%|▌         | 25/500 [07:13<2:13:39, 16.88s/it]  5%|▌         | 26/500 [07:29<2:12:11, 16.73s/it]  5%|▌         | 27/500 [07:47<2:13:55, 16.99s/it]  6%|▌         | 28/500 [08:07<2:22:18, 18.09s/it]  6%|▌         | 29/500 [08:24<2:19:26, 17.76s/it]  6%|▌         | 29/500 [08:24<2:16:41, 17.41s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.028 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.137 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▃▄▃▁▃▄▃▄▅▃▅▄▆▅▅▅▆▇▅▅▅▆▇▄▇▇▇▆█
wandb:     train_loss ▃▃▃▃▅▃▅▆▃▃▂▆▁▁▁▃▃▂█▁▂▂▁▂▂▁▁▁▂
wandb:   val_accuracy ▂▇▅▁▂▄▂▅▇▁█▄▇▆▅▄▅▇▇▄▆▆▇▄█▆▆▆█
wandb:       val_loss ▁▁▁▃▁▁▁▂█▁▄▁▁▁▂▁▂▂▂▄▇▂▂▂▁▁▃▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 28
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.88559
wandb:     train_loss 0.52473
wandb:   val_accuracy 0.49778
wandb:       val_loss 1.22439
wandb: 
wandb: 🚀 View run unique-totem-117 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2rsepuc6
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_145151-2rsepuc6/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_150059-ki1dgu7d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-dust-118
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ki1dgu7d
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:22<3:11:04, 22.97s/it]  0%|          | 2/500 [00:39<2:36:53, 18.90s/it]  1%|          | 3/500 [00:54<2:23:40, 17.35s/it]  1%|          | 4/500 [01:10<2:18:30, 16.75s/it]  1%|          | 5/500 [01:30<2:29:41, 18.14s/it]  1%|          | 6/500 [01:47<2:24:29, 17.55s/it]  1%|▏         | 7/500 [02:03<2:19:35, 16.99s/it]  2%|▏         | 8/500 [02:19<2:17:21, 16.75s/it]  2%|▏         | 9/500 [02:35<2:15:35, 16.57s/it]  2%|▏         | 10/500 [02:51<2:13:04, 16.30s/it]  2%|▏         | 11/500 [03:07<2:11:23, 16.12s/it]  2%|▏         | 12/500 [03:22<2:09:59, 15.98s/it]  3%|▎         | 13/500 [03:38<2:08:58, 15.89s/it]  3%|▎         | 14/500 [03:54<2:09:01, 15.93s/it]  3%|▎         | 15/500 [04:10<2:09:24, 16.01s/it]  3%|▎         | 16/500 [04:26<2:08:12, 15.89s/it]  3%|▎         | 17/500 [04:41<2:07:14, 15.81s/it]  4%|▎         | 18/500 [04:57<2:06:45, 15.78s/it]  4%|▍         | 19/500 [05:13<2:07:05, 15.85s/it]  4%|▍         | 20/500 [05:29<2:06:25, 15.80s/it]  4%|▍         | 21/500 [05:45<2:06:18, 15.82s/it]  4%|▍         | 22/500 [06:00<2:05:31, 15.76s/it]  5%|▍         | 23/500 [06:16<2:04:34, 15.67s/it]  5%|▍         | 24/500 [06:32<2:04:55, 15.75s/it]  5%|▌         | 25/500 [06:47<2:03:54, 15.65s/it]  5%|▌         | 26/500 [07:03<2:03:32, 15.64s/it]  5%|▌         | 27/500 [07:23<2:13:42, 16.96s/it]  6%|▌         | 28/500 [07:39<2:11:23, 16.70s/it]  6%|▌         | 29/500 [07:54<2:08:13, 16.33s/it]  6%|▌         | 30/500 [08:10<2:06:24, 16.14s/it]  6%|▌         | 31/500 [08:26<2:04:50, 15.97s/it]  6%|▋         | 32/500 [08:41<2:04:23, 15.95s/it]  7%|▋         | 33/500 [08:57<2:03:47, 15.90s/it]  7%|▋         | 34/500 [09:13<2:02:36, 15.79s/it]  7%|▋         | 35/500 [09:28<2:01:31, 15.68s/it]  7%|▋         | 36/500 [09:44<2:01:17, 15.68s/it]  7%|▋         | 37/500 [09:59<2:00:20, 15.60s/it]  8%|▊         | 38/500 [10:15<2:00:12, 15.61s/it]  8%|▊         | 39/500 [10:31<1:59:58, 15.61s/it]  8%|▊         | 40/500 [10:46<1:59:51, 15.63s/it]  8%|▊         | 41/500 [11:02<1:59:21, 15.60s/it]  8%|▊         | 42/500 [11:17<1:59:18, 15.63s/it]  9%|▊         | 43/500 [11:33<1:58:41, 15.58s/it]  9%|▊         | 43/500 [11:33<2:02:50, 16.13s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.028 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.019 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▃▄▄▆▃▅▇▇██▇▇▅▆▇▇▇▇▇▇█▆▇▇▆▆▇▆▇▅▆▆▆▆▅▆▆
wandb:     train_loss ▂▁▃█▂▁▁▁▄▁▃▁▃▂▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▂▁▁▄▁▁
wandb:   val_accuracy ▁▁▁▃▃▄▅▄▄▇▇▇█▇▇▃▆▆▇▇▇▇▆▇█▇▆▆▆▆▆▇▅▆▇▇▆▆▆▆
wandb:       val_loss ▁▁▁▂▁▁▂▁▁▂▁▁▃▂▂▂▂▂▂▁▁▁▂▁▂▁▁▂▂▁▃▃▄▃▂█▂▁▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 42
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.71174
wandb:     train_loss 0.03635
wandb:   val_accuracy 0.54222
wandb:       val_loss 2.01405
wandb: 
wandb: 🚀 View run dandy-dust-118 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ki1dgu7d
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_150059-ki1dgu7d/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_151316-un7logxy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-terrain-119
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/un7logxy
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:30:15, 18.07s/it]  0%|          | 2/500 [00:34<2:20:39, 16.95s/it]  1%|          | 3/500 [00:51<2:20:01, 16.90s/it]  1%|          | 4/500 [01:07<2:17:22, 16.62s/it]  1%|          | 5/500 [01:24<2:17:30, 16.67s/it]  1%|          | 6/500 [01:40<2:16:11, 16.54s/it]  1%|▏         | 7/500 [01:56<2:14:59, 16.43s/it]  2%|▏         | 8/500 [02:12<2:13:08, 16.24s/it]  2%|▏         | 9/500 [02:28<2:11:44, 16.10s/it]  2%|▏         | 10/500 [02:44<2:11:42, 16.13s/it]  2%|▏         | 11/500 [03:00<2:10:37, 16.03s/it]  2%|▏         | 12/500 [03:16<2:11:04, 16.12s/it]  3%|▎         | 13/500 [03:33<2:12:38, 16.34s/it]  3%|▎         | 14/500 [03:49<2:11:52, 16.28s/it]  3%|▎         | 15/500 [04:04<2:09:31, 16.02s/it]  3%|▎         | 16/500 [04:20<2:07:46, 15.84s/it]  3%|▎         | 17/500 [04:36<2:08:11, 15.92s/it]  4%|▎         | 18/500 [04:56<2:17:16, 17.09s/it]  4%|▍         | 19/500 [05:12<2:16:03, 16.97s/it]  4%|▍         | 20/500 [05:29<2:14:12, 16.78s/it]  4%|▍         | 21/500 [05:46<2:14:27, 16.84s/it]  4%|▍         | 22/500 [06:07<2:25:31, 18.27s/it]  5%|▍         | 23/500 [06:24<2:21:14, 17.77s/it]  5%|▍         | 24/500 [06:40<2:17:57, 17.39s/it]  5%|▌         | 25/500 [06:57<2:16:39, 17.26s/it]  5%|▌         | 26/500 [07:14<2:14:24, 17.01s/it]  5%|▌         | 27/500 [07:30<2:12:14, 16.77s/it]  6%|▌         | 28/500 [07:52<2:24:12, 18.33s/it]  6%|▌         | 28/500 [07:52<2:12:45, 16.88s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▃▁▅▄▅▇▇▇███▇█▇██▇▇▇█▇▇▇██▇
wandb:     train_loss ▆▅▅█▅▄▅▅▄▄▄▄▄▂▄▃▃▃▅▂▄▆▃▆▇▅▁▁
wandb:   val_accuracy ▃▃▆▁▁▄▆▄▄▂▄▅▆▅▆█▇▇█▇▅▆▆▆▄▆▇▆
wandb:       val_loss ▂▂▂▃▂▂▂▂▂▂▄▁▃▂▂▂▃▅▂▃█▁▁▆▂▃▂▃
wandb: 
wandb: Run summary:
wandb:          epoch 27
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.75037
wandb:     train_loss 0.25959
wandb:   val_accuracy 0.37111
wandb:       val_loss 1.34682
wandb: 
wandb: 🚀 View run autumn-terrain-119 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/un7logxy
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_151316-un7logxy/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_152159-82vakxbx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-pyramid-120
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/82vakxbx
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:32<4:26:51, 32.09s/it]  0%|          | 2/500 [00:59<4:05:51, 29.62s/it]  1%|          | 3/500 [01:32<4:16:09, 30.92s/it]  1%|          | 4/500 [02:16<4:57:37, 36.00s/it]  1%|          | 5/500 [02:50<4:51:46, 35.37s/it]  1%|          | 6/500 [03:06<3:56:01, 28.67s/it]  1%|▏         | 7/500 [03:26<3:32:34, 25.87s/it]  2%|▏         | 8/500 [03:41<3:04:44, 22.53s/it]  2%|▏         | 9/500 [04:01<2:58:25, 21.80s/it]  2%|▏         | 10/500 [04:21<2:53:42, 21.27s/it]  2%|▏         | 11/500 [04:37<2:39:24, 19.56s/it]  2%|▏         | 12/500 [04:53<2:29:49, 18.42s/it]  3%|▎         | 13/500 [05:09<2:23:32, 17.68s/it]  3%|▎         | 14/500 [05:28<2:25:36, 17.98s/it]  3%|▎         | 15/500 [06:00<3:00:57, 22.39s/it]  3%|▎         | 16/500 [06:31<3:20:43, 24.88s/it]  3%|▎         | 17/500 [07:00<3:31:32, 26.28s/it]  4%|▎         | 18/500 [07:35<3:51:23, 28.80s/it]  4%|▍         | 19/500 [08:04<3:50:05, 28.70s/it]  4%|▍         | 20/500 [08:34<3:55:01, 29.38s/it]  4%|▍         | 21/500 [09:11<4:12:00, 31.57s/it]  4%|▍         | 22/500 [09:32<3:46:01, 28.37s/it]  5%|▍         | 23/500 [09:48<3:14:52, 24.51s/it]  5%|▍         | 24/500 [10:03<2:53:49, 21.91s/it]  5%|▌         | 25/500 [10:24<2:49:17, 21.38s/it]  5%|▌         | 26/500 [10:39<2:34:56, 19.61s/it]  5%|▌         | 27/500 [10:55<2:25:10, 18.42s/it]  6%|▌         | 28/500 [11:10<2:17:37, 17.49s/it]  6%|▌         | 29/500 [11:26<2:13:23, 16.99s/it]  6%|▌         | 30/500 [11:41<2:09:55, 16.59s/it]  6%|▌         | 31/500 [12:01<2:17:27, 17.59s/it]  6%|▋         | 32/500 [12:17<2:12:26, 16.98s/it]  7%|▋         | 33/500 [12:32<2:08:37, 16.52s/it]  7%|▋         | 34/500 [12:48<2:06:08, 16.24s/it]  7%|▋         | 35/500 [13:04<2:04:11, 16.03s/it]  7%|▋         | 36/500 [13:19<2:03:33, 15.98s/it]  7%|▋         | 37/500 [13:35<2:02:33, 15.88s/it]  8%|▊         | 38/500 [13:50<2:01:14, 15.75s/it]  8%|▊         | 39/500 [14:06<2:01:02, 15.75s/it]  8%|▊         | 40/500 [14:22<2:01:41, 15.87s/it]  8%|▊         | 41/500 [14:38<2:00:50, 15.80s/it]  8%|▊         | 42/500 [14:54<2:00:28, 15.78s/it]  9%|▊         | 43/500 [15:09<1:59:44, 15.72s/it]  9%|▉         | 44/500 [15:25<1:59:22, 15.71s/it]  9%|▉         | 45/500 [15:40<1:58:03, 15.57s/it]  9%|▉         | 46/500 [15:55<1:57:02, 15.47s/it]  9%|▉         | 47/500 [16:11<1:57:10, 15.52s/it] 10%|▉         | 48/500 [16:27<1:57:01, 15.53s/it] 10%|▉         | 49/500 [16:42<1:57:09, 15.59s/it] 10%|█         | 50/500 [16:58<1:57:11, 15.63s/it] 10%|█         | 51/500 [17:14<1:57:21, 15.68s/it] 10%|█         | 52/500 [17:30<1:57:07, 15.69s/it] 11%|█         | 53/500 [17:45<1:56:38, 15.66s/it] 11%|█         | 54/500 [18:05<2:06:32, 17.02s/it] 11%|█         | 55/500 [18:21<2:03:18, 16.63s/it] 11%|█         | 56/500 [18:37<2:00:39, 16.31s/it] 11%|█         | 56/500 [18:41<2:28:13, 20.03s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.019 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ███████▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▄▃▁▃▄▄▄▅▆▇▆▇▇▇█▇███▇▇███▇█▇▇█▇▇████████▇
wandb:     train_loss ▂▂▂▂▁█▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁
wandb:   val_accuracy ▅▅▁▅▇▅▆██▇▆▅▄▄▄▅▄▄▄▄▄▅▅▄▅▄▆▄▄▆▅▅▅▅▅▄▅▅▅▅
wandb:       val_loss ▂▂▂▂▂▆▂▂▁▂▆▃▂▂▄▁▁▆▂▂▇▃▁▆▄▆▇▇▁▃▂▃█▃▁▂█▅▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 55
wandb:  learning_rate 2e-05
wandb: train_accuracy 0.79792
wandb:     train_loss 0.41765
wandb:   val_accuracy 0.33778
wandb:       val_loss 1.07279
wandb: 
wandb: 🚀 View run dainty-pyramid-120 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/82vakxbx
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240918_152159-82vakxbx/logs
Successfully processed 1_20131030
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20240918_154121-2eg9ksc9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-water-121
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/2eg9ksc9
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:31:42, 25.46s/it]  0%|          | 2/500 [00:49<3:24:37, 24.65s/it]  1%|          | 3/500 [01:14<3:24:55, 24.74s/it]  1%|          | 4/500 [01:43<3:39:24, 26.54s/it]  1%|          | 5/500 [02:07<3:31:43, 25.66s/it]  1%|          | 6/500 [02:31<3:26:07, 25.03s/it]  1%|▏         | 7/500 [03:00<3:36:35, 26.36s/it]  2%|▏         | 8/500 [03:24<3:30:20, 25.65s/it]  2%|▏         | 9/500 [03:48<3:25:16, 25.09s/it]  2%|▏         | 10/500 [04:16<3:32:36, 26.03s/it]  2%|▏         | 11/500 [04:40<3:26:09, 25.29s/it]  2%|▏         | 12/500 [05:04<3:21:47, 24.81s/it]  3%|▎         | 13/500 [05:27<3:18:50, 24.50s/it]  3%|▎         | 14/500 [05:51<3:17:05, 24.33s/it]  3%|▎         | 15/500 [06:23<3:33:25, 26.40s/it]  3%|▎         | 16/500 [06:51<3:38:46, 27.12s/it]  3%|▎         | 17/500 [07:21<3:43:18, 27.74s/it]  4%|▎         | 18/500 [07:50<3:46:42, 28.22s/it]  4%|▍         | 19/500 [08:14<3:35:58, 26.94s/it]  4%|▍         | 20/500 [08:38<3:27:47, 25.97s/it]  4%|▍         | 21/500 [09:02<3:22:31, 25.37s/it]  4%|▍         | 22/500 [09:25<3:17:57, 24.85s/it]  5%|▍         | 23/500 [09:49<3:14:41, 24.49s/it]  5%|▍         | 24/500 [10:13<3:12:24, 24.25s/it]  5%|▌         | 25/500 [10:38<3:14:17, 24.54s/it]  5%|▌         | 26/500 [11:01<3:11:42, 24.27s/it]