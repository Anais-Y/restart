nohup: 忽略输入
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_093325-xpr3592k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-aardvark-2648
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xpr3592k
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:29:09, 17.94s/it]  0%|          | 2/500 [00:30<2:02:09, 14.72s/it]  1%|          | 3/500 [00:41<1:48:15, 13.07s/it]  1%|          | 4/500 [00:52<1:40:56, 12.21s/it]  1%|          | 5/500 [01:03<1:38:28, 11.94s/it]  1%|          | 6/500 [01:15<1:36:54, 11.77s/it]  1%|▏         | 7/500 [01:26<1:34:43, 11.53s/it]  2%|▏         | 8/500 [01:38<1:36:07, 11.72s/it]  2%|▏         | 9/500 [01:50<1:37:13, 11.88s/it]  2%|▏         | 10/500 [02:02<1:38:02, 12.00s/it]  2%|▏         | 11/500 [02:15<1:38:44, 12.12s/it]  2%|▏         | 12/500 [02:27<1:38:54, 12.16s/it]  3%|▎         | 13/500 [02:50<2:03:54, 15.27s/it]  3%|▎         | 14/500 [03:01<1:53:32, 14.02s/it]  3%|▎         | 15/500 [03:12<1:45:47, 13.09s/it]  3%|▎         | 16/500 [03:22<1:39:09, 12.29s/it]  3%|▎         | 17/500 [03:32<1:34:24, 11.73s/it]  4%|▎         | 18/500 [03:43<1:30:47, 11.30s/it]  4%|▍         | 19/500 [03:53<1:28:29, 11.04s/it]  4%|▍         | 20/500 [04:04<1:26:52, 10.86s/it]  4%|▍         | 21/500 [04:14<1:25:57, 10.77s/it]  4%|▍         | 22/500 [04:25<1:24:46, 10.64s/it]  5%|▍         | 23/500 [04:35<1:24:50, 10.67s/it]  5%|▍         | 24/500 [04:47<1:26:13, 10.87s/it]  5%|▌         | 25/500 [04:57<1:24:48, 10.71s/it]  5%|▌         | 26/500 [05:07<1:23:41, 10.59s/it]  5%|▌         | 27/500 [05:18<1:23:47, 10.63s/it]  6%|▌         | 28/500 [05:29<1:23:45, 10.65s/it]  6%|▌         | 29/500 [05:39<1:22:56, 10.56s/it]  6%|▌         | 29/500 [05:39<1:31:55, 11.71s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.311 MB uploadedwandb: \ 0.010 MB of 0.311 MB uploadedwandb: | 0.231 MB of 0.311 MB uploadedwandb: / 0.231 MB of 0.311 MB uploadedwandb: - 0.231 MB of 0.311 MB uploadedwandb: \ 0.231 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▄▆▂▁▁▁▂▄▆█▅███▇█▇▇▃██▆██▇
wandb:     train_loss ▂▂█▃▁▁▇▅▅▄▃▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▄▆▆▇▇▂▅▆▅▆▁█▇█▇▇▇▇▇█▇▆▇▇█▇▇▇
wandb:       val_loss ▂▂▇▂▄▄▃▄▃▃█▄▁▃▃▇▁▄▂▄▆▁▅▄▃▄▁█▇
wandb: 
wandb: Run summary:
wandb:          epoch 28
wandb:  learning_rate 0.00064
wandb: train_accuracy 0.90639
wandb:     train_loss 5e-05
wandb:   val_accuracy 0.43778
wandb:       val_loss 6.97033
wandb: 
wandb: 🚀 View run feasible-aardvark-2648 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xpr3592k
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_093325-xpr3592k/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_093959-qarp5mip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-fire-2649
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qarp5mip
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:12:11, 15.90s/it]  0%|          | 2/500 [00:28<1:56:21, 14.02s/it]  1%|          | 3/500 [00:40<1:47:50, 13.02s/it]  1%|          | 4/500 [00:50<1:38:58, 11.97s/it]  1%|          | 5/500 [01:01<1:35:05, 11.53s/it]  1%|          | 6/500 [01:12<1:32:01, 11.18s/it]  1%|▏         | 7/500 [01:22<1:30:14, 10.98s/it]  2%|▏         | 8/500 [01:33<1:28:40, 10.81s/it]  2%|▏         | 9/500 [01:43<1:28:17, 10.79s/it]  2%|▏         | 10/500 [01:54<1:27:45, 10.75s/it]  2%|▏         | 11/500 [02:04<1:25:35, 10.50s/it]  2%|▏         | 12/500 [02:14<1:24:23, 10.38s/it]  3%|▎         | 13/500 [02:24<1:23:05, 10.24s/it]  3%|▎         | 14/500 [02:34<1:22:16, 10.16s/it]  3%|▎         | 15/500 [02:44<1:21:36, 10.10s/it]  3%|▎         | 16/500 [02:54<1:20:48, 10.02s/it]  3%|▎         | 17/500 [03:04<1:20:57, 10.06s/it]  4%|▎         | 18/500 [03:14<1:21:31, 10.15s/it]  4%|▍         | 19/500 [03:25<1:22:08, 10.25s/it]  4%|▍         | 20/500 [03:35<1:22:16, 10.28s/it]  4%|▍         | 21/500 [03:46<1:22:57, 10.39s/it]  4%|▍         | 22/500 [03:56<1:22:41, 10.38s/it]  5%|▍         | 23/500 [04:06<1:21:52, 10.30s/it]  5%|▍         | 24/500 [04:16<1:20:20, 10.13s/it]  5%|▌         | 25/500 [04:26<1:20:17, 10.14s/it]  5%|▌         | 26/500 [04:36<1:19:24, 10.05s/it]  5%|▌         | 27/500 [04:46<1:18:49, 10.00s/it]  6%|▌         | 28/500 [04:56<1:18:09,  9.94s/it]  6%|▌         | 29/500 [05:05<1:17:30,  9.87s/it]  6%|▌         | 30/500 [05:15<1:17:30,  9.89s/it]  6%|▌         | 31/500 [05:25<1:17:14,  9.88s/it]  6%|▋         | 32/500 [05:35<1:17:33,  9.94s/it]  7%|▋         | 33/500 [05:45<1:17:18,  9.93s/it]  7%|▋         | 34/500 [05:55<1:17:22,  9.96s/it]  7%|▋         | 35/500 [06:05<1:16:53,  9.92s/it]  7%|▋         | 36/500 [06:15<1:16:29,  9.89s/it]  7%|▋         | 37/500 [06:24<1:15:58,  9.84s/it]  8%|▊         | 38/500 [06:34<1:15:59,  9.87s/it]  8%|▊         | 39/500 [06:44<1:15:36,  9.84s/it]  8%|▊         | 40/500 [06:54<1:15:44,  9.88s/it]  8%|▊         | 41/500 [07:04<1:15:41,  9.89s/it]  8%|▊         | 41/500 [07:04<1:19:13, 10.36s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.232 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▁▂▁▁▄▄▁▃▄▁▂▁▄▄▇▆▄▄▄▄▇▆▅▁▅▄▄█▂▃▁▁▅▄▄▄▅▄▄
wandb:     train_loss ▂▂▂▂▂▂▂▂▂▂▁▂▁▂▂▂▂▂▂▂▃▂▁▂█▂▂▂▁▂▂▁▁▃▃▂▃▂▃▂
wandb:   val_accuracy ▇▇▇▇▄▇▁▆▇▇▆▄▆▇█▆▇▇▆█▇▇▄▇▆▇▇▇█▆▇▆▆▆▇▇▇█▇▇
wandb:       val_loss ▃▃▃▃▃▃▃▄▃▃▂▄▅▃▃▅▃▃▃▄▃▃▄▄▁▄▃▄▄▆▆▁█▄▂▃▄▃▄▅
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.51412
wandb:     train_loss 1.4091
wandb:   val_accuracy 0.35556
wandb:       val_loss 1.82175
wandb: 
wandb: 🚀 View run fresh-fire-2649 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qarp5mip
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_093959-qarp5mip/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_094743-erzx5a2j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-dawn-2650
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/erzx5a2j
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:14:51, 16.22s/it]  0%|          | 2/500 [00:28<1:54:21, 13.78s/it]  1%|          | 3/500 [00:39<1:44:13, 12.58s/it]  1%|          | 4/500 [00:49<1:37:21, 11.78s/it]  1%|          | 5/500 [01:00<1:33:45, 11.36s/it]  1%|          | 6/500 [01:10<1:29:32, 10.88s/it]  1%|▏         | 7/500 [01:20<1:27:40, 10.67s/it]  2%|▏         | 8/500 [01:30<1:26:11, 10.51s/it]  2%|▏         | 9/500 [01:40<1:24:24, 10.32s/it]  2%|▏         | 10/500 [01:50<1:22:55, 10.15s/it]  2%|▏         | 11/500 [02:00<1:21:54, 10.05s/it]  2%|▏         | 12/500 [02:10<1:21:20, 10.00s/it]  3%|▎         | 13/500 [02:20<1:20:52,  9.96s/it]  3%|▎         | 14/500 [02:30<1:20:18,  9.91s/it]  3%|▎         | 15/500 [02:40<1:20:20,  9.94s/it]  3%|▎         | 16/500 [02:50<1:21:37, 10.12s/it]  3%|▎         | 17/500 [03:01<1:22:50, 10.29s/it]  4%|▎         | 18/500 [03:11<1:22:24, 10.26s/it]  4%|▍         | 19/500 [03:21<1:22:27, 10.29s/it]  4%|▍         | 20/500 [03:31<1:21:33, 10.19s/it]  4%|▍         | 21/500 [03:41<1:20:45, 10.12s/it]  4%|▍         | 22/500 [03:51<1:20:29, 10.10s/it]  5%|▍         | 23/500 [04:02<1:21:57, 10.31s/it]  5%|▍         | 24/500 [04:13<1:23:05, 10.47s/it]  5%|▌         | 25/500 [04:23<1:23:09, 10.50s/it]  5%|▌         | 26/500 [04:34<1:22:32, 10.45s/it]  5%|▌         | 27/500 [04:44<1:22:05, 10.41s/it]  6%|▌         | 28/500 [04:54<1:21:34, 10.37s/it]  6%|▌         | 29/500 [05:05<1:22:13, 10.47s/it]  6%|▌         | 30/500 [05:15<1:21:11, 10.36s/it]  6%|▌         | 31/500 [05:25<1:20:14, 10.27s/it]  6%|▋         | 32/500 [05:35<1:19:21, 10.17s/it]  7%|▋         | 33/500 [05:45<1:18:28, 10.08s/it]  7%|▋         | 34/500 [05:55<1:17:48, 10.02s/it]  7%|▋         | 35/500 [06:05<1:17:15,  9.97s/it]  7%|▋         | 36/500 [06:15<1:17:13,  9.99s/it]  7%|▋         | 37/500 [06:25<1:16:40,  9.94s/it]  8%|▊         | 38/500 [06:35<1:16:18,  9.91s/it]  8%|▊         | 38/500 [06:35<1:20:02, 10.40s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.028 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▂▁▁▄▆▁▆▁▆▄▁▄▅▃▆▅▁▅▆▂▁▅▅▃▄▅██▅▅▅▃█▂▇█
wandb:     train_loss ▂▂▂▅▁▁▁▆▂█▁▁▄▃▂▄▁▂▆▁▂▄▅▁▃▁▂▄▁▁▃▁▂▅▁▁▁▁
wandb:   val_accuracy ▅▄▄▆▆▁▇▅█▆▄▁▅▁▁▁▃▂▅██▆▅▇▇▆▇▁▄▅▇█▇▆▇▆▇▆
wandb:       val_loss ▂▂▂▄▇▂▁▄▂▄▃▂▂▃▄█▂▃▄▃▄▁▃▄▃▃▁▆▅▁▃▆▅▃▁▂▅▃
wandb: 
wandb: Run summary:
wandb:          epoch 37
wandb:  learning_rate 0.00026
wandb: train_accuracy 0.99554
wandb:     train_loss 6e-05
wandb:   val_accuracy 0.36222
wandb:       val_loss 4.21339
wandb: 
wandb: 🚀 View run fanciful-dawn-2650 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/erzx5a2j
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_094743-erzx5a2j/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_095456-yzaigfxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-bird-2651
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/yzaigfxq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<2:04:27, 14.97s/it]  0%|          | 2/500 [00:27<1:53:08, 13.63s/it]  1%|          | 3/500 [00:39<1:45:53, 12.78s/it]  1%|          | 4/500 [00:50<1:41:04, 12.23s/it]  1%|          | 5/500 [01:01<1:36:14, 11.67s/it]  1%|          | 6/500 [01:13<1:35:54, 11.65s/it]  1%|▏         | 7/500 [01:24<1:35:19, 11.60s/it]  2%|▏         | 8/500 [01:35<1:33:51, 11.45s/it]  2%|▏         | 9/500 [01:45<1:30:09, 11.02s/it]  2%|▏         | 10/500 [01:55<1:26:58, 10.65s/it]  2%|▏         | 11/500 [02:06<1:27:41, 10.76s/it]  2%|▏         | 12/500 [02:17<1:26:49, 10.68s/it]  3%|▎         | 13/500 [02:26<1:24:32, 10.41s/it]  3%|▎         | 14/500 [02:36<1:22:52, 10.23s/it]  3%|▎         | 15/500 [02:46<1:21:47, 10.12s/it]  3%|▎         | 16/500 [02:56<1:20:34,  9.99s/it]  3%|▎         | 17/500 [03:06<1:19:53,  9.92s/it]  4%|▎         | 18/500 [03:15<1:19:45,  9.93s/it]  4%|▍         | 19/500 [03:25<1:19:31,  9.92s/it]  4%|▍         | 20/500 [03:35<1:18:51,  9.86s/it]  4%|▍         | 21/500 [03:45<1:18:37,  9.85s/it]  4%|▍         | 22/500 [03:55<1:19:30,  9.98s/it]  5%|▍         | 23/500 [04:06<1:20:25, 10.12s/it]  5%|▍         | 24/500 [04:16<1:20:36, 10.16s/it]  5%|▌         | 25/500 [04:26<1:20:25, 10.16s/it]  5%|▌         | 26/500 [04:36<1:20:40, 10.21s/it]  5%|▌         | 27/500 [04:47<1:21:12, 10.30s/it]  6%|▌         | 28/500 [04:57<1:20:14, 10.20s/it]  6%|▌         | 29/500 [05:08<1:21:21, 10.36s/it]  6%|▌         | 30/500 [05:18<1:20:56, 10.33s/it]  6%|▌         | 31/500 [05:28<1:19:21, 10.15s/it]  6%|▋         | 32/500 [05:37<1:18:25, 10.06s/it]  7%|▋         | 33/500 [05:47<1:17:31,  9.96s/it]  7%|▋         | 34/500 [05:57<1:17:04,  9.92s/it]  7%|▋         | 35/500 [06:07<1:16:53,  9.92s/it]  7%|▋         | 36/500 [06:17<1:16:37,  9.91s/it]  7%|▋         | 37/500 [06:27<1:16:36,  9.93s/it]  8%|▊         | 38/500 [06:37<1:17:04, 10.01s/it]  8%|▊         | 39/500 [06:47<1:17:52, 10.14s/it]  8%|▊         | 40/500 [06:58<1:18:15, 10.21s/it]  8%|▊         | 41/500 [07:08<1:18:57, 10.32s/it]  8%|▊         | 42/500 [07:19<1:19:48, 10.45s/it]  9%|▊         | 43/500 [07:30<1:20:30, 10.57s/it]  9%|▉         | 44/500 [07:41<1:20:35, 10.61s/it]  9%|▉         | 45/500 [07:51<1:20:17, 10.59s/it]  9%|▉         | 46/500 [08:01<1:19:14, 10.47s/it]  9%|▉         | 47/500 [08:12<1:18:15, 10.36s/it] 10%|▉         | 48/500 [08:22<1:18:24, 10.41s/it] 10%|▉         | 49/500 [08:32<1:17:47, 10.35s/it] 10%|█         | 50/500 [08:42<1:16:58, 10.26s/it] 10%|█         | 51/500 [08:53<1:16:56, 10.28s/it] 10%|█         | 52/500 [09:03<1:17:28, 10.38s/it] 11%|█         | 53/500 [09:13<1:16:22, 10.25s/it] 11%|█         | 54/500 [09:23<1:14:58, 10.09s/it] 11%|█         | 55/500 [09:33<1:14:16, 10.01s/it] 11%|█         | 56/500 [09:43<1:13:41,  9.96s/it] 11%|█▏        | 57/500 [09:52<1:13:14,  9.92s/it] 11%|█▏        | 57/500 [09:52<1:16:48, 10.40s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.020 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▆▆▆▆▆▆▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁
wandb: train_accuracy ▁▁▁▁▃▄▁▅▁▅▇▄█▄▇█▇▇▇█▇█▇████▇▇▇▇█████▇█▇█
wandb:     train_loss ▂▄▄▁▁▃█▁▅▁▁▁▁▂▁▁▁▂▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁
wandb:   val_accuracy ▅▅▆▅▃▁▆▂▅▂▃█▆▇▇▅▃██▇█▆▇▆▆▅▅▆▇▇▇▆▇▆▇▇█▇▇▆
wandb:       val_loss ▂▂▄▄▄▆▄▄▂▃▄▅▄▃▅▄▄▃▄▆▅█▇▄▂▁▄▅▁▁▂▆▁▅▁▅▁██▇
wandb: 
wandb: Run summary:
wandb:          epoch 56
wandb:  learning_rate 0.00033
wandb: train_accuracy 0.95542
wandb:     train_loss 0.00303
wandb:   val_accuracy 0.38667
wandb:       val_loss 9.15963
wandb: 
wandb: 🚀 View run morning-bird-2651 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/yzaigfxq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_095456-yzaigfxq/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_100529-lvlxmnfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-snowball-2652
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lvlxmnfb
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:12<1:44:05, 12.52s/it]  0%|          | 2/500 [00:24<1:39:54, 12.04s/it]  1%|          | 3/500 [00:36<1:39:12, 11.98s/it]  1%|          | 4/500 [00:47<1:36:30, 11.68s/it]  1%|          | 5/500 [00:58<1:34:19, 11.43s/it]  1%|          | 6/500 [01:08<1:31:54, 11.16s/it]  1%|▏         | 7/500 [01:19<1:30:35, 11.03s/it]  2%|▏         | 8/500 [01:30<1:29:34, 10.92s/it]  2%|▏         | 9/500 [01:40<1:28:09, 10.77s/it]  2%|▏         | 10/500 [01:51<1:27:13, 10.68s/it]  2%|▏         | 11/500 [02:01<1:26:52, 10.66s/it]  2%|▏         | 12/500 [02:12<1:26:07, 10.59s/it]  3%|▎         | 13/500 [02:22<1:25:46, 10.57s/it]  3%|▎         | 14/500 [02:33<1:25:22, 10.54s/it]  3%|▎         | 15/500 [02:44<1:25:24, 10.57s/it]  3%|▎         | 16/500 [02:54<1:25:11, 10.56s/it]  3%|▎         | 17/500 [03:05<1:24:57, 10.55s/it]  4%|▎         | 18/500 [03:15<1:24:29, 10.52s/it]  4%|▍         | 19/500 [03:26<1:26:07, 10.74s/it]  4%|▍         | 20/500 [03:38<1:27:20, 10.92s/it]  4%|▍         | 21/500 [03:48<1:26:46, 10.87s/it]  4%|▍         | 22/500 [03:59<1:25:41, 10.76s/it]  5%|▍         | 23/500 [04:09<1:24:42, 10.66s/it]  5%|▍         | 24/500 [04:20<1:24:00, 10.59s/it]  5%|▌         | 25/500 [04:31<1:26:13, 10.89s/it]  5%|▌         | 26/500 [04:42<1:24:34, 10.71s/it]  5%|▌         | 27/500 [04:52<1:24:15, 10.69s/it]  6%|▌         | 28/500 [05:03<1:23:54, 10.67s/it]  6%|▌         | 29/500 [05:13<1:23:33, 10.64s/it]  6%|▌         | 30/500 [05:24<1:22:32, 10.54s/it]  6%|▌         | 31/500 [05:34<1:22:00, 10.49s/it]  6%|▋         | 32/500 [05:45<1:21:45, 10.48s/it]  7%|▋         | 33/500 [05:55<1:21:20, 10.45s/it]  7%|▋         | 34/500 [06:05<1:20:53, 10.42s/it]  7%|▋         | 35/500 [06:16<1:20:40, 10.41s/it]  7%|▋         | 36/500 [06:26<1:20:14, 10.38s/it]  7%|▋         | 37/500 [06:36<1:20:01, 10.37s/it]  8%|▊         | 38/500 [06:47<1:19:57, 10.39s/it]  8%|▊         | 39/500 [06:57<1:20:34, 10.49s/it]  8%|▊         | 40/500 [07:08<1:20:38, 10.52s/it]  8%|▊         | 41/500 [07:19<1:21:43, 10.68s/it]  8%|▊         | 42/500 [07:30<1:22:17, 10.78s/it]  9%|▊         | 43/500 [07:41<1:21:38, 10.72s/it]  9%|▉         | 44/500 [07:51<1:20:25, 10.58s/it]  9%|▉         | 45/500 [08:01<1:19:47, 10.52s/it]  9%|▉         | 46/500 [08:12<1:19:19, 10.48s/it]  9%|▉         | 47/500 [08:22<1:18:48, 10.44s/it] 10%|▉         | 48/500 [08:32<1:18:23, 10.41s/it] 10%|▉         | 49/500 [08:43<1:18:15, 10.41s/it] 10%|█         | 50/500 [08:53<1:17:49, 10.38s/it] 10%|█         | 51/500 [09:03<1:17:33, 10.36s/it] 10%|█         | 52/500 [09:14<1:17:43, 10.41s/it] 11%|█         | 53/500 [09:24<1:17:12, 10.36s/it] 11%|█         | 54/500 [09:35<1:16:55, 10.35s/it] 11%|█         | 55/500 [09:45<1:16:38, 10.33s/it] 11%|█         | 56/500 [09:55<1:16:22, 10.32s/it] 11%|█▏        | 57/500 [10:06<1:16:16, 10.33s/it] 12%|█▏        | 58/500 [10:16<1:16:07, 10.33s/it] 12%|█▏        | 59/500 [10:26<1:16:13, 10.37s/it] 12%|█▏        | 60/500 [10:37<1:16:54, 10.49s/it] 12%|█▏        | 60/500 [10:37<1:17:55, 10.63s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.317 MB uploadedwandb: / 0.020 MB of 0.317 MB uploadedwandb: - 0.280 MB of 0.317 MB uploadedwandb: \ 0.280 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▆▅▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▁▁▁▁▁▂▁▁▃▁▅▃▁▁▁▁▁▃▁▁▆▃▁▇▁▇█▁▁▆▂▅▁▂▁▄█▁▁
wandb:     train_loss ▂▂▂▂▃▂▁▃▃▃▄▁▂▂▄▁▅█▃▁▇▁▁▆▁█▃▁▂▁▁▃▁▁▃▁▂▁▁▄
wandb:   val_accuracy ▆▆▄▄▅▄▄▆▆▅▅▁▂▄▆▄▆▅▄▆▆▁▂▆▃▆▃▇▅▆█▄▂▅▅▅▁▆▅▅
wandb:       val_loss ▂▂▂▂▂▃▃▃▃▂▆▂▂▂▃▃▆▆▄▁▁▆▃▁▅█▃▂▄▁▁▃▃▆▃▂▄▃▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 59
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.33581
wandb:     train_loss 3.98471
wandb:   val_accuracy 0.32222
wandb:       val_loss 2.36114
wandb: 
wandb: 🚀 View run different-snowball-2652 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lvlxmnfb
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_100529-lvlxmnfb/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_101646-h65v292d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-snowball-2653
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h65v292d
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:13<1:53:57, 13.70s/it]  0%|          | 2/500 [00:25<1:43:31, 12.47s/it]  1%|          | 3/500 [00:36<1:39:57, 12.07s/it]  1%|          | 4/500 [00:47<1:36:31, 11.68s/it]  1%|          | 5/500 [00:59<1:34:30, 11.46s/it]  1%|          | 6/500 [01:09<1:32:32, 11.24s/it]  1%|▏         | 7/500 [01:20<1:31:25, 11.13s/it]  2%|▏         | 8/500 [01:31<1:30:37, 11.05s/it]  2%|▏         | 9/500 [01:42<1:29:52, 10.98s/it]  2%|▏         | 10/500 [01:53<1:29:28, 10.96s/it]  2%|▏         | 11/500 [02:03<1:27:51, 10.78s/it]  2%|▏         | 12/500 [02:14<1:26:46, 10.67s/it]  3%|▎         | 13/500 [02:24<1:25:27, 10.53s/it]  3%|▎         | 14/500 [02:34<1:24:40, 10.45s/it]  3%|▎         | 15/500 [02:45<1:24:19, 10.43s/it]  3%|▎         | 16/500 [02:55<1:23:54, 10.40s/it]  3%|▎         | 17/500 [03:05<1:23:34, 10.38s/it]  4%|▎         | 18/500 [03:16<1:23:16, 10.37s/it]  4%|▍         | 19/500 [03:26<1:23:34, 10.43s/it]  4%|▍         | 20/500 [03:36<1:22:50, 10.36s/it]  4%|▍         | 21/500 [03:47<1:22:27, 10.33s/it]  4%|▍         | 22/500 [03:57<1:23:43, 10.51s/it]  5%|▍         | 23/500 [04:09<1:26:26, 10.87s/it]  5%|▍         | 24/500 [04:20<1:27:06, 10.98s/it]  5%|▌         | 25/500 [04:31<1:26:46, 10.96s/it]  5%|▌         | 26/500 [04:42<1:26:38, 10.97s/it]  5%|▌         | 27/500 [04:53<1:26:02, 10.92s/it]  6%|▌         | 28/500 [05:04<1:25:26, 10.86s/it]  6%|▌         | 29/500 [05:14<1:23:47, 10.67s/it]  6%|▌         | 30/500 [05:24<1:22:46, 10.57s/it]  6%|▌         | 31/500 [05:35<1:22:02, 10.50s/it]  6%|▋         | 32/500 [05:45<1:21:21, 10.43s/it]  7%|▋         | 33/500 [05:56<1:21:40, 10.49s/it]  7%|▋         | 34/500 [06:06<1:21:05, 10.44s/it]  7%|▋         | 35/500 [06:16<1:20:33, 10.39s/it]  7%|▋         | 36/500 [06:27<1:20:14, 10.38s/it]  7%|▋         | 37/500 [06:37<1:19:53, 10.35s/it]  8%|▊         | 38/500 [06:47<1:19:55, 10.38s/it]  8%|▊         | 39/500 [06:58<1:19:25, 10.34s/it]  8%|▊         | 40/500 [07:08<1:19:06, 10.32s/it]  8%|▊         | 41/500 [07:18<1:19:21, 10.37s/it]  8%|▊         | 42/500 [07:29<1:20:00, 10.48s/it]  9%|▊         | 43/500 [07:40<1:20:57, 10.63s/it]  9%|▉         | 44/500 [07:51<1:20:38, 10.61s/it]  9%|▉         | 45/500 [08:01<1:20:06, 10.56s/it]  9%|▉         | 46/500 [08:11<1:19:21, 10.49s/it]  9%|▉         | 47/500 [08:22<1:18:58, 10.46s/it] 10%|▉         | 48/500 [08:32<1:18:33, 10.43s/it] 10%|▉         | 49/500 [08:42<1:18:07, 10.39s/it] 10%|█         | 50/500 [08:53<1:17:48, 10.37s/it] 10%|█         | 51/500 [09:03<1:17:28, 10.35s/it] 10%|█         | 52/500 [09:13<1:17:04, 10.32s/it] 11%|█         | 53/500 [09:24<1:16:46, 10.31s/it] 11%|█         | 54/500 [09:34<1:16:34, 10.30s/it] 11%|█         | 55/500 [09:44<1:16:40, 10.34s/it] 11%|█         | 56/500 [09:55<1:16:36, 10.35s/it] 11%|█▏        | 57/500 [10:05<1:16:54, 10.42s/it] 12%|█▏        | 58/500 [10:16<1:16:45, 10.42s/it] 12%|█▏        | 59/500 [10:26<1:16:10, 10.36s/it] 12%|█▏        | 60/500 [10:36<1:16:06, 10.38s/it] 12%|█▏        | 60/500 [10:36<1:17:50, 10.62s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.233 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▆▅▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▂▅▁▇▃▁▃▁▇▄▇▂▁▂▃▅▁▆▄▆▃▅▆▇▇▇▆▅▅▅██▆▇▇▆█▅▅
wandb:     train_loss ▂▂▂▁▁▂█▂▄▁▁▁▄▃▂▁▃▁▂▁▁▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▄▁▁▂
wandb:   val_accuracy ▅▂▃▆▆▂▆▆▆▆▁▅▆▆▆▆█▆▅▆█▆▇█▆█▆▇▃▇▇▇▇█▆█▇▇▇▇
wandb:       val_loss ▂▂▂▅▁▆▅▅▃▃█▁▃▅▁▃▃▄▇▃▄█▄▁▆▄▂▂▂▁▂▁▁▇▃▆▇▃▃▆
wandb: 
wandb: Run summary:
wandb:          epoch 59
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.68796
wandb:     train_loss 1.94106
wandb:   val_accuracy 0.40222
wandb:       val_loss 7.04874
wandb: 
wandb: 🚀 View run lyric-snowball-2653 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/h65v292d
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_101646-h65v292d/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_102804-t8do9w0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-silence-2654
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t8do9w0t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<2:04:02, 14.91s/it]  0%|          | 2/500 [00:26<1:49:17, 13.17s/it]  1%|          | 3/500 [00:38<1:41:36, 12.27s/it]  1%|          | 4/500 [00:49<1:37:29, 11.79s/it]  1%|          | 5/500 [01:00<1:34:52, 11.50s/it]  1%|          | 6/500 [01:10<1:32:49, 11.27s/it]  1%|▏         | 7/500 [01:21<1:31:39, 11.16s/it]  2%|▏         | 8/500 [01:32<1:30:50, 11.08s/it]  2%|▏         | 9/500 [01:43<1:30:32, 11.06s/it]  2%|▏         | 10/500 [01:55<1:31:48, 11.24s/it]  2%|▏         | 11/500 [02:06<1:32:10, 11.31s/it]  2%|▏         | 12/500 [02:18<1:32:46, 11.41s/it]  3%|▎         | 13/500 [02:29<1:32:34, 11.40s/it]  3%|▎         | 14/500 [02:40<1:31:21, 11.28s/it]  3%|▎         | 15/500 [02:51<1:30:24, 11.19s/it]  3%|▎         | 16/500 [03:02<1:29:40, 11.12s/it]  3%|▎         | 17/500 [03:14<1:29:37, 11.13s/it]  4%|▎         | 18/500 [03:25<1:29:06, 11.09s/it]  4%|▍         | 19/500 [03:36<1:28:56, 11.10s/it]  4%|▍         | 20/500 [03:47<1:28:38, 11.08s/it]  4%|▍         | 21/500 [03:58<1:28:40, 11.11s/it]  4%|▍         | 22/500 [04:09<1:29:02, 11.18s/it]  5%|▍         | 23/500 [04:20<1:28:22, 11.12s/it]  5%|▍         | 24/500 [04:31<1:27:59, 11.09s/it]  5%|▌         | 25/500 [04:41<1:25:58, 10.86s/it]  5%|▌         | 26/500 [04:52<1:24:26, 10.69s/it]  5%|▌         | 27/500 [05:02<1:23:56, 10.65s/it]  6%|▌         | 28/500 [05:13<1:24:15, 10.71s/it]  6%|▌         | 29/500 [05:24<1:24:07, 10.72s/it]  6%|▌         | 30/500 [05:35<1:24:21, 10.77s/it]  6%|▌         | 31/500 [05:45<1:23:03, 10.63s/it]  6%|▋         | 32/500 [05:55<1:21:56, 10.51s/it]  7%|▋         | 33/500 [06:06<1:21:00, 10.41s/it]  7%|▋         | 34/500 [06:17<1:22:21, 10.60s/it]  7%|▋         | 35/500 [06:27<1:21:35, 10.53s/it]  7%|▋         | 36/500 [06:37<1:20:35, 10.42s/it]  7%|▋         | 37/500 [06:47<1:20:14, 10.40s/it]  8%|▊         | 38/500 [06:58<1:19:53, 10.38s/it]  8%|▊         | 39/500 [07:09<1:20:43, 10.51s/it]  8%|▊         | 40/500 [07:19<1:21:29, 10.63s/it]  8%|▊         | 41/500 [07:31<1:22:23, 10.77s/it]  8%|▊         | 42/500 [07:42<1:23:40, 10.96s/it]  9%|▊         | 43/500 [07:53<1:23:53, 11.01s/it]  9%|▉         | 44/500 [08:04<1:24:13, 11.08s/it]  9%|▉         | 45/500 [08:15<1:23:50, 11.06s/it]  9%|▉         | 46/500 [08:26<1:23:45, 11.07s/it]  9%|▉         | 47/500 [08:37<1:23:22, 11.04s/it] 10%|▉         | 48/500 [08:48<1:22:58, 11.01s/it] 10%|▉         | 49/500 [09:00<1:23:04, 11.05s/it] 10%|█         | 50/500 [09:11<1:22:46, 11.04s/it] 10%|█         | 51/500 [09:22<1:22:39, 11.05s/it] 10%|█         | 52/500 [09:33<1:22:12, 11.01s/it] 11%|█         | 53/500 [09:43<1:21:45, 10.97s/it] 11%|█         | 54/500 [09:54<1:21:44, 11.00s/it] 11%|█         | 55/500 [10:05<1:21:20, 10.97s/it] 11%|█         | 56/500 [10:16<1:21:12, 10.97s/it] 11%|█▏        | 57/500 [10:27<1:21:00, 10.97s/it] 12%|█▏        | 58/500 [10:38<1:20:37, 10.94s/it] 12%|█▏        | 59/500 [10:49<1:20:48, 11.00s/it] 12%|█▏        | 60/500 [11:00<1:19:10, 10.80s/it] 12%|█▏        | 60/500 [11:00<1:20:41, 11.00s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.312 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.233 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▆▅▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▂▁▁▃▁▁▃▃▄▃▂▁▃▆▁█▁██▂▂▂▄▆▃█▁█▃███▇█▆▆▇▇█
wandb:     train_loss ▂▂▅▁▃▄█▃▁▂▃▁▄▁▂▄▁▁▁▁▃▁▄▅▄▁▁▄▄▁▁▁▁▁▁▁▃▁▁▁
wandb:   val_accuracy ▅▄▅▆▁▅▆▆▃▇▂▆▅▇█▆▇▅▇▆▆▅▅▇█▂▇▅▅▅▄▆▄▂▆▇▇█▃▃
wandb:       val_loss ▁▁▄▄▂▄▄▅▃▃▇▂▃▅▁▄▂▃█▄▄█▄▁▆▃▁▂▂▁▁▂▂▆▂▄▅▃▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 59
wandb:  learning_rate 0.00026
wandb: train_accuracy 0.94651
wandb:     train_loss 0.31853
wandb:   val_accuracy 0.20444
wandb:       val_loss 8.21826
wandb: 
wandb: 🚀 View run smooth-silence-2654 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t8do9w0t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_102804-t8do9w0t/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_103944-195lip0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-wood-2655
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/195lip0s
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:15<2:11:09, 15.77s/it]  0%|          | 2/500 [00:27<1:50:46, 13.35s/it]  1%|          | 3/500 [00:38<1:42:54, 12.42s/it]  1%|          | 4/500 [00:49<1:38:09, 11.87s/it]  1%|          | 5/500 [01:01<1:36:27, 11.69s/it]  1%|          | 6/500 [01:12<1:33:56, 11.41s/it]  1%|▏         | 7/500 [01:22<1:32:20, 11.24s/it]  2%|▏         | 8/500 [01:33<1:31:22, 11.14s/it]  2%|▏         | 9/500 [01:44<1:30:45, 11.09s/it]  2%|▏         | 10/500 [01:55<1:30:05, 11.03s/it]  2%|▏         | 11/500 [02:06<1:28:35, 10.87s/it]  2%|▏         | 12/500 [02:16<1:27:18, 10.74s/it]  3%|▎         | 13/500 [02:27<1:26:15, 10.63s/it]  3%|▎         | 14/500 [02:37<1:26:19, 10.66s/it]  3%|▎         | 15/500 [02:48<1:25:58, 10.64s/it]  3%|▎         | 16/500 [02:59<1:26:12, 10.69s/it]  3%|▎         | 17/500 [03:09<1:25:33, 10.63s/it]  4%|▎         | 18/500 [03:20<1:26:12, 10.73s/it]  4%|▍         | 19/500 [03:31<1:26:16, 10.76s/it]  4%|▍         | 20/500 [03:42<1:26:23, 10.80s/it]  4%|▍         | 21/500 [03:52<1:25:13, 10.68s/it]  4%|▍         | 22/500 [04:03<1:24:46, 10.64s/it]  5%|▍         | 23/500 [04:13<1:24:26, 10.62s/it]  5%|▍         | 24/500 [04:24<1:23:56, 10.58s/it]  5%|▌         | 25/500 [04:35<1:24:39, 10.69s/it]  5%|▌         | 26/500 [04:46<1:25:41, 10.85s/it]  5%|▌         | 27/500 [04:57<1:25:02, 10.79s/it]  5%|▌         | 27/500 [04:57<1:26:45, 11.01s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.314 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.137 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▁▂▂▄▃▄▅▁▁▇▂▃▁▁▁▁█▄▁▁▄▁▅▄
wandb:     train_loss ▂▃▃▃▃▃▃▂▂▂▁▃▂▂▃▁▁█▅▂▃▆▅▄█▃▁
wandb:   val_accuracy ███▇▇▇▇▃▃▆▇▇▂▃▇█▇█▇▇▇██▁█▁▂
wandb:       val_loss ▂▂▂▂▂▂▂▃▃▂▁▂▂▂▃▁▃▆▂▂▂▃▄▂█▃▂
wandb: 
wandb: Run summary:
wandb:          epoch 26
wandb:  learning_rate 6e-05
wandb: train_accuracy 0.48588
wandb:     train_loss 0.23412
wandb:   val_accuracy 0.17333
wandb:       val_loss 0.95103
wandb: 
wandb: 🚀 View run toasty-wood-2655 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/195lip0s
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_103944-195lip0s/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_104524-17hsmfp3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-shadow-2656
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/17hsmfp3
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:14<2:03:52, 14.90s/it]  0%|          | 2/500 [00:26<1:46:53, 12.88s/it]  1%|          | 3/500 [00:37<1:40:52, 12.18s/it]  1%|          | 4/500 [00:48<1:36:00, 11.61s/it]  1%|          | 5/500 [00:58<1:31:50, 11.13s/it]  1%|          | 6/500 [01:08<1:28:16, 10.72s/it]  1%|▏         | 7/500 [01:18<1:26:36, 10.54s/it]  2%|▏         | 8/500 [01:29<1:25:45, 10.46s/it]  2%|▏         | 9/500 [01:39<1:26:07, 10.52s/it]  2%|▏         | 10/500 [01:50<1:26:47, 10.63s/it]  2%|▏         | 11/500 [02:01<1:26:30, 10.62s/it]  2%|▏         | 12/500 [02:11<1:26:19, 10.61s/it]  3%|▎         | 13/500 [02:22<1:25:52, 10.58s/it]  3%|▎         | 14/500 [02:32<1:25:04, 10.50s/it]  3%|▎         | 15/500 [02:42<1:24:16, 10.43s/it]  3%|▎         | 16/500 [02:53<1:23:43, 10.38s/it]  3%|▎         | 17/500 [03:03<1:22:33, 10.26s/it]  4%|▎         | 18/500 [03:13<1:21:36, 10.16s/it]  4%|▍         | 19/500 [03:22<1:20:32, 10.05s/it]  4%|▍         | 20/500 [03:32<1:19:46,  9.97s/it]  4%|▍         | 21/500 [03:42<1:18:57,  9.89s/it]  4%|▍         | 22/500 [03:52<1:18:31,  9.86s/it]  5%|▍         | 23/500 [04:02<1:19:01,  9.94s/it]  5%|▍         | 24/500 [04:12<1:18:28,  9.89s/it]  5%|▌         | 25/500 [04:21<1:17:53,  9.84s/it]  5%|▌         | 26/500 [04:32<1:18:55,  9.99s/it]  5%|▌         | 27/500 [04:42<1:19:55, 10.14s/it]  6%|▌         | 28/500 [04:52<1:19:47, 10.14s/it]  6%|▌         | 29/500 [05:02<1:19:13, 10.09s/it]  6%|▌         | 29/500 [05:02<1:21:56, 10.44s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▅▅▄▂▃▃█▃▃▁▆▄█▆▆▇▇█▇▇█████▆█▅▄
wandb:     train_loss ▃▃▃▃▃▄▂▄▃▄▂▃▂▂▃▅▆▁▃▂▁▁▁▆▁▅▁▄█
wandb:   val_accuracy ▆▆▆█▇▆▃▅▆▃▁▂▆▃▃▂▃▄▂▃▄▃▄▄▅▂▄▁▃
wandb:       val_loss ▂▂▂▂▃▂▂▁▃▂▃▃▁▃▃█▁▂▂▂▅▄▄▃▂▅▂▅▅
wandb: 
wandb: Run summary:
wandb:          epoch 28
wandb:  learning_rate 0.00032
wandb: train_accuracy 0.28232
wandb:     train_loss 3.83901
wandb:   val_accuracy 0.18444
wandb:       val_loss 2.54481
wandb: 
wandb: 🚀 View run peachy-shadow-2656 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/17hsmfp3
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_104524-17hsmfp3/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_105105-cpi5dgfr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-hill-2657
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cpi5dgfr
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:27<3:52:51, 28.00s/it]  0%|          | 2/500 [00:42<2:48:14, 20.27s/it]  1%|          | 3/500 [01:07<3:03:01, 22.10s/it]  1%|          | 4/500 [01:22<2:39:39, 19.31s/it]  1%|          | 5/500 [01:41<2:39:13, 19.30s/it]  1%|          | 6/500 [02:01<2:40:00, 19.43s/it]  1%|▏         | 7/500 [02:15<2:27:11, 17.91s/it]  2%|▏         | 8/500 [02:35<2:31:07, 18.43s/it]  2%|▏         | 9/500 [02:50<2:21:58, 17.35s/it]  2%|▏         | 10/500 [03:05<2:14:49, 16.51s/it]  2%|▏         | 11/500 [03:19<2:09:42, 15.91s/it]  2%|▏         | 12/500 [03:34<2:06:23, 15.54s/it]  3%|▎         | 13/500 [03:49<2:04:15, 15.31s/it]  3%|▎         | 14/500 [04:03<2:02:39, 15.14s/it]  3%|▎         | 15/500 [04:19<2:04:09, 15.36s/it]  3%|▎         | 16/500 [04:34<2:03:28, 15.31s/it]  3%|▎         | 17/500 [04:49<2:01:34, 15.10s/it]  4%|▎         | 18/500 [05:03<1:59:45, 14.91s/it]  4%|▍         | 19/500 [05:18<1:58:34, 14.79s/it]  4%|▍         | 20/500 [05:33<1:57:38, 14.71s/it]  4%|▍         | 21/500 [05:48<1:58:37, 14.86s/it]  4%|▍         | 22/500 [06:03<1:59:54, 15.05s/it]  5%|▍         | 23/500 [06:18<1:58:28, 14.90s/it]  5%|▍         | 24/500 [06:32<1:57:05, 14.76s/it]  5%|▌         | 25/500 [06:47<1:55:51, 14.64s/it]  5%|▌         | 26/500 [07:01<1:55:35, 14.63s/it]  5%|▌         | 27/500 [07:16<1:55:20, 14.63s/it]  6%|▌         | 28/500 [07:30<1:54:47, 14.59s/it]  6%|▌         | 29/500 [07:45<1:53:57, 14.52s/it]  6%|▌         | 30/500 [07:59<1:53:41, 14.51s/it]  6%|▌         | 31/500 [08:14<1:53:13, 14.48s/it]  6%|▋         | 32/500 [08:28<1:52:53, 14.47s/it]  7%|▋         | 33/500 [08:43<1:53:47, 14.62s/it]  7%|▋         | 33/500 [08:43<2:03:28, 15.86s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.308 MB uploadedwandb: | 0.010 MB of 0.308 MB uploadedwandb: / 0.133 MB of 0.308 MB uploadedwandb: - 0.303 MB of 0.308 MB uploadedwandb: \ 0.303 MB of 0.308 MB uploadedwandb: | 0.303 MB of 0.308 MB uploadedwandb: / 0.303 MB of 0.308 MB uploadedwandb: - 0.308 MB of 0.308 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb: train_accuracy ▁▁▂▃▆▇▃▆▄▄▆▇▆█▇▆▇▇███████▆███████
wandb:     train_loss ▃▂▃▃▂▅▁▂▁▁▁▁▄▁▁▁▂█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▅▇▆▇█▁█▁▇█▇█▇▅▃▇██▇▆▇▇▅▇█▆▇▇▆▆▆▆
wandb:       val_loss ▂▂▂▂▂▃▄▁█▄▂▃▂▇▃▂▁▄▁▄▄▂▆▄▁▁▄▄▅▃▄▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 32
wandb:  learning_rate 0.00051
wandb: train_accuracy 1.0
wandb:     train_loss 0.00928
wandb:   val_accuracy 0.41111
wandb:       val_loss 4.61907
wandb: 
wandb: 🚀 View run treasured-hill-2657 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/cpi5dgfr
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_105105-cpi5dgfr/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_110029-23sq0x9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-wood-2658
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/23sq0x9i
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:29:49, 18.02s/it]  0%|          | 2/500 [00:33<2:16:18, 16.42s/it]  1%|          | 3/500 [00:49<2:13:13, 16.08s/it]  1%|          | 4/500 [01:04<2:10:19, 15.76s/it]  1%|          | 5/500 [01:20<2:10:05, 15.77s/it]  1%|          | 6/500 [01:35<2:08:29, 15.61s/it]  1%|▏         | 7/500 [01:50<2:06:13, 15.36s/it]  2%|▏         | 8/500 [02:05<2:04:46, 15.22s/it]  2%|▏         | 9/500 [02:20<2:03:52, 15.14s/it]  2%|▏         | 10/500 [02:34<2:02:49, 15.04s/it]  2%|▏         | 11/500 [02:49<2:02:30, 15.03s/it]  2%|▏         | 12/500 [03:04<2:01:41, 14.96s/it]  3%|▎         | 13/500 [03:19<2:01:48, 15.01s/it]  3%|▎         | 14/500 [03:34<2:01:44, 15.03s/it]  3%|▎         | 15/500 [03:50<2:01:43, 15.06s/it]  3%|▎         | 16/500 [04:04<2:00:35, 14.95s/it]  3%|▎         | 17/500 [04:19<1:59:46, 14.88s/it]  4%|▎         | 18/500 [04:34<1:59:35, 14.89s/it]  4%|▍         | 19/500 [04:49<1:59:04, 14.85s/it]  4%|▍         | 20/500 [05:03<1:58:32, 14.82s/it]  4%|▍         | 21/500 [05:18<1:58:06, 14.79s/it]  4%|▍         | 22/500 [05:33<1:57:42, 14.78s/it]  5%|▍         | 23/500 [05:48<1:57:43, 14.81s/it]  5%|▍         | 24/500 [06:05<2:02:47, 15.48s/it]  5%|▌         | 25/500 [06:19<2:00:25, 15.21s/it]  5%|▌         | 26/500 [06:34<1:59:28, 15.12s/it]  5%|▌         | 27/500 [06:49<1:58:00, 14.97s/it]  6%|▌         | 28/500 [07:04<1:57:07, 14.89s/it]  6%|▌         | 29/500 [07:18<1:56:26, 14.83s/it]  6%|▌         | 30/500 [07:33<1:55:45, 14.78s/it]  6%|▌         | 31/500 [07:48<1:55:50, 14.82s/it]  6%|▋         | 32/500 [08:03<1:55:19, 14.79s/it]  7%|▋         | 33/500 [08:17<1:54:56, 14.77s/it]  7%|▋         | 34/500 [08:32<1:55:27, 14.87s/it]  7%|▋         | 34/500 [08:32<1:57:09, 15.08s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.138 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▂▅▁▂▁▆▂▃▁▃▇▃▄▁▁▄▁▁▂▁▄▄▄▁▇▄█▄▂▆▁▁█
wandb:     train_loss ▂▂▂▁▂▁▂▂▂▄▂▂▂▂▇▁▂▁▅▃▁▂▂▂▄▂▂▁▁▃▃█▃▂
wandb:   val_accuracy ▂▁▂▁▁▁▁▂▁▁▁▃▁▂▁▁▂▁▁▁▁▁▁▂▁▅▁▅▄▁▄▁▁█
wandb:       val_loss ▁▁▁▂▁▁▁▁▁▃▁▁▁▂▂▂▂▁▃▂█▁▂▂▃▁▁▂▁▂▁▆▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 33
wandb:  learning_rate 5e-05
wandb: train_accuracy 0.71471
wandb:     train_loss 1.74852
wandb:   val_accuracy 0.48
wandb:       val_loss 0.86754
wandb: 
wandb: 🚀 View run olive-wood-2658 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/23sq0x9i
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_110029-23sq0x9i/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_110943-wy6093s7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-silence-2659
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wy6093s7
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:23:02, 17.20s/it]  0%|          | 2/500 [00:31<2:10:36, 15.74s/it]  1%|          | 3/500 [00:46<2:06:17, 15.25s/it]  1%|          | 4/500 [01:00<2:03:06, 14.89s/it]  1%|          | 5/500 [01:15<2:01:13, 14.69s/it]  1%|          | 6/500 [01:29<2:00:03, 14.58s/it]  1%|▏         | 7/500 [01:43<1:58:53, 14.47s/it]  2%|▏         | 8/500 [01:58<1:58:27, 14.45s/it]  2%|▏         | 9/500 [02:12<1:58:25, 14.47s/it]  2%|▏         | 10/500 [02:27<1:58:07, 14.46s/it]  2%|▏         | 11/500 [02:42<1:59:31, 14.66s/it]  2%|▏         | 12/500 [02:56<1:58:27, 14.57s/it]  3%|▎         | 13/500 [03:10<1:56:51, 14.40s/it]  3%|▎         | 14/500 [03:25<1:56:50, 14.43s/it]  3%|▎         | 15/500 [03:39<1:57:29, 14.54s/it]  3%|▎         | 16/500 [03:54<1:57:02, 14.51s/it]  3%|▎         | 17/500 [04:08<1:55:22, 14.33s/it]  4%|▎         | 18/500 [04:22<1:54:36, 14.27s/it]  4%|▍         | 19/500 [04:36<1:54:11, 14.24s/it]  4%|▍         | 20/500 [04:50<1:53:43, 14.22s/it]  4%|▍         | 21/500 [05:04<1:53:04, 14.16s/it]  4%|▍         | 22/500 [05:19<1:52:52, 14.17s/it]  5%|▍         | 23/500 [05:33<1:53:26, 14.27s/it]  5%|▍         | 24/500 [05:48<1:53:40, 14.33s/it]  5%|▌         | 25/500 [06:02<1:53:13, 14.30s/it]  5%|▌         | 25/500 [06:02<1:54:42, 14.49s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.010 MB of 0.312 MB uploadedwandb: - 0.231 MB of 0.312 MB uploadedwandb: \ 0.231 MB of 0.312 MB uploadedwandb: | 0.231 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁
wandb: train_accuracy ▁▁▅▅▆▄▆▁▁▃▅▅▆▇▇▇▆▇▇██▇██▆
wandb:     train_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▅▂▁▂▁▁▅█▆▅▅▆▅▅▅▄▅▃▆▇▄▆▇▄
wandb:       val_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 24
wandb:  learning_rate 0.00032
wandb: train_accuracy 0.789
wandb:     train_loss 1.07763
wandb:   val_accuracy 0.29333
wandb:       val_loss 1.92059
wandb: 
wandb: 🚀 View run zesty-silence-2659 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wy6093s7
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_110943-wy6093s7/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_111626-x5m2fs18
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-totem-2660
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x5m2fs18
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:19:19, 16.75s/it]  0%|          | 2/500 [00:31<2:10:27, 15.72s/it]  1%|          | 3/500 [00:46<2:07:53, 15.44s/it]  1%|          | 4/500 [01:01<2:05:59, 15.24s/it]  1%|          | 5/500 [01:16<2:04:25, 15.08s/it]  1%|          | 6/500 [01:31<2:03:20, 14.98s/it]  1%|▏         | 7/500 [01:46<2:02:58, 14.97s/it]  2%|▏         | 8/500 [02:01<2:02:39, 14.96s/it]  2%|▏         | 9/500 [02:15<2:01:45, 14.88s/it]  2%|▏         | 10/500 [02:30<2:01:16, 14.85s/it]  2%|▏         | 11/500 [02:45<2:01:03, 14.85s/it]  2%|▏         | 12/500 [03:01<2:03:32, 15.19s/it]  3%|▎         | 13/500 [03:16<2:02:33, 15.10s/it]  3%|▎         | 14/500 [03:31<2:01:22, 14.98s/it]  3%|▎         | 15/500 [03:46<2:00:57, 14.96s/it]  3%|▎         | 16/500 [04:01<2:02:18, 15.16s/it]  3%|▎         | 17/500 [04:17<2:03:20, 15.32s/it]  4%|▎         | 18/500 [04:32<2:02:16, 15.22s/it]  4%|▍         | 19/500 [04:47<2:01:02, 15.10s/it]  4%|▍         | 20/500 [05:02<2:00:45, 15.09s/it]  4%|▍         | 21/500 [05:17<2:01:08, 15.17s/it]  4%|▍         | 22/500 [05:32<2:00:47, 15.16s/it]  5%|▍         | 23/500 [05:47<1:59:12, 14.99s/it]  5%|▍         | 24/500 [06:02<1:58:06, 14.89s/it]  5%|▌         | 25/500 [06:16<1:57:07, 14.79s/it]  5%|▌         | 26/500 [06:31<1:56:43, 14.78s/it]  5%|▌         | 27/500 [06:46<1:56:17, 14.75s/it]  6%|▌         | 28/500 [07:00<1:55:46, 14.72s/it]  6%|▌         | 29/500 [07:15<1:56:05, 14.79s/it]  6%|▌         | 30/500 [07:30<1:56:07, 14.82s/it]  6%|▌         | 31/500 [07:45<1:55:57, 14.83s/it]  6%|▋         | 32/500 [08:00<1:56:02, 14.88s/it]  7%|▋         | 33/500 [08:14<1:55:07, 14.79s/it]  7%|▋         | 33/500 [08:14<1:56:44, 15.00s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.021 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb: train_accuracy ▁▃▃▄▅▂▃▆▃▇▇▇▆▇▆▇██▇▇▇▆▇▇█▇███▇██▇
wandb:     train_loss ▆▇▆▃▁▃▁█▁▁▃▆▆▂▃▁▁▇▁▁▁▁▁▃▂▁▁▁▁▁▁▂▃
wandb:   val_accuracy ▅▄▁▂▃▁▂▇▂▆▆▇▆▆▆▆▇▇█▆█▆█▆██▇█▇▆▇▇▆
wandb:       val_loss ▂▂▂▂▂▂▃▁▆▄▂▄▂▇▄▄▁▄▂▅▃▆█▇▂▁▄▄▇▃▆▂▃
wandb: 
wandb: Run summary:
wandb:          epoch 32
wandb:  learning_rate 0.00051
wandb: train_accuracy 0.89747
wandb:     train_loss 0.29835
wandb:   val_accuracy 0.43111
wandb:       val_loss 3.35422
wandb: 
wandb: 🚀 View run eager-totem-2660 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/x5m2fs18
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_111626-x5m2fs18/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_112523-jdkopsup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-haze-2661
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jdkopsup
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:25:13, 17.46s/it]  0%|          | 2/500 [00:33<2:17:37, 16.58s/it]  1%|          | 3/500 [00:49<2:15:15, 16.33s/it]  1%|          | 4/500 [01:04<2:11:12, 15.87s/it]  1%|          | 5/500 [01:19<2:08:06, 15.53s/it]  1%|          | 6/500 [01:34<2:05:45, 15.27s/it]  1%|▏         | 7/500 [01:49<2:04:44, 15.18s/it]  2%|▏         | 8/500 [02:03<2:02:51, 14.98s/it]  2%|▏         | 9/500 [02:18<2:01:45, 14.88s/it]  2%|▏         | 10/500 [02:33<2:00:56, 14.81s/it]  2%|▏         | 11/500 [02:48<2:00:45, 14.82s/it]  2%|▏         | 12/500 [03:02<2:00:31, 14.82s/it]  3%|▎         | 13/500 [03:19<2:05:46, 15.50s/it]  3%|▎         | 14/500 [03:34<2:03:16, 15.22s/it]  3%|▎         | 15/500 [03:49<2:01:27, 15.03s/it]  3%|▎         | 16/500 [04:03<2:00:04, 14.88s/it]  3%|▎         | 17/500 [04:18<1:59:42, 14.87s/it]  4%|▎         | 18/500 [04:33<1:58:53, 14.80s/it]  4%|▍         | 19/500 [04:47<1:58:13, 14.75s/it]  4%|▍         | 20/500 [05:05<2:05:30, 15.69s/it]  4%|▍         | 21/500 [05:20<2:03:32, 15.47s/it]  4%|▍         | 22/500 [05:35<2:01:10, 15.21s/it]  5%|▍         | 23/500 [05:49<1:59:19, 15.01s/it]  5%|▍         | 24/500 [06:04<1:58:16, 14.91s/it]  5%|▌         | 25/500 [06:19<1:58:25, 14.96s/it]  5%|▌         | 26/500 [06:36<2:03:13, 15.60s/it]  5%|▌         | 27/500 [06:51<2:00:30, 15.29s/it]  6%|▌         | 28/500 [07:05<1:58:37, 15.08s/it]  6%|▌         | 29/500 [07:20<1:57:29, 14.97s/it]  6%|▌         | 30/500 [07:35<1:57:07, 14.95s/it]  6%|▌         | 31/500 [07:49<1:55:55, 14.83s/it]  6%|▋         | 32/500 [08:04<1:55:27, 14.80s/it]  7%|▋         | 33/500 [08:21<2:01:08, 15.56s/it]  7%|▋         | 34/500 [08:41<2:09:57, 16.73s/it]  7%|▋         | 35/500 [09:00<2:15:16, 17.45s/it]  7%|▋         | 36/500 [09:15<2:08:10, 16.57s/it]  7%|▋         | 37/500 [09:29<2:03:27, 16.00s/it]  8%|▊         | 38/500 [09:44<1:59:57, 15.58s/it]  8%|▊         | 39/500 [09:59<1:57:52, 15.34s/it]  8%|▊         | 40/500 [10:13<1:55:50, 15.11s/it]  8%|▊         | 41/500 [10:28<1:54:37, 14.98s/it]  8%|▊         | 42/500 [10:43<1:53:44, 14.90s/it]  9%|▊         | 43/500 [10:57<1:53:16, 14.87s/it]  9%|▉         | 44/500 [11:12<1:52:31, 14.81s/it]  9%|▉         | 45/500 [11:27<1:52:19, 14.81s/it]  9%|▉         | 46/500 [11:41<1:51:33, 14.74s/it]  9%|▉         | 47/500 [11:56<1:50:49, 14.68s/it] 10%|▉         | 48/500 [12:13<1:56:06, 15.41s/it] 10%|▉         | 49/500 [12:28<1:54:08, 15.19s/it] 10%|█         | 50/500 [12:43<1:53:07, 15.08s/it] 10%|█         | 51/500 [12:57<1:51:58, 14.96s/it] 10%|█         | 52/500 [13:12<1:51:16, 14.90s/it] 11%|█         | 53/500 [13:27<1:50:26, 14.82s/it] 11%|█         | 54/500 [13:42<1:50:22, 14.85s/it] 11%|█         | 55/500 [13:57<1:50:45, 14.93s/it] 11%|█         | 56/500 [14:12<1:50:24, 14.92s/it] 11%|█▏        | 57/500 [14:26<1:49:43, 14.86s/it] 12%|█▏        | 58/500 [14:41<1:49:15, 14.83s/it] 12%|█▏        | 59/500 [14:56<1:48:32, 14.77s/it] 12%|█▏        | 60/500 [15:10<1:48:20, 14.77s/it] 12%|█▏        | 61/500 [15:26<1:48:43, 14.86s/it] 12%|█▏        | 62/500 [15:40<1:47:52, 14.78s/it] 13%|█▎        | 63/500 [15:55<1:47:09, 14.71s/it] 13%|█▎        | 64/500 [16:10<1:47:45, 14.83s/it] 13%|█▎        | 65/500 [16:25<1:48:51, 15.01s/it] 13%|█▎        | 66/500 [16:40<1:48:06, 14.94s/it] 13%|█▎        | 67/500 [16:55<1:47:29, 14.90s/it] 14%|█▎        | 68/500 [17:10<1:47:28, 14.93s/it] 14%|█▍        | 69/500 [17:24<1:46:21, 14.81s/it] 14%|█▍        | 70/500 [17:39<1:46:06, 14.81s/it] 14%|█▍        | 71/500 [17:54<1:45:27, 14.75s/it] 14%|█▍        | 72/500 [18:09<1:45:15, 14.76s/it] 15%|█▍        | 73/500 [18:23<1:45:24, 14.81s/it] 15%|█▍        | 74/500 [18:38<1:45:01, 14.79s/it] 15%|█▌        | 75/500 [18:53<1:44:20, 14.73s/it] 15%|█▌        | 76/500 [19:07<1:43:44, 14.68s/it] 15%|█▌        | 77/500 [19:22<1:44:03, 14.76s/it] 16%|█▌        | 78/500 [19:37<1:43:57, 14.78s/it] 16%|█▌        | 79/500 [19:52<1:43:44, 14.78s/it] 16%|█▌        | 80/500 [20:07<1:43:15, 14.75s/it] 16%|█▌        | 81/500 [20:22<1:44:51, 15.02s/it] 16%|█▋        | 82/500 [20:38<1:45:18, 15.12s/it] 17%|█▋        | 83/500 [20:52<1:43:57, 14.96s/it] 17%|█▋        | 83/500 [20:52<1:44:53, 15.09s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.318 MB uploadedwandb: \ 0.010 MB of 0.318 MB uploadedwandb: | 0.020 MB of 0.318 MB uploadedwandb: / 0.318 MB of 0.318 MB uploadedwandb: - 0.318 MB of 0.318 MB uploadedwandb: \ 0.318 MB of 0.318 MB uploadedwandb: | 0.318 MB of 0.318 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████▆▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train_accuracy ▁▄▄▅▅▆▆▅▅▆▁▆▅▄▆▇▇▇▆▇▇▇▆▇▆▅▅▆▇▆▇▆▅▅█▅▆▇██
wandb:     train_loss ▅▄▄▃▅▄▃▄▃▄█▅▂▂▃▃▄▃█▂▃▃▂▂▃▃▃▄▂▂▂▂▃█▁▁▂▂▁▂
wandb:   val_accuracy ▆▇▃▃▃▁▃▄▄▃▅▄▄▅▄▄▅▅▆▆▆▆▆▅▇▆▆▆▇▇▆▇▇▆▇▇▇█▇█
wandb:       val_loss ▃▃▃▃▄▃▂▄▂▃▃▂▃▄▅▃▄▄▆▃▂▄▇▅▁▇▁▂▄█▄▅▄▄█▆▅▆▂▃
wandb: 
wandb: Run summary:
wandb:          epoch 82
wandb:  learning_rate 2e-05
wandb: train_accuracy 0.7578
wandb:     train_loss 0.43624
wandb:   val_accuracy 0.38222
wandb:       val_loss 1.06716
wandb: 
wandb: 🚀 View run pious-haze-2661 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jdkopsup
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_112523-jdkopsup/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_114654-mtyoyugq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-yogurt-2662
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mtyoyugq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:25:52, 17.54s/it]  0%|          | 2/500 [00:32<2:15:01, 16.27s/it]  1%|          | 3/500 [00:48<2:10:51, 15.80s/it]  1%|          | 4/500 [01:03<2:07:59, 15.48s/it]  1%|          | 5/500 [01:18<2:06:12, 15.30s/it]  1%|          | 6/500 [01:33<2:05:10, 15.20s/it]  1%|▏         | 7/500 [01:48<2:03:59, 15.09s/it]  2%|▏         | 8/500 [02:03<2:03:36, 15.07s/it]  2%|▏         | 9/500 [02:18<2:03:25, 15.08s/it]  2%|▏         | 10/500 [02:33<2:02:36, 15.01s/it]  2%|▏         | 11/500 [02:48<2:03:25, 15.14s/it]  2%|▏         | 12/500 [03:03<2:03:32, 15.19s/it]  3%|▎         | 13/500 [03:18<2:02:58, 15.15s/it]  3%|▎         | 14/500 [03:33<2:02:21, 15.11s/it]  3%|▎         | 15/500 [03:48<2:01:41, 15.06s/it]  3%|▎         | 16/500 [04:05<2:04:54, 15.48s/it]  3%|▎         | 17/500 [04:20<2:04:10, 15.43s/it]  4%|▎         | 18/500 [04:35<2:01:55, 15.18s/it]  4%|▍         | 19/500 [04:49<2:00:56, 15.09s/it]  4%|▍         | 20/500 [05:04<1:59:56, 14.99s/it]  4%|▍         | 21/500 [05:19<1:58:52, 14.89s/it]  4%|▍         | 22/500 [05:34<1:58:14, 14.84s/it]  5%|▍         | 23/500 [05:49<1:58:09, 14.86s/it]  5%|▍         | 24/500 [06:04<1:58:23, 14.92s/it]  5%|▌         | 25/500 [06:19<1:58:12, 14.93s/it]  5%|▌         | 26/500 [06:33<1:57:47, 14.91s/it]  5%|▌         | 27/500 [06:48<1:56:59, 14.84s/it]  5%|▌         | 27/500 [06:48<1:59:18, 15.13s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.021 MB of 0.311 MB uploadedwandb: - 0.311 MB of 0.311 MB uploadedwandb: \ 0.311 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb: / 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▅▅▅▅▆▇▃▇▇▇▇▇▇▆▇███▇███▇██
wandb:     train_loss ▆▆▆▄▁▄▁▂▁▁▃▂▂▃▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▆▃▂▁▂▄▆▁█▅▅▄▄▄▃▅▆▆▄▄▄▆▄▃▆▄
wandb:       val_loss ▂▂▂▄▃▃▃▂█▅▁▃▃█▄▃▁▆▂█▄▆▇▆▃▁▅
wandb: 
wandb: Run summary:
wandb:          epoch 26
wandb:  learning_rate 0.00032
wandb: train_accuracy 0.95245
wandb:     train_loss 0.0196
wandb:   val_accuracy 0.25556
wandb:       val_loss 3.40239
wandb: 
wandb: 🚀 View run eager-yogurt-2662 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/mtyoyugq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_114654-mtyoyugq/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_115424-brz031bx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-snow-2663
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/brz031bx
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:26:10, 17.58s/it]  0%|          | 2/500 [00:32<2:14:28, 16.20s/it]  1%|          | 3/500 [00:48<2:10:28, 15.75s/it]  1%|          | 4/500 [01:03<2:08:20, 15.53s/it]  1%|          | 5/500 [01:18<2:06:41, 15.36s/it]  1%|          | 6/500 [01:33<2:05:48, 15.28s/it]  1%|▏         | 7/500 [01:48<2:04:51, 15.20s/it]  2%|▏         | 8/500 [02:03<2:04:42, 15.21s/it]  2%|▏         | 9/500 [02:18<2:04:03, 15.16s/it]  2%|▏         | 10/500 [02:33<2:02:43, 15.03s/it]  2%|▏         | 11/500 [02:48<2:01:46, 14.94s/it]  2%|▏         | 12/500 [03:03<2:01:45, 14.97s/it]  3%|▎         | 13/500 [03:22<2:12:55, 16.38s/it]  3%|▎         | 14/500 [03:37<2:09:06, 15.94s/it]  3%|▎         | 15/500 [03:57<2:17:35, 17.02s/it]  3%|▎         | 16/500 [04:12<2:11:55, 16.35s/it]  3%|▎         | 17/500 [04:31<2:19:13, 17.29s/it]  4%|▎         | 18/500 [04:46<2:13:11, 16.58s/it]  4%|▍         | 19/500 [05:01<2:08:24, 16.02s/it]  4%|▍         | 20/500 [05:16<2:05:18, 15.66s/it]  4%|▍         | 21/500 [05:31<2:03:44, 15.50s/it]  4%|▍         | 22/500 [05:46<2:02:07, 15.33s/it]  5%|▍         | 23/500 [06:01<2:01:07, 15.24s/it]  5%|▍         | 24/500 [06:16<2:01:37, 15.33s/it]  5%|▌         | 25/500 [06:31<2:00:18, 15.20s/it]  5%|▌         | 26/500 [06:46<1:59:30, 15.13s/it]  5%|▌         | 27/500 [07:01<1:59:24, 15.15s/it]  6%|▌         | 28/500 [07:16<1:59:11, 15.15s/it]  6%|▌         | 29/500 [07:31<1:58:14, 15.06s/it]  6%|▌         | 30/500 [07:46<1:57:44, 15.03s/it]  6%|▌         | 31/500 [08:01<1:57:21, 15.01s/it]  6%|▋         | 32/500 [08:16<1:57:14, 15.03s/it]  7%|▋         | 33/500 [08:31<1:56:41, 14.99s/it]  7%|▋         | 34/500 [08:46<1:56:10, 14.96s/it]  7%|▋         | 35/500 [09:01<1:56:32, 15.04s/it]  7%|▋         | 36/500 [09:17<1:57:00, 15.13s/it]  7%|▋         | 37/500 [09:32<1:57:12, 15.19s/it]  8%|▊         | 38/500 [09:47<1:56:08, 15.08s/it]  8%|▊         | 39/500 [10:02<1:56:52, 15.21s/it]  8%|▊         | 40/500 [10:18<1:57:07, 15.28s/it]  8%|▊         | 41/500 [10:33<1:56:23, 15.22s/it]  8%|▊         | 42/500 [10:48<1:55:37, 15.15s/it]  9%|▊         | 43/500 [11:03<1:55:08, 15.12s/it]  9%|▉         | 44/500 [11:18<1:55:45, 15.23s/it]  9%|▉         | 45/500 [11:33<1:54:51, 15.15s/it]  9%|▉         | 46/500 [11:48<1:54:09, 15.09s/it]  9%|▉         | 47/500 [12:03<1:53:54, 15.09s/it] 10%|▉         | 48/500 [12:20<1:56:51, 15.51s/it] 10%|▉         | 49/500 [12:35<1:55:56, 15.42s/it] 10%|█         | 50/500 [12:50<1:54:48, 15.31s/it] 10%|█         | 51/500 [13:05<1:53:42, 15.19s/it] 10%|█         | 52/500 [13:21<1:56:07, 15.55s/it] 11%|█         | 53/500 [13:37<1:56:45, 15.67s/it] 11%|█         | 54/500 [13:53<1:57:10, 15.76s/it] 11%|█         | 55/500 [14:09<1:56:37, 15.73s/it] 11%|█         | 56/500 [14:25<1:56:44, 15.78s/it] 11%|█▏        | 57/500 [14:41<1:56:52, 15.83s/it] 12%|█▏        | 58/500 [14:56<1:56:24, 15.80s/it] 12%|█▏        | 59/500 [15:12<1:55:58, 15.78s/it] 12%|█▏        | 60/500 [15:27<1:53:50, 15.52s/it] 12%|█▏        | 61/500 [15:42<1:52:22, 15.36s/it] 12%|█▏        | 62/500 [15:57<1:51:20, 15.25s/it] 13%|█▎        | 63/500 [16:12<1:50:43, 15.20s/it] 13%|█▎        | 64/500 [16:27<1:50:10, 15.16s/it] 13%|█▎        | 65/500 [16:42<1:49:06, 15.05s/it] 13%|█▎        | 66/500 [16:57<1:48:33, 15.01s/it] 13%|█▎        | 67/500 [17:12<1:48:03, 14.97s/it] 14%|█▎        | 68/500 [17:27<1:48:43, 15.10s/it] 14%|█▎        | 68/500 [17:27<1:50:56, 15.41s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.020 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▁▃▂▄▆▇▅▇▄▄▇▅████▇███▇▇██▇▅██▇███████
wandb:     train_loss ▃▃▂▁▁▆▂█▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▄▁▁▁▆▁▁▃▁▁▁
wandb:   val_accuracy ▅▄▄▃▄▅▆▆▆▆▃▆▁█▆█▇▇▆██▇▇▇██▇▇▆▇▇▇▇▆▇█▆▇▇▇
wandb:       val_loss ▂▂▂▃▅▂▂▁▄▅▂▄▅▃▂▁▃▂▃▂▅▁▃▁▃▁▄▅▃▄▁▁▁▂▃█▁▄▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 67
wandb:  learning_rate 0.00026
wandb: train_accuracy 0.97177
wandb:     train_loss 1e-05
wandb:   val_accuracy 0.49333
wandb:       val_loss 3.45934
wandb: 
wandb: 🚀 View run serene-snow-2663 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/brz031bx
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_115424-brz031bx/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_121233-3x0l9xwa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sound-2664
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/3x0l9xwa
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:29<4:01:29, 29.04s/it]  0%|          | 2/500 [00:44<2:56:59, 21.32s/it]  1%|          | 3/500 [01:00<2:36:24, 18.88s/it]  1%|          | 4/500 [01:16<2:25:21, 17.58s/it]  1%|          | 5/500 [01:40<2:45:20, 20.04s/it]  1%|          | 6/500 [01:56<2:32:55, 18.57s/it]  1%|▏         | 7/500 [02:16<2:36:40, 19.07s/it]  2%|▏         | 8/500 [02:36<2:38:56, 19.38s/it]  2%|▏         | 9/500 [02:52<2:28:33, 18.15s/it]  2%|▏         | 10/500 [03:07<2:21:19, 17.31s/it]  2%|▏         | 11/500 [03:22<2:15:52, 16.67s/it]  2%|▏         | 12/500 [03:37<2:11:33, 16.17s/it]  3%|▎         | 13/500 [03:53<2:09:06, 15.91s/it]  3%|▎         | 14/500 [04:08<2:08:03, 15.81s/it]  3%|▎         | 15/500 [04:24<2:06:52, 15.70s/it]  3%|▎         | 16/500 [04:39<2:06:45, 15.71s/it]  3%|▎         | 17/500 [04:55<2:06:42, 15.74s/it]  4%|▎         | 18/500 [05:11<2:07:28, 15.87s/it]  4%|▍         | 19/500 [05:27<2:07:12, 15.87s/it]  4%|▍         | 20/500 [05:43<2:05:40, 15.71s/it]  4%|▍         | 21/500 [05:58<2:03:52, 15.52s/it]  4%|▍         | 22/500 [06:13<2:02:53, 15.43s/it]  5%|▍         | 23/500 [06:28<2:01:53, 15.33s/it]  5%|▍         | 24/500 [06:43<2:01:20, 15.29s/it]  5%|▌         | 25/500 [06:59<2:01:50, 15.39s/it]  5%|▌         | 26/500 [07:14<2:01:56, 15.44s/it]  5%|▌         | 27/500 [07:30<2:01:13, 15.38s/it]  6%|▌         | 28/500 [07:45<2:00:40, 15.34s/it]  6%|▌         | 29/500 [08:00<2:00:43, 15.38s/it]  6%|▌         | 30/500 [08:16<2:00:52, 15.43s/it]  6%|▌         | 31/500 [08:31<2:00:32, 15.42s/it]  6%|▋         | 32/500 [08:47<2:00:18, 15.42s/it]  7%|▋         | 33/500 [09:02<2:00:07, 15.43s/it]  7%|▋         | 34/500 [09:18<1:59:55, 15.44s/it]  7%|▋         | 34/500 [09:18<2:07:30, 16.42s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.315 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.106 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▂▃▂▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇▇█▇███▇▇█▇▇▆▇██
wandb:     train_loss █▆▆▅▆▅▅▅▆▆▅▄▄▄▅▅▆▅▅▂▄▁▃▃▅▄▅▂▃▁█▁▁▄
wandb:   val_accuracy █▇█▇▇▇▆▅▆▆▇▇▆▆▆▅▅▄▄▄▂▂▂▁▂▁▃▁▁▁▂▂▃▂
wandb:       val_loss ▃▃▃▄▂▂▃▂▅▄▃▄▁▃▃▇▅▁▄▆▃▆█▃▂▂▄▇█▃▁█▄▅
wandb: 
wandb: Run summary:
wandb:          epoch 33
wandb:  learning_rate 5e-05
wandb: train_accuracy 0.70431
wandb:     train_loss 0.69952
wandb:   val_accuracy 0.20444
wandb:       val_loss 1.3837
wandb: 
wandb: 🚀 View run fanciful-sound-2664 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/3x0l9xwa
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_121233-3x0l9xwa/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_122231-xdghrmry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-donkey-2665
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xdghrmry
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:39:01, 19.12s/it]  0%|          | 2/500 [00:35<2:25:55, 17.58s/it]  1%|          | 3/500 [00:52<2:21:52, 17.13s/it]  1%|          | 4/500 [01:08<2:17:55, 16.68s/it]  1%|          | 5/500 [01:24<2:15:43, 16.45s/it]  1%|          | 6/500 [01:40<2:13:54, 16.26s/it]  1%|▏         | 7/500 [01:56<2:12:47, 16.16s/it]  2%|▏         | 8/500 [02:11<2:11:15, 16.01s/it]  2%|▏         | 9/500 [02:27<2:10:06, 15.90s/it]  2%|▏         | 10/500 [02:43<2:09:14, 15.83s/it]  2%|▏         | 11/500 [02:58<2:08:59, 15.83s/it]  2%|▏         | 12/500 [03:14<2:07:05, 15.63s/it]  3%|▎         | 13/500 [03:29<2:06:00, 15.53s/it]  3%|▎         | 14/500 [03:44<2:04:47, 15.41s/it]  3%|▎         | 15/500 [03:59<2:03:28, 15.28s/it]  3%|▎         | 16/500 [04:14<2:03:24, 15.30s/it]  3%|▎         | 17/500 [04:29<2:01:50, 15.14s/it]  4%|▎         | 18/500 [04:44<2:00:53, 15.05s/it]  4%|▍         | 19/500 [04:59<2:00:11, 14.99s/it]  4%|▍         | 20/500 [05:14<1:59:50, 14.98s/it]  4%|▍         | 21/500 [05:29<1:59:52, 15.01s/it]  4%|▍         | 22/500 [05:44<1:59:07, 14.95s/it]  4%|▍         | 22/500 [05:44<2:04:38, 15.65s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.027 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.021 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁
wandb: train_accuracy ▁▂█▃▁▃▁▂▃▄▄▄▅▅▅▆▆▅▅▅▆▆
wandb:     train_loss ▄▃▃▁█▂▃▄▃▄▄▄▁▄▄▄▂▁▄▄▄▄
wandb:   val_accuracy ▆▄▁▂▂▇█▇▆▇▆▇▆▇▇▆▇▆▆▇▇▇
wandb:       val_loss ▃▃▃█▂▁▃▃▄▄▃▄▃▃▂▄▇▃▆▃▃▂
wandb: 
wandb: Run summary:
wandb:          epoch 21
wandb:  learning_rate 0.00032
wandb: train_accuracy 0.53343
wandb:     train_loss 1.09861
wandb:   val_accuracy 0.39111
wandb:       val_loss 0.91082
wandb: 
wandb: 🚀 View run smart-donkey-2665 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/xdghrmry
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_122231-xdghrmry/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_122903-6f32oe42
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-plant-2666
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6f32oe42
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:30:16, 25.28s/it]  0%|          | 2/500 [00:49<3:25:38, 24.78s/it]  1%|          | 3/500 [01:13<3:22:07, 24.40s/it]  1%|          | 4/500 [01:54<4:16:47, 31.06s/it]  1%|          | 5/500 [02:27<4:19:31, 31.46s/it]  1%|          | 6/500 [02:50<3:57:36, 28.86s/it]  1%|▏         | 7/500 [03:23<4:05:48, 29.92s/it]  2%|▏         | 8/500 [03:54<4:08:37, 30.32s/it]  2%|▏         | 9/500 [04:24<4:08:38, 30.38s/it]  2%|▏         | 10/500 [04:58<4:15:58, 31.34s/it]  2%|▏         | 11/500 [05:33<4:24:14, 32.42s/it]  2%|▏         | 12/500 [06:04<4:21:24, 32.14s/it]  3%|▎         | 13/500 [06:37<4:22:06, 32.29s/it]  3%|▎         | 14/500 [07:04<4:10:18, 30.90s/it]  3%|▎         | 15/500 [07:33<4:04:53, 30.30s/it]  3%|▎         | 16/500 [07:57<3:47:12, 28.17s/it]  3%|▎         | 17/500 [08:29<3:56:51, 29.42s/it]  4%|▎         | 18/500 [08:53<3:42:34, 27.71s/it]  4%|▍         | 19/500 [09:23<3:48:33, 28.51s/it]  4%|▍         | 20/500 [09:47<3:37:40, 27.21s/it]  4%|▍         | 21/500 [10:17<3:44:20, 28.10s/it]  4%|▍         | 22/500 [10:41<3:32:29, 26.67s/it]  5%|▍         | 23/500 [11:12<3:44:19, 28.22s/it]  5%|▍         | 24/500 [11:39<3:40:05, 27.74s/it]  5%|▌         | 25/500 [12:13<3:54:30, 29.62s/it]  5%|▌         | 26/500 [12:46<4:02:13, 30.66s/it]  5%|▌         | 27/500 [13:10<3:46:21, 28.71s/it]  6%|▌         | 28/500 [13:36<3:38:04, 27.72s/it]  6%|▌         | 29/500 [14:00<3:30:18, 26.79s/it]  6%|▌         | 30/500 [14:33<3:44:13, 28.62s/it]  6%|▌         | 31/500 [15:06<3:53:24, 29.86s/it]  6%|▋         | 32/500 [15:38<3:58:07, 30.53s/it]  7%|▋         | 33/500 [16:07<3:53:35, 30.01s/it]  7%|▋         | 34/500 [16:38<3:56:25, 30.44s/it]  7%|▋         | 35/500 [17:07<3:51:58, 29.93s/it]  7%|▋         | 35/500 [17:07<3:47:32, 29.36s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.310 MB uploadedwandb: / 0.010 MB of 0.310 MB uploadedwandb: - 0.231 MB of 0.310 MB uploadedwandb: \ 0.231 MB of 0.310 MB uploadedwandb: | 0.310 MB of 0.310 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁
wandb: train_accuracy ▂▂▁▂▇▅▇▇▄▇▇▇▇█▇███▇██▇████▄████████
wandb:     train_loss ▃▃█▃▃▄▂▂▁▁▁▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▃▄▄▆▄▁▅▄▆▇██▇▇█▁▆▅█▆▃▇▆▇▆▇▄▅▆▆▇▅▄▆▆
wandb:       val_loss ▂▂▂▁▁▁▄▃▃▃▃▂▃▂▃▃▁▁▁▃▁▆▄▄▅▃█▄▁▂▂▂▃▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 34
wandb:  learning_rate 0.00051
wandb: train_accuracy 1.0
wandb:     train_loss 0.00115
wandb:   val_accuracy 0.43556
wandb:       val_loss 0.09223
wandb: 
wandb: 🚀 View run skilled-plant-2666 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/6f32oe42
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_122903-6f32oe42/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_124650-sv0yn09k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-dream-2667
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sv0yn09k
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:36:16, 26.00s/it]  0%|          | 2/500 [00:50<3:28:44, 25.15s/it]  1%|          | 3/500 [01:14<3:23:57, 24.62s/it]  1%|          | 4/500 [01:37<3:19:29, 24.13s/it]  1%|          | 5/500 [02:08<3:38:42, 26.51s/it]  1%|          | 6/500 [02:32<3:30:55, 25.62s/it]  1%|▏         | 7/500 [02:56<3:26:51, 25.18s/it]  2%|▏         | 8/500 [03:22<3:28:47, 25.46s/it]  2%|▏         | 9/500 [03:46<3:24:28, 24.99s/it]  2%|▏         | 10/500 [04:15<3:34:15, 26.24s/it]  2%|▏         | 11/500 [04:40<3:31:00, 25.89s/it]  2%|▏         | 12/500 [05:06<3:28:37, 25.65s/it]  3%|▎         | 13/500 [05:29<3:22:35, 24.96s/it]  3%|▎         | 14/500 [06:00<3:36:47, 26.76s/it]  3%|▎         | 15/500 [06:23<3:27:13, 25.64s/it]  3%|▎         | 16/500 [06:54<3:40:42, 27.36s/it]  3%|▎         | 17/500 [07:19<3:34:55, 26.70s/it]  4%|▎         | 18/500 [07:43<3:26:45, 25.74s/it]  4%|▍         | 19/500 [08:12<3:34:02, 26.70s/it]  4%|▍         | 20/500 [08:45<3:50:13, 28.78s/it]  4%|▍         | 21/500 [09:25<4:16:35, 32.14s/it]  4%|▍         | 22/500 [09:49<3:54:53, 29.48s/it]  5%|▍         | 23/500 [10:20<3:59:02, 30.07s/it]  5%|▍         | 24/500 [10:51<4:00:10, 30.27s/it]  5%|▌         | 25/500 [11:21<3:58:08, 30.08s/it]  5%|▌         | 26/500 [11:50<3:54:57, 29.74s/it]  5%|▌         | 27/500 [12:22<4:00:56, 30.56s/it]  6%|▌         | 28/500 [12:56<4:07:50, 31.51s/it]  6%|▌         | 29/500 [13:27<4:07:51, 31.57s/it]  6%|▌         | 30/500 [13:59<4:06:49, 31.51s/it]  6%|▌         | 31/500 [14:36<4:19:35, 33.21s/it]  6%|▋         | 32/500 [14:59<3:55:57, 30.25s/it]  7%|▋         | 33/500 [15:31<3:58:13, 30.61s/it]  7%|▋         | 34/500 [15:59<3:53:21, 30.05s/it]  7%|▋         | 35/500 [16:27<3:46:54, 29.28s/it]  7%|▋         | 36/500 [16:51<3:34:42, 27.76s/it]  7%|▋         | 37/500 [17:15<3:25:04, 26.58s/it]  8%|▊         | 38/500 [17:39<3:18:41, 25.80s/it]  8%|▊         | 39/500 [18:04<3:15:21, 25.43s/it]  8%|▊         | 40/500 [18:32<3:21:19, 26.26s/it]  8%|▊         | 41/500 [18:55<3:13:59, 25.36s/it]  8%|▊         | 42/500 [19:25<3:24:49, 26.83s/it]  9%|▊         | 43/500 [19:50<3:19:24, 26.18s/it]  9%|▉         | 44/500 [20:14<3:15:08, 25.68s/it]  9%|▉         | 45/500 [20:38<3:10:56, 25.18s/it]  9%|▉         | 46/500 [21:05<3:12:51, 25.49s/it]  9%|▉         | 47/500 [21:28<3:07:03, 24.78s/it]  9%|▉         | 47/500 [21:28<3:26:57, 27.41s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.020 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▁▃▄▄▅▄▆▆▆▆▆▆▇▆▄▇▆▇▇▇▇▇▇█▇█▇▇▇▇▇▇███████
wandb:     train_loss ▆▇▅▅▆▆▅▇▆▅▅▄▄▄▄▆▄▃▂▃▂▆▄▂▂▃▁▂▁▃▄▂▆▄▄▃█▅▂▄
wandb:   val_accuracy ▆▅▅▂▂▁▂▄▃▂▂▃▁▃▁▂▃▃▅▃▃▄▄▄▄▄▅▄█▄▅▅▃▆▅▆▇▇▇▇
wandb:       val_loss ▃▂▃▃▂▃▃▃▃▃▄▃▄▄▂▃▄▂▅▄▄▄▃▃▃▄▁▄▂▂▃▂▄▇▇▃▁▂▆█
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.77712
wandb:     train_loss 0.69833
wandb:   val_accuracy 0.36
wandb:       val_loss 3.14078
wandb: 
wandb: 🚀 View run zesty-dream-2667 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sv0yn09k
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_124650-sv0yn09k/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_130902-alq1nyf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run blooming-puddle-2668
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/alq1nyf7
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:30:11, 25.27s/it]  0%|          | 2/500 [00:48<3:21:37, 24.29s/it]  1%|          | 3/500 [01:12<3:17:44, 23.87s/it]  1%|          | 4/500 [01:35<3:16:55, 23.82s/it]  1%|          | 5/500 [02:07<3:38:11, 26.45s/it]  1%|          | 6/500 [02:40<3:58:25, 28.96s/it]  1%|▏         | 7/500 [03:11<4:02:08, 29.47s/it]  2%|▏         | 8/500 [03:43<4:07:45, 30.22s/it]  2%|▏         | 9/500 [04:13<4:07:21, 30.23s/it]  2%|▏         | 10/500 [04:43<4:06:52, 30.23s/it]  2%|▏         | 11/500 [05:15<4:09:47, 30.65s/it]  2%|▏         | 12/500 [05:54<4:30:35, 33.27s/it]  3%|▎         | 13/500 [06:23<4:20:25, 32.09s/it]  3%|▎         | 14/500 [06:47<3:57:46, 29.36s/it]  3%|▎         | 15/500 [07:18<4:01:36, 29.89s/it]  3%|▎         | 16/500 [07:49<4:04:26, 30.30s/it]  3%|▎         | 17/500 [08:16<3:55:55, 29.31s/it]  4%|▎         | 18/500 [08:39<3:41:35, 27.58s/it]  4%|▍         | 19/500 [09:05<3:36:17, 26.98s/it]  4%|▍         | 20/500 [09:33<3:37:09, 27.15s/it]  4%|▍         | 21/500 [10:01<3:39:41, 27.52s/it]  4%|▍         | 22/500 [10:27<3:36:41, 27.20s/it]  5%|▍         | 23/500 [10:52<3:30:12, 26.44s/it]  5%|▍         | 24/500 [11:15<3:21:08, 25.35s/it]  5%|▌         | 25/500 [11:47<3:36:19, 27.33s/it]  5%|▌         | 26/500 [12:10<3:25:17, 25.99s/it]  5%|▌         | 27/500 [12:42<3:40:29, 27.97s/it]  6%|▌         | 28/500 [13:06<3:29:03, 26.58s/it]  6%|▌         | 29/500 [13:31<3:26:30, 26.31s/it]  6%|▌         | 30/500 [13:56<3:21:29, 25.72s/it]  6%|▌         | 31/500 [14:21<3:19:12, 25.49s/it]  6%|▋         | 32/500 [14:44<3:13:01, 24.75s/it]  7%|▋         | 33/500 [15:12<3:21:15, 25.86s/it]  7%|▋         | 34/500 [15:45<3:37:50, 28.05s/it]  7%|▋         | 35/500 [16:15<3:42:32, 28.72s/it]  7%|▋         | 36/500 [16:41<3:35:44, 27.90s/it]  7%|▋         | 37/500 [17:08<3:32:05, 27.48s/it]  8%|▊         | 38/500 [17:32<3:24:08, 26.51s/it]  8%|▊         | 39/500 [17:58<3:21:21, 26.21s/it]  8%|▊         | 40/500 [18:21<3:14:01, 25.31s/it]  8%|▊         | 41/500 [18:48<3:18:02, 25.89s/it]  8%|▊         | 42/500 [19:12<3:12:00, 25.15s/it]  9%|▊         | 43/500 [19:39<3:16:39, 25.82s/it]  9%|▉         | 44/500 [20:05<3:15:39, 25.74s/it]  9%|▉         | 45/500 [20:29<3:12:57, 25.44s/it]  9%|▉         | 46/500 [20:56<3:14:20, 25.68s/it]  9%|▉         | 47/500 [21:22<3:16:11, 25.98s/it] 10%|▉         | 48/500 [21:53<3:26:17, 27.38s/it] 10%|▉         | 49/500 [22:24<3:34:39, 28.56s/it] 10%|█         | 50/500 [22:52<3:32:13, 28.30s/it] 10%|█         | 51/500 [23:16<3:21:45, 26.96s/it] 10%|█         | 52/500 [23:41<3:18:08, 26.54s/it] 11%|█         | 53/500 [24:08<3:17:22, 26.49s/it] 11%|█         | 54/500 [24:32<3:12:14, 25.86s/it] 11%|█         | 55/500 [24:57<3:09:35, 25.56s/it] 11%|█         | 56/500 [25:24<3:11:49, 25.92s/it] 11%|█▏        | 57/500 [25:47<3:05:10, 25.08s/it] 12%|█▏        | 58/500 [26:15<3:12:39, 26.15s/it] 12%|█▏        | 59/500 [26:43<3:14:26, 26.45s/it] 12%|█▏        | 59/500 [26:43<3:19:42, 27.17s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.320 MB uploadedwandb: \ 0.010 MB of 0.320 MB uploadedwandb: | 0.133 MB of 0.320 MB uploadedwandb: / 0.320 MB of 0.320 MB uploadedwandb: - 0.320 MB of 0.320 MB uploadedwandb: \ 0.320 MB of 0.320 MB uploadedwandb: | 0.320 MB of 0.320 MB uploadedwandb: / 0.320 MB of 0.320 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▆▆▆▆▆▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train_accuracy ▁▂▁▂▃▅▄▄▄▅▅▇▇▅▆▄█▇▅▅▅█▆██▆██▇▇▇▇██▆██▃██
wandb:     train_loss ▂▂▂▂▂▂▁▆▄▁▂▁▁▁▁▁▁▅▂▁▁▁▁▁▁▃▁▂▆▂▁▁▁▁▁▁▁█▁▁
wandb:   val_accuracy ▂▃▂▁▂▆▅▇▃▆▅█▇▇▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▅▇██▆▇▇▇▇
wandb:       val_loss ▁▁▁▂▂▂▁▂▁▁▂▁▁▁▃▂▂▂▆▁▃▁▂▂▁▁▃▃▁▂▂▅▃▂▂▃█▂▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 58
wandb:  learning_rate 0.00016
wandb: train_accuracy 0.96285
wandb:     train_loss 0.00165
wandb:   val_accuracy 0.42444
wandb:       val_loss 2.16835
wandb: 
wandb: 🚀 View run blooming-puddle-2668 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/alq1nyf7
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_130902-alq1nyf7/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_133632-jfms9l08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-pond-2669
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jfms9l08
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:09:08, 37.17s/it]  0%|          | 2/500 [01:01<4:03:44, 29.37s/it]  1%|          | 3/500 [01:33<4:13:21, 30.59s/it]  1%|          | 4/500 [02:05<4:18:45, 31.30s/it]  1%|          | 5/500 [02:37<4:20:19, 31.55s/it]  1%|          | 6/500 [03:06<4:13:23, 30.78s/it]  1%|▏         | 7/500 [03:39<4:18:02, 31.40s/it]  2%|▏         | 8/500 [04:11<4:19:34, 31.66s/it]  2%|▏         | 9/500 [04:44<4:20:54, 31.88s/it]  2%|▏         | 10/500 [05:12<4:11:42, 30.82s/it]  2%|▏         | 11/500 [05:45<4:17:35, 31.61s/it]  2%|▏         | 12/500 [06:14<4:10:09, 30.76s/it]  3%|▎         | 13/500 [06:38<3:52:58, 28.70s/it]  3%|▎         | 14/500 [07:04<3:45:46, 27.87s/it]  3%|▎         | 15/500 [07:29<3:38:50, 27.07s/it]  3%|▎         | 16/500 [07:54<3:33:32, 26.47s/it]  3%|▎         | 17/500 [08:18<3:27:05, 25.73s/it]  4%|▎         | 18/500 [08:46<3:31:46, 26.36s/it]  4%|▍         | 19/500 [09:11<3:28:05, 25.96s/it]  4%|▍         | 20/500 [09:35<3:23:00, 25.38s/it]  4%|▍         | 21/500 [10:17<4:00:51, 30.17s/it]  4%|▍         | 22/500 [10:40<3:44:52, 28.23s/it]  5%|▍         | 23/500 [11:12<3:53:14, 29.34s/it]  5%|▍         | 24/500 [11:44<3:59:06, 30.14s/it]  5%|▌         | 25/500 [12:14<3:56:48, 29.91s/it]  5%|▌         | 26/500 [12:37<3:41:48, 28.08s/it]  5%|▌         | 27/500 [13:02<3:32:51, 27.00s/it]  6%|▌         | 28/500 [13:28<3:31:16, 26.86s/it]  6%|▌         | 29/500 [14:02<3:46:35, 28.86s/it]  6%|▌         | 30/500 [14:33<3:50:27, 29.42s/it]  6%|▌         | 31/500 [15:05<3:56:15, 30.23s/it]  6%|▋         | 32/500 [15:32<3:48:36, 29.31s/it]  7%|▋         | 33/500 [15:58<3:41:24, 28.45s/it]  7%|▋         | 34/500 [16:24<3:34:21, 27.60s/it]  7%|▋         | 35/500 [16:47<3:23:34, 26.27s/it]  7%|▋         | 36/500 [17:19<3:35:28, 27.86s/it]  7%|▋         | 37/500 [17:47<3:35:32, 27.93s/it]  7%|▋         | 37/500 [17:47<3:42:37, 28.85s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.231 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▅▃▅▄▃▂██▅▇▁▂▅▅▅▄▅▄▅▄▄▄▅▅▅▅▅▄▅▄▅▅▅▅▅▄
wandb:     train_loss ▃▂▂▁▃██▁▂▁▁▄▃▂▁▂▂▃▂▄▃▃▅▁▃▁▁▁▁▁▃▃▁▃▁▁▃
wandb:   val_accuracy ▅▅▁▂▂▃▃▅▆▂▄▅▂▅▆▆▇▇▇▇▇█▇▇▇▆▇▆▇▇▇▇▇▇▆▇▇
wandb:       val_loss ▂▂▃▂▂▃█▅▃▄▃▃▂▂▂▂▁▁▂▂▁▂▂▂▂▂▃▃▂▃▂▂▁▂▃▁▁
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 0.00051
wandb: train_accuracy 0.58544
wandb:     train_loss 1.36704
wandb:   val_accuracy 0.41111
wandb:       val_loss 0.17501
wandb: 
wandb: 🚀 View run absurd-pond-2669 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jfms9l08
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_133632-jfms9l08/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_135516-hy1zsg0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-armadillo-2670
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/hy1zsg0l
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:36<5:05:23, 36.72s/it]  0%|          | 2/500 [01:08<4:42:26, 34.03s/it]  1%|          | 3/500 [01:32<4:03:25, 29.39s/it]  1%|          | 4/500 [01:56<3:43:22, 27.02s/it]  1%|          | 5/500 [02:20<3:34:21, 25.98s/it]  1%|          | 6/500 [02:53<3:53:27, 28.36s/it]  1%|▏         | 7/500 [03:18<3:45:01, 27.39s/it]  2%|▏         | 8/500 [03:43<3:38:13, 26.61s/it]  2%|▏         | 9/500 [04:07<3:30:47, 25.76s/it]  2%|▏         | 10/500 [04:34<3:32:21, 26.00s/it]  2%|▏         | 11/500 [04:58<3:29:06, 25.66s/it]  2%|▏         | 12/500 [05:24<3:28:14, 25.60s/it]  3%|▎         | 13/500 [05:48<3:25:16, 25.29s/it]  3%|▎         | 14/500 [06:15<3:27:36, 25.63s/it]  3%|▎         | 15/500 [06:38<3:21:12, 24.89s/it]  3%|▎         | 16/500 [07:05<3:26:36, 25.61s/it]  3%|▎         | 17/500 [07:34<3:32:44, 26.43s/it]  4%|▎         | 18/500 [07:57<3:25:12, 25.54s/it]  4%|▍         | 19/500 [08:29<3:39:46, 27.41s/it]  4%|▍         | 20/500 [08:52<3:28:36, 26.08s/it]  4%|▍         | 21/500 [09:24<3:42:57, 27.93s/it]  4%|▍         | 22/500 [09:47<3:30:26, 26.42s/it]  5%|▍         | 23/500 [10:15<3:33:30, 26.86s/it]  5%|▍         | 24/500 [10:41<3:30:57, 26.59s/it]  5%|▌         | 25/500 [11:04<3:21:17, 25.43s/it]  5%|▌         | 26/500 [11:31<3:25:17, 25.99s/it]  5%|▌         | 27/500 [11:56<3:22:35, 25.70s/it]  6%|▌         | 28/500 [12:19<3:17:02, 25.05s/it]  6%|▌         | 29/500 [12:46<3:19:48, 25.45s/it]  6%|▌         | 30/500 [13:09<3:14:34, 24.84s/it]  6%|▌         | 31/500 [13:39<3:26:07, 26.37s/it]  6%|▋         | 32/500 [14:03<3:18:59, 25.51s/it]  7%|▋         | 33/500 [14:31<3:25:35, 26.41s/it]  7%|▋         | 34/500 [14:58<3:26:54, 26.64s/it]  7%|▋         | 35/500 [15:24<3:25:19, 26.49s/it]  7%|▋         | 36/500 [15:48<3:17:06, 25.49s/it]  7%|▋         | 37/500 [16:18<3:28:27, 27.01s/it]  8%|▊         | 38/500 [16:41<3:18:39, 25.80s/it]  8%|▊         | 39/500 [17:13<3:31:09, 27.48s/it]  8%|▊         | 40/500 [17:37<3:23:23, 26.53s/it]  8%|▊         | 41/500 [18:01<3:18:15, 25.92s/it]  8%|▊         | 42/500 [18:26<3:13:58, 25.41s/it]  9%|▊         | 43/500 [18:50<3:10:48, 25.05s/it]  9%|▉         | 44/500 [19:14<3:07:54, 24.72s/it]  9%|▉         | 45/500 [19:38<3:05:25, 24.45s/it]  9%|▉         | 46/500 [20:04<3:08:41, 24.94s/it]  9%|▉         | 47/500 [20:30<3:11:10, 25.32s/it]  9%|▉         | 47/500 [20:30<3:17:38, 26.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.029 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.232 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▂▂▃▄▄▁▃▄▆▆▅▆▇▆▅▅▇▅▇▇▇▆▇▇▇▇██▇▇▆▇▇██████
wandb:     train_loss ▆▆▅▅▅▅▆▅▅▆▅▃▅▅▄▅▄▃▂▂▂▅▇▃▃▄▁▁▁▅▃▁▅▃█▄▆█▃▂
wandb:   val_accuracy ▇█▄▅▄▆▆▆▃▄▅▄▄▃█▃▅▃▅▂▂▅▆▂▆▆▇▄▄▅▂▅▁▃▂▄▃▄▄▄
wandb:       val_loss ▃▃▃▃▃▃▂▃▃▃▃▃▃▃▂▃▃▃▅▄▃▅▄▅▃▄▁▄▃▂▂▃▄▇▇▄▂▃▅█
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.74146
wandb:     train_loss 0.49983
wandb:   val_accuracy 0.28889
wandb:       val_loss 2.91985
wandb: 
wandb: 🚀 View run fancy-armadillo-2670 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/hy1zsg0l
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_135516-hy1zsg0l/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_141638-z4gxdq5w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-oath-2671
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/z4gxdq5w
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:32:46, 25.58s/it]  0%|          | 2/500 [00:49<3:22:52, 24.44s/it]  1%|          | 3/500 [01:12<3:19:23, 24.07s/it]  1%|          | 4/500 [01:36<3:17:58, 23.95s/it]  1%|          | 5/500 [02:05<3:32:09, 25.72s/it]  1%|          | 6/500 [02:30<3:30:24, 25.56s/it]  1%|▏         | 7/500 [02:54<3:25:40, 25.03s/it]  2%|▏         | 8/500 [03:18<3:21:58, 24.63s/it]  2%|▏         | 9/500 [03:43<3:21:47, 24.66s/it]  2%|▏         | 10/500 [04:09<3:26:19, 25.27s/it]  2%|▏         | 11/500 [04:33<3:21:02, 24.67s/it]  2%|▏         | 12/500 [05:01<3:29:31, 25.76s/it]  3%|▎         | 13/500 [05:24<3:22:03, 24.89s/it]  3%|▎         | 14/500 [05:56<3:38:49, 27.02s/it]  3%|▎         | 15/500 [06:22<3:35:39, 26.68s/it]  3%|▎         | 16/500 [06:46<3:30:08, 26.05s/it]  3%|▎         | 17/500 [07:10<3:24:41, 25.43s/it]  4%|▎         | 18/500 [07:38<3:29:29, 26.08s/it]  4%|▍         | 19/500 [08:01<3:23:17, 25.36s/it]  4%|▍         | 20/500 [08:31<3:32:42, 26.59s/it]  4%|▍         | 21/500 [08:54<3:23:24, 25.48s/it]  4%|▍         | 22/500 [09:22<3:29:24, 26.29s/it]  5%|▍         | 23/500 [09:45<3:22:24, 25.46s/it]  5%|▍         | 24/500 [10:12<3:24:41, 25.80s/it]  5%|▌         | 25/500 [10:37<3:21:24, 25.44s/it]  5%|▌         | 26/500 [11:04<3:25:34, 26.02s/it]  5%|▌         | 27/500 [11:30<3:25:20, 26.05s/it]  6%|▌         | 28/500 [11:54<3:19:03, 25.30s/it]  6%|▌         | 29/500 [12:24<3:29:54, 26.74s/it]  6%|▌         | 30/500 [12:49<3:25:17, 26.21s/it]  6%|▌         | 31/500 [13:14<3:22:40, 25.93s/it]  6%|▋         | 32/500 [13:38<3:17:18, 25.29s/it]  7%|▋         | 33/500 [14:09<3:30:18, 27.02s/it]  7%|▋         | 34/500 [14:32<3:20:43, 25.85s/it]  7%|▋         | 35/500 [15:00<3:25:22, 26.50s/it]  7%|▋         | 36/500 [15:25<3:21:11, 26.02s/it]  7%|▋         | 37/500 [15:52<3:22:21, 26.22s/it]  8%|▊         | 38/500 [16:19<3:24:39, 26.58s/it]  8%|▊         | 39/500 [16:45<3:22:36, 26.37s/it]  8%|▊         | 40/500 [17:08<3:14:43, 25.40s/it]  8%|▊         | 41/500 [17:36<3:20:44, 26.24s/it]  8%|▊         | 42/500 [17:59<3:13:09, 25.31s/it]  9%|▊         | 43/500 [18:31<3:26:34, 27.12s/it]  9%|▉         | 44/500 [18:54<3:16:11, 25.81s/it]  9%|▉         | 45/500 [19:22<3:22:52, 26.75s/it]  9%|▉         | 46/500 [19:45<3:13:30, 25.57s/it]  9%|▉         | 47/500 [20:13<3:17:43, 26.19s/it]  9%|▉         | 47/500 [20:13<3:14:55, 25.82s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.319 MB uploadedwandb: / 0.010 MB of 0.319 MB uploadedwandb: - 0.232 MB of 0.319 MB uploadedwandb: \ 0.319 MB of 0.319 MB uploadedwandb: | 0.319 MB of 0.319 MB uploadedwandb: / 0.319 MB of 0.319 MB uploadedwandb: - 0.319 MB of 0.319 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▂▃▁▂▃▃▅▅▆▇▆▃▄▇▂▇▁▇▅▅▇▇▆█▆▅▆▅▂███▇▇█▇▇█▇▇
wandb:     train_loss ▄▄▄▃▄▃▂▁▃▃▃▁▄▂▂▂▃▁▁▁▁▆▁▁▁▁▁▁▂▁▁▁▇▅▁█▁▁▁▁
wandb:   val_accuracy ▃▃▁▂▂▃▆▆▇█▇▃▃▅▄▅▁▅▄▄▆▆▅▆▄▆▆▆▆▇█▇▇▇▆▇▆▇▆▇
wandb:       val_loss ▂▂▂▂▂▂▂▂▂▃▂▅▂▁▂▁▂▅▄▃▂▆▃▇▂▅▁▃▃▂▂▁▂▄▅▂▁▃▃█
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 0.0002
wandb: train_accuracy 0.90193
wandb:     train_loss 0.00143
wandb:   val_accuracy 0.41556
wandb:       val_loss 9.52684
wandb: 
wandb: 🚀 View run young-oath-2671 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/z4gxdq5w
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_141638-z4gxdq5w/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_143737-qclezurf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-brook-2672
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qclezurf
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:32:47, 25.59s/it]  0%|          | 2/500 [00:48<3:20:52, 24.20s/it]  1%|          | 3/500 [01:11<3:16:17, 23.70s/it]  1%|          | 4/500 [01:35<3:14:09, 23.49s/it]  1%|          | 5/500 [02:04<3:32:01, 25.70s/it]  1%|          | 6/500 [02:27<3:23:40, 24.74s/it]  1%|▏         | 7/500 [02:57<3:38:24, 26.58s/it]  2%|▏         | 8/500 [03:29<3:50:50, 28.15s/it]  2%|▏         | 9/500 [03:59<3:55:41, 28.80s/it]  2%|▏         | 10/500 [04:30<3:59:49, 29.37s/it]  2%|▏         | 11/500 [05:01<4:02:45, 29.79s/it]  2%|▏         | 12/500 [05:24<3:45:44, 27.76s/it]  3%|▎         | 13/500 [05:50<3:42:24, 27.40s/it]  3%|▎         | 14/500 [06:16<3:37:33, 26.86s/it]  3%|▎         | 15/500 [06:39<3:26:49, 25.59s/it]  3%|▎         | 16/500 [07:05<3:28:19, 25.83s/it]  3%|▎         | 17/500 [07:33<3:32:56, 26.45s/it]  4%|▎         | 18/500 [07:56<3:24:04, 25.40s/it]  4%|▍         | 19/500 [08:25<3:32:28, 26.50s/it]  4%|▍         | 20/500 [08:48<3:24:13, 25.53s/it]  4%|▍         | 21/500 [09:16<3:28:24, 26.10s/it]  4%|▍         | 22/500 [09:39<3:20:44, 25.20s/it]  5%|▍         | 23/500 [10:08<3:29:34, 26.36s/it]  5%|▍         | 24/500 [10:31<3:21:20, 25.38s/it]  5%|▌         | 25/500 [10:58<3:25:47, 25.99s/it]  5%|▌         | 26/500 [11:25<3:27:36, 26.28s/it]  5%|▌         | 27/500 [11:49<3:21:19, 25.54s/it]  6%|▌         | 28/500 [12:12<3:15:03, 24.80s/it]  6%|▌         | 29/500 [12:43<3:28:52, 26.61s/it]  6%|▌         | 30/500 [13:06<3:21:06, 25.67s/it]  6%|▌         | 31/500 [13:35<3:27:27, 26.54s/it]  6%|▋         | 32/500 [14:06<3:38:22, 28.00s/it]  7%|▋         | 33/500 [14:36<3:41:10, 28.42s/it]  7%|▋         | 34/500 [14:59<3:28:58, 26.91s/it]  7%|▋         | 35/500 [15:27<3:31:33, 27.30s/it]  7%|▋         | 36/500 [15:50<3:20:55, 25.98s/it]  7%|▋         | 37/500 [16:22<3:33:15, 27.64s/it]  8%|▊         | 38/500 [16:50<3:33:53, 27.78s/it]  8%|▊         | 39/500 [17:23<3:45:42, 29.38s/it]  8%|▊         | 40/500 [17:54<3:49:46, 29.97s/it]  8%|▊         | 41/500 [18:25<3:51:04, 30.21s/it]  8%|▊         | 42/500 [18:53<3:46:06, 29.62s/it]  9%|▊         | 43/500 [19:38<4:20:41, 34.23s/it]  9%|▉         | 44/500 [20:01<3:54:11, 30.81s/it]  9%|▉         | 45/500 [20:24<3:36:03, 28.49s/it]  9%|▉         | 46/500 [20:53<3:35:35, 28.49s/it]  9%|▉         | 47/500 [21:24<3:40:49, 29.25s/it] 10%|▉         | 48/500 [21:47<3:25:53, 27.33s/it] 10%|▉         | 49/500 [22:10<3:17:36, 26.29s/it] 10%|█         | 50/500 [22:36<3:16:26, 26.19s/it] 10%|█         | 51/500 [23:00<3:09:33, 25.33s/it] 10%|█         | 52/500 [23:29<3:18:06, 26.53s/it] 11%|█         | 53/500 [23:53<3:11:52, 25.75s/it] 11%|█         | 54/500 [24:17<3:06:48, 25.13s/it] 11%|█         | 55/500 [24:40<3:02:54, 24.66s/it] 11%|█         | 56/500 [25:10<3:13:02, 26.09s/it] 11%|█▏        | 57/500 [25:33<3:06:32, 25.27s/it] 12%|█▏        | 58/500 [26:00<3:10:18, 25.83s/it] 12%|█▏        | 59/500 [26:23<3:03:10, 24.92s/it] 12%|█▏        | 59/500 [26:23<3:17:15, 26.84s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.020 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▆▆▆▆▆▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▃▁▁▁▃▅▄▅▇▇▄▇▇▇█▇▇█▇▇██████████▇██▇████
wandb:     train_loss ▃▂▂▃▅▇█▂▂▁▁▁▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▁▁▁▂▃▃▃▂▃▄▆▃▅▄▄▇▄▄▇█▄▅▆▆█▆▆▆▅▇▄▄▅▅▄▆▆▅▆
wandb:       val_loss ▂▂▂▂▂▃▃▂▃▃▄▁▂▅▁▃▂▄▄▄▃▃▂▁▄▂▆▇▅▄▅▅█▄▃▆▇▁▃▃
wandb: 
wandb: Run summary:
wandb:          epoch 58
wandb:  learning_rate 0.00033
wandb: train_accuracy 0.97623
wandb:     train_loss 0.00057
wandb:   val_accuracy 0.35556
wandb:       val_loss 3.66958
wandb: 
wandb: 🚀 View run crimson-brook-2672 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qclezurf
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_143737-qclezurf/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_150443-9lfftb92
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sun-2673
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9lfftb92
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:43:28, 26.87s/it]  0%|          | 2/500 [00:50<3:29:08, 25.20s/it]  1%|          | 3/500 [01:14<3:24:13, 24.65s/it]  1%|          | 4/500 [01:42<3:32:50, 25.75s/it]  1%|          | 5/500 [02:06<3:28:10, 25.23s/it]  1%|          | 6/500 [02:34<3:34:45, 26.08s/it]  1%|▏         | 7/500 [02:58<3:27:49, 25.29s/it]  2%|▏         | 8/500 [03:28<3:40:05, 26.84s/it]  2%|▏         | 9/500 [03:52<3:32:23, 25.96s/it]  2%|▏         | 10/500 [04:21<3:39:26, 26.87s/it]  2%|▏         | 11/500 [04:46<3:36:24, 26.55s/it]  2%|▏         | 12/500 [05:12<3:32:25, 26.12s/it]  3%|▎         | 13/500 [05:36<3:27:30, 25.56s/it]  3%|▎         | 14/500 [06:01<3:26:28, 25.49s/it]  3%|▎         | 15/500 [06:26<3:24:18, 25.27s/it]  3%|▎         | 16/500 [06:49<3:19:05, 24.68s/it]  3%|▎         | 17/500 [07:19<3:30:56, 26.20s/it]  4%|▎         | 18/500 [07:42<3:23:28, 25.33s/it]  4%|▍         | 19/500 [08:10<3:28:18, 25.98s/it]  4%|▍         | 20/500 [08:35<3:26:09, 25.77s/it]  4%|▍         | 21/500 [09:12<3:51:47, 29.04s/it]  4%|▍         | 22/500 [09:35<3:37:57, 27.36s/it]  5%|▍         | 23/500 [10:04<3:41:29, 27.86s/it]  5%|▍         | 24/500 [10:36<3:50:48, 29.09s/it]  5%|▌         | 25/500 [11:05<3:50:11, 29.08s/it]  5%|▌         | 26/500 [11:34<3:49:49, 29.09s/it]  5%|▌         | 27/500 [12:05<3:51:55, 29.42s/it]  6%|▌         | 28/500 [12:29<3:40:17, 28.00s/it]  6%|▌         | 29/500 [12:54<3:31:05, 26.89s/it]  6%|▌         | 30/500 [13:18<3:25:18, 26.21s/it]  6%|▌         | 31/500 [13:42<3:20:23, 25.64s/it]  6%|▋         | 32/500 [14:09<3:22:12, 25.92s/it]  7%|▋         | 33/500 [14:33<3:18:11, 25.46s/it]  7%|▋         | 34/500 [14:58<3:16:44, 25.33s/it]  7%|▋         | 35/500 [15:22<3:12:28, 24.84s/it]  7%|▋         | 36/500 [15:49<3:16:46, 25.45s/it]  7%|▋         | 37/500 [16:15<3:18:39, 25.74s/it]  8%|▊         | 38/500 [16:42<3:19:09, 25.86s/it]  8%|▊         | 39/500 [17:05<3:13:45, 25.22s/it]  8%|▊         | 40/500 [17:36<3:25:11, 26.76s/it]  8%|▊         | 41/500 [18:02<3:24:17, 26.70s/it]  8%|▊         | 42/500 [18:26<3:17:46, 25.91s/it]  9%|▊         | 43/500 [18:52<3:16:02, 25.74s/it]  9%|▉         | 44/500 [19:18<3:17:01, 25.92s/it]  9%|▉         | 45/500 [19:41<3:10:39, 25.14s/it]  9%|▉         | 46/500 [20:13<3:25:43, 27.19s/it]  9%|▉         | 47/500 [20:37<3:17:42, 26.19s/it]  9%|▉         | 47/500 [20:37<3:18:48, 26.33s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.020 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▃▂▄▃▅▅▅▅▅▆▆▆▆▆▄▆▅▇▆▆▆▇▅▇▇▇▇▇▇▇▇▆▇▇█▇█▇▇
wandb:     train_loss ▄▃▃▃▃▃▃▆▅▃▃▃▃▃▃▃▃▂▂▂▂▃▂▂▂▂▁▂▁▂▂▁▃▁▂▂█▃▂▃
wandb:   val_accuracy ██▆▃▄▄▄▄▃▄▄▄▄▂▄▄▂▄▃▃▄▃▂▄▂▂▂▂▂▂▂▁▃▁▂▂▂▁▂▁
wandb:       val_loss ▃▃▄▃▂▃▂▂▃▂▅▃▅▄▂▂▄▂▂▆▅▅▅▄▅▃▁▅▅▄▂▂▆▆▇▅▂▆▆█
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.63299
wandb:     train_loss 0.78903
wandb:   val_accuracy 0.14444
wandb:       val_loss 2.62146
wandb: 
wandb: 🚀 View run sunny-sun-2673 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/9lfftb92
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_150443-9lfftb92/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_152604-632k1525
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-waterfall-2674
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/632k1525
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:38:55, 26.32s/it]  0%|          | 2/500 [00:51<3:30:43, 25.39s/it]  1%|          | 3/500 [01:15<3:26:20, 24.91s/it]  1%|          | 4/500 [01:39<3:23:24, 24.61s/it]  1%|          | 5/500 [02:09<3:37:29, 26.36s/it]  1%|          | 6/500 [02:33<3:31:45, 25.72s/it]  1%|▏         | 7/500 [03:03<3:42:59, 27.14s/it]  2%|▏         | 8/500 [03:27<3:33:50, 26.08s/it]  2%|▏         | 9/500 [03:56<3:42:11, 27.15s/it]  2%|▏         | 10/500 [04:20<3:33:41, 26.17s/it]  2%|▏         | 11/500 [04:48<3:36:37, 26.58s/it]  2%|▏         | 12/500 [05:13<3:31:39, 26.02s/it]  3%|▎         | 13/500 [05:37<3:26:55, 25.49s/it]  3%|▎         | 14/500 [06:05<3:33:39, 26.38s/it]  3%|▎         | 15/500 [06:29<3:27:21, 25.65s/it]  3%|▎         | 16/500 [07:02<3:43:11, 27.67s/it]  3%|▎         | 17/500 [07:28<3:40:01, 27.33s/it]  4%|▎         | 18/500 [07:52<3:31:20, 26.31s/it]  4%|▍         | 19/500 [08:21<3:36:27, 27.00s/it]  4%|▍         | 20/500 [08:46<3:32:25, 26.55s/it]  4%|▍         | 21/500 [09:11<3:26:38, 25.88s/it]  4%|▍         | 22/500 [09:35<3:23:43, 25.57s/it]  5%|▍         | 23/500 [10:05<3:34:07, 26.93s/it]  5%|▍         | 24/500 [10:41<3:53:39, 29.45s/it]  5%|▌         | 25/500 [11:14<4:02:38, 30.65s/it]  5%|▌         | 26/500 [11:48<4:08:36, 31.47s/it]  5%|▌         | 27/500 [12:21<4:12:41, 32.05s/it]  6%|▌         | 28/500 [12:54<4:15:26, 32.47s/it]  6%|▌         | 29/500 [13:28<4:16:43, 32.70s/it]  6%|▌         | 30/500 [13:52<3:57:18, 30.30s/it]  6%|▌         | 31/500 [14:21<3:53:06, 29.82s/it]  6%|▋         | 32/500 [14:46<3:39:50, 28.18s/it]  7%|▋         | 33/500 [15:16<3:44:34, 28.85s/it]  7%|▋         | 34/500 [15:45<3:45:26, 29.03s/it]  7%|▋         | 35/500 [16:10<3:34:05, 27.62s/it]  7%|▋         | 36/500 [16:39<3:37:02, 28.07s/it]  7%|▋         | 37/500 [17:03<3:27:41, 26.91s/it]  7%|▋         | 37/500 [17:03<3:33:28, 27.66s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.312 MB uploadedwandb: | 0.010 MB of 0.312 MB uploadedwandb: / 0.184 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▁▄▄▂▅▃▆▆▃▆▆▄▆▇▅▅▃▇▅▆▇▆▇█▆▇▇███▇████▇
wandb:     train_loss ▃▃▃▂▁▄▅▂▇▃▁▁█▁▁▃▁▇▁▁▁▃▁▁▁▁▂▁▁▁▁▁▄▁▁▁▂
wandb:   val_accuracy █▄▁▁▇▂▂▅█▁▆▅▂▄▅▃▄▄▅▄▅▅▄▆▇▄▆▅▇▇▇▆▆▇▆▆▇
wandb:       val_loss ▂▂▃▂▁▂█▄▄▅▃▄▁▅▇▅▂▃▂▆▁█▆▅▆▃▄▂▄▅▄▃▃▄▃▆▂
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 0.00026
wandb: train_accuracy 0.87519
wandb:     train_loss 0.51064
wandb:   val_accuracy 0.34
wandb:       val_loss 0.72078
wandb: 
wandb: 🚀 View run stellar-waterfall-2674 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/632k1525
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_152604-632k1525/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_154354-wyxda649
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-snowball-2675
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wyxda649
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:16<2:20:13, 16.86s/it]  0%|          | 2/500 [00:32<2:12:34, 15.97s/it]  1%|          | 3/500 [00:47<2:08:58, 15.57s/it]  1%|          | 4/500 [01:02<2:06:25, 15.29s/it]  1%|          | 5/500 [01:17<2:05:03, 15.16s/it]  1%|          | 6/500 [01:31<2:03:43, 15.03s/it]  1%|▏         | 7/500 [01:46<2:03:07, 14.98s/it]  2%|▏         | 8/500 [02:01<2:03:14, 15.03s/it]  2%|▏         | 9/500 [02:16<2:02:18, 14.95s/it]  2%|▏         | 10/500 [02:31<2:02:30, 15.00s/it]  2%|▏         | 11/500 [02:47<2:03:27, 15.15s/it]  2%|▏         | 12/500 [03:02<2:03:08, 15.14s/it]  3%|▎         | 13/500 [03:17<2:03:10, 15.18s/it]  3%|▎         | 14/500 [03:32<2:01:55, 15.05s/it]  3%|▎         | 15/500 [03:47<2:01:03, 14.98s/it]  3%|▎         | 16/500 [04:01<2:00:04, 14.89s/it]  3%|▎         | 17/500 [04:16<1:59:15, 14.81s/it]  4%|▎         | 18/500 [04:31<1:59:37, 14.89s/it]  4%|▍         | 19/500 [04:46<1:58:41, 14.81s/it]  4%|▍         | 20/500 [05:00<1:57:21, 14.67s/it]  4%|▍         | 21/500 [05:15<1:56:54, 14.64s/it]  4%|▍         | 22/500 [05:29<1:56:29, 14.62s/it]  5%|▍         | 23/500 [05:44<1:56:09, 14.61s/it]  5%|▍         | 24/500 [05:58<1:55:58, 14.62s/it]  5%|▌         | 25/500 [06:13<1:56:03, 14.66s/it]  5%|▌         | 26/500 [06:28<1:55:13, 14.59s/it]  5%|▌         | 27/500 [06:42<1:55:03, 14.59s/it]  6%|▌         | 28/500 [06:57<1:54:31, 14.56s/it]  6%|▌         | 29/500 [07:11<1:54:32, 14.59s/it]  6%|▌         | 30/500 [07:26<1:54:52, 14.67s/it]  6%|▌         | 31/500 [07:41<1:54:40, 14.67s/it]  6%|▋         | 32/500 [07:56<1:54:57, 14.74s/it]  7%|▋         | 33/500 [08:11<1:55:49, 14.88s/it]  7%|▋         | 33/500 [08:11<1:55:55, 14.89s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.308 MB uploadedwandb: | 0.010 MB of 0.308 MB uploadedwandb: / 0.137 MB of 0.308 MB uploadedwandb: - 0.308 MB of 0.308 MB uploadedwandb: \ 0.308 MB of 0.308 MB uploadedwandb: | 0.308 MB of 0.308 MB uploadedwandb: / 0.308 MB of 0.308 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁
wandb: train_accuracy ▁▂▅▆▅▃▃▇▃▆▇▆███▇█████▇██▇████████
wandb:     train_loss ▆▄▅▅▂▁▁▁▁▁▃█▂▁▁▁▁▅▂▁▁▁▁▁▂▁▂▁▁▁▁▁▁
wandb:   val_accuracy ▅▁▃█▂▁▂▇▁█▇▃▅▆▇▅▆▆▇▆▆▄█▇█▇▅▇▆▆▄▇▆
wandb:       val_loss ▂▂▂▃▃▃▄▁█▄▁▅▃▅▄▂▁▄▁▄▄▅█▅▁▁▅▄▅▄▄▃▅
wandb: 
wandb: Run summary:
wandb:          epoch 32
wandb:  learning_rate 0.00051
wandb: train_accuracy 0.99851
wandb:     train_loss 0.00675
wandb:   val_accuracy 0.33778
wandb:       val_loss 5.16453
wandb: 
wandb: 🚀 View run smart-snowball-2675 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/wyxda649
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_154354-wyxda649/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_155249-k7i4q6hc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-armadillo-2676
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/k7i4q6hc
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:29:06, 17.93s/it]  0%|          | 2/500 [00:33<2:15:00, 16.27s/it]  1%|          | 3/500 [00:47<2:09:10, 15.59s/it]  1%|          | 4/500 [01:02<2:05:05, 15.13s/it]  1%|          | 5/500 [01:16<2:02:36, 14.86s/it]  1%|          | 6/500 [01:31<2:01:59, 14.82s/it]  1%|▏         | 7/500 [01:46<2:01:19, 14.77s/it]  2%|▏         | 8/500 [02:00<2:01:10, 14.78s/it]  2%|▏         | 9/500 [02:15<2:00:53, 14.77s/it]  2%|▏         | 10/500 [02:34<2:11:31, 16.11s/it]  2%|▏         | 11/500 [02:53<2:18:42, 17.02s/it]  2%|▏         | 12/500 [03:12<2:23:40, 17.67s/it]  3%|▎         | 13/500 [03:32<2:27:27, 18.17s/it]  3%|▎         | 14/500 [03:46<2:18:10, 17.06s/it]  3%|▎         | 15/500 [04:01<2:11:42, 16.29s/it]  3%|▎         | 16/500 [04:15<2:07:08, 15.76s/it]  3%|▎         | 17/500 [04:30<2:04:22, 15.45s/it]  4%|▎         | 18/500 [04:44<2:01:44, 15.15s/it]  4%|▍         | 19/500 [04:59<2:00:21, 15.01s/it]  4%|▍         | 20/500 [05:14<1:59:11, 14.90s/it]  4%|▍         | 21/500 [05:28<1:58:00, 14.78s/it]  4%|▍         | 22/500 [05:43<1:56:51, 14.67s/it]  5%|▍         | 23/500 [05:57<1:55:50, 14.57s/it]  5%|▍         | 24/500 [06:11<1:55:05, 14.51s/it]  5%|▌         | 25/500 [06:26<1:55:02, 14.53s/it]  5%|▌         | 26/500 [06:41<1:54:59, 14.56s/it]  5%|▌         | 27/500 [06:55<1:54:26, 14.52s/it]  6%|▌         | 28/500 [07:09<1:53:55, 14.48s/it]  6%|▌         | 29/500 [07:24<1:53:41, 14.48s/it]  6%|▌         | 30/500 [07:38<1:53:26, 14.48s/it]  6%|▌         | 31/500 [07:53<1:53:47, 14.56s/it]  6%|▋         | 32/500 [08:08<1:53:12, 14.51s/it]  7%|▋         | 33/500 [08:22<1:52:43, 14.48s/it]  7%|▋         | 34/500 [08:37<1:52:39, 14.51s/it]  7%|▋         | 35/500 [08:51<1:52:33, 14.52s/it]  7%|▋         | 36/500 [09:06<1:52:59, 14.61s/it]  7%|▋         | 37/500 [09:21<1:52:56, 14.64s/it]  8%|▊         | 38/500 [09:35<1:52:51, 14.66s/it]  8%|▊         | 39/500 [09:50<1:52:54, 14.70s/it]  8%|▊         | 40/500 [10:05<1:52:19, 14.65s/it]  8%|▊         | 41/500 [10:19<1:52:06, 14.65s/it]  8%|▊         | 42/500 [10:34<1:51:22, 14.59s/it]  9%|▊         | 43/500 [10:48<1:51:03, 14.58s/it]  9%|▉         | 44/500 [11:03<1:51:47, 14.71s/it]  9%|▉         | 45/500 [11:18<1:51:32, 14.71s/it]  9%|▉         | 46/500 [11:32<1:50:39, 14.62s/it]  9%|▉         | 47/500 [11:47<1:49:56, 14.56s/it] 10%|▉         | 48/500 [12:01<1:49:27, 14.53s/it] 10%|▉         | 49/500 [12:16<1:49:03, 14.51s/it] 10%|█         | 50/500 [12:30<1:48:38, 14.48s/it] 10%|█         | 51/500 [12:45<1:48:59, 14.56s/it] 10%|█         | 52/500 [12:59<1:48:36, 14.55s/it] 11%|█         | 53/500 [13:14<1:48:19, 14.54s/it] 11%|█         | 54/500 [13:28<1:47:42, 14.49s/it] 11%|█         | 55/500 [13:43<1:47:23, 14.48s/it] 11%|█         | 56/500 [13:57<1:46:48, 14.43s/it] 11%|█▏        | 57/500 [14:12<1:48:20, 14.67s/it] 12%|█▏        | 58/500 [14:27<1:48:51, 14.78s/it] 12%|█▏        | 59/500 [14:42<1:48:06, 14.71s/it] 12%|█▏        | 60/500 [14:56<1:47:17, 14.63s/it] 12%|█▏        | 61/500 [15:11<1:47:02, 14.63s/it] 12%|█▏        | 62/500 [15:26<1:46:50, 14.64s/it] 13%|█▎        | 63/500 [15:40<1:46:18, 14.60s/it] 13%|█▎        | 64/500 [15:54<1:45:26, 14.51s/it] 13%|█▎        | 65/500 [16:10<1:46:54, 14.74s/it] 13%|█▎        | 66/500 [16:25<1:47:07, 14.81s/it] 13%|█▎        | 67/500 [16:39<1:46:16, 14.73s/it] 14%|█▎        | 68/500 [16:54<1:45:15, 14.62s/it] 14%|█▍        | 69/500 [17:08<1:44:21, 14.53s/it] 14%|█▍        | 70/500 [17:23<1:44:23, 14.57s/it] 14%|█▍        | 71/500 [17:37<1:43:47, 14.52s/it] 14%|█▍        | 72/500 [17:51<1:43:20, 14.49s/it] 15%|█▍        | 73/500 [18:06<1:43:26, 14.54s/it] 15%|█▍        | 74/500 [18:21<1:43:19, 14.55s/it] 15%|█▌        | 75/500 [18:35<1:42:47, 14.51s/it] 15%|█▌        | 76/500 [18:50<1:42:38, 14.53s/it] 15%|█▌        | 77/500 [19:04<1:42:42, 14.57s/it] 16%|█▌        | 78/500 [19:19<1:42:14, 14.54s/it] 16%|█▌        | 79/500 [19:36<1:46:43, 15.21s/it] 16%|█▌        | 80/500 [19:51<1:46:05, 15.16s/it] 16%|█▌        | 81/500 [20:05<1:44:29, 14.96s/it] 16%|█▋        | 82/500 [20:20<1:43:23, 14.84s/it] 17%|█▋        | 83/500 [20:34<1:42:54, 14.81s/it] 17%|█▋        | 84/500 [20:49<1:42:36, 14.80s/it] 17%|█▋        | 85/500 [21:06<1:47:05, 15.48s/it] 17%|█▋        | 86/500 [21:21<1:44:43, 15.18s/it] 17%|█▋        | 87/500 [21:35<1:42:58, 14.96s/it] 18%|█▊        | 88/500 [21:49<1:41:27, 14.77s/it] 18%|█▊        | 89/500 [22:04<1:40:31, 14.67s/it] 18%|█▊        | 90/500 [22:19<1:40:04, 14.65s/it] 18%|█▊        | 91/500 [22:33<1:39:50, 14.65s/it] 18%|█▊        | 92/500 [22:48<1:39:24, 14.62s/it] 19%|█▊        | 93/500 [23:02<1:39:01, 14.60s/it] 19%|█▉        | 94/500 [23:18<1:41:47, 15.04s/it] 19%|█▉        | 95/500 [23:33<1:40:21, 14.87s/it] 19%|█▉        | 96/500 [23:47<1:39:42, 14.81s/it] 19%|█▉        | 97/500 [24:02<1:39:00, 14.74s/it] 20%|█▉        | 98/500 [24:16<1:38:06, 14.64s/it] 20%|█▉        | 99/500 [24:32<1:40:39, 15.06s/it] 20%|█▉        | 99/500 [24:33<1:39:26, 14.88s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.318 MB uploadedwandb: / 0.141 MB of 0.318 MB uploadedwandb: - 0.318 MB of 0.318 MB uploadedwandb: \ 0.318 MB of 0.318 MB uploadedwandb: | 0.318 MB of 0.318 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ████▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▅▆▅▆▆▇▇▇▆▄██▇▇▇▇▇█▆▆▇▆▂█▅▆█▇▆▆▇█▆▆▅▆▇▇
wandb:     train_loss ▃▃▃▃▃▂▂▃▂▂▂▂▂▁▂▄▁▁▁▂▂▂▂▂█▂▂▃▂▁▂▃▂▁▃▁▁▃▂▁
wandb:   val_accuracy ▆▆▄▃▁▃▂▃▃▅▆▅▅▆▇▇▇▇▇▇▆▆█▇▅▇▅▅█▇▆▆▇█▆▆▄▇▇▆
wandb:       val_loss ▂▂▂▂▂▂▃▂▃▃▂▃▂▃▃▂▂▂▄▄▁▄▂▂█▃▃▄▂▃▂▄▄▁▂▂▂▃▁▃
wandb: 
wandb: Run summary:
wandb:          epoch 98
wandb:  learning_rate 1e-05
wandb: train_accuracy 0.69985
wandb:     train_loss 0.25728
wandb:   val_accuracy 0.36667
wandb:       val_loss 1.79333
wandb: 
wandb: 🚀 View run jolly-armadillo-2676 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/k7i4q6hc
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_155249-k7i4q6hc/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_161806-qr87ebka
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-shadow-2677
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qr87ebka
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:24<3:20:48, 24.15s/it]  0%|          | 2/500 [00:40<2:40:59, 19.40s/it]  1%|          | 3/500 [00:56<2:28:20, 17.91s/it]  1%|          | 4/500 [01:11<2:18:50, 16.79s/it]  1%|          | 5/500 [01:27<2:15:02, 16.37s/it]  1%|          | 6/500 [01:43<2:15:27, 16.45s/it]  1%|▏         | 7/500 [01:59<2:13:11, 16.21s/it]  2%|▏         | 8/500 [02:15<2:11:37, 16.05s/it]  2%|▏         | 9/500 [02:30<2:09:15, 15.80s/it]  2%|▏         | 10/500 [02:45<2:07:52, 15.66s/it]  2%|▏         | 11/500 [03:00<2:06:43, 15.55s/it]  2%|▏         | 12/500 [03:16<2:06:00, 15.49s/it]  3%|▎         | 13/500 [03:32<2:07:52, 15.76s/it]  3%|▎         | 14/500 [03:47<2:06:24, 15.61s/it]  3%|▎         | 15/500 [04:03<2:05:07, 15.48s/it]  3%|▎         | 16/500 [04:18<2:04:53, 15.48s/it]  3%|▎         | 17/500 [04:33<2:03:27, 15.34s/it]  4%|▎         | 18/500 [04:48<2:03:03, 15.32s/it]  4%|▍         | 19/500 [05:04<2:02:58, 15.34s/it]  4%|▍         | 20/500 [05:22<2:09:13, 16.15s/it]  4%|▍         | 21/500 [05:37<2:07:30, 15.97s/it]  4%|▍         | 22/500 [05:53<2:06:18, 15.86s/it]  5%|▍         | 23/500 [06:08<2:05:06, 15.74s/it]  5%|▍         | 24/500 [06:24<2:04:10, 15.65s/it]  5%|▌         | 25/500 [06:39<2:03:02, 15.54s/it]  5%|▌         | 26/500 [06:54<2:02:10, 15.46s/it]  5%|▌         | 27/500 [07:10<2:01:37, 15.43s/it]  6%|▌         | 28/500 [07:25<2:00:50, 15.36s/it]  6%|▌         | 29/500 [07:41<2:01:15, 15.45s/it]  6%|▌         | 30/500 [07:56<2:00:31, 15.39s/it]  6%|▌         | 31/500 [08:11<2:00:31, 15.42s/it]  6%|▋         | 32/500 [08:27<1:59:57, 15.38s/it]  7%|▋         | 33/500 [08:42<1:59:20, 15.33s/it]  7%|▋         | 34/500 [08:57<1:59:06, 15.33s/it]  7%|▋         | 35/500 [09:13<2:00:02, 15.49s/it]  7%|▋         | 36/500 [09:28<1:58:52, 15.37s/it]  7%|▋         | 37/500 [09:43<1:58:10, 15.31s/it]  8%|▊         | 38/500 [09:59<1:57:34, 15.27s/it]  8%|▊         | 39/500 [10:14<1:56:48, 15.20s/it]  8%|▊         | 40/500 [10:29<1:56:32, 15.20s/it]  8%|▊         | 41/500 [10:44<1:56:26, 15.22s/it]  8%|▊         | 42/500 [10:59<1:56:09, 15.22s/it]  9%|▊         | 43/500 [11:15<1:56:10, 15.25s/it]  9%|▉         | 44/500 [11:30<1:56:32, 15.34s/it]  9%|▉         | 45/500 [11:45<1:56:07, 15.31s/it]  9%|▉         | 46/500 [12:01<1:55:38, 15.28s/it]  9%|▉         | 47/500 [12:16<1:55:41, 15.32s/it] 10%|▉         | 48/500 [12:31<1:55:03, 15.27s/it] 10%|▉         | 49/500 [12:46<1:54:46, 15.27s/it] 10%|█         | 50/500 [13:01<1:53:55, 15.19s/it] 10%|█         | 51/500 [13:18<1:56:19, 15.54s/it] 10%|█         | 52/500 [13:34<1:58:01, 15.81s/it] 11%|█         | 53/500 [13:51<1:58:49, 15.95s/it] 11%|█         | 54/500 [14:07<1:59:56, 16.14s/it] 11%|█         | 55/500 [14:23<1:59:55, 16.17s/it] 11%|█         | 56/500 [14:40<2:00:55, 16.34s/it] 11%|█▏        | 57/500 [14:56<2:00:25, 16.31s/it] 12%|█▏        | 58/500 [15:12<1:58:12, 16.05s/it] 12%|█▏        | 59/500 [15:27<1:56:13, 15.81s/it] 12%|█▏        | 60/500 [15:43<1:55:17, 15.72s/it] 12%|█▏        | 61/500 [15:58<1:54:51, 15.70s/it] 12%|█▏        | 62/500 [16:14<1:54:10, 15.64s/it] 13%|█▎        | 63/500 [16:29<1:53:51, 15.63s/it] 13%|█▎        | 64/500 [16:45<1:53:21, 15.60s/it] 13%|█▎        | 65/500 [17:00<1:52:56, 15.58s/it] 13%|█▎        | 66/500 [17:20<2:02:22, 16.92s/it] 13%|█▎        | 67/500 [17:36<1:58:42, 16.45s/it] 13%|█▎        | 67/500 [17:36<1:53:46, 15.76s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.317 MB uploadedwandb: | 0.010 MB of 0.317 MB uploadedwandb: / 0.234 MB of 0.317 MB uploadedwandb: - 0.317 MB of 0.317 MB uploadedwandb: \ 0.317 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb: / 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁
wandb: train_accuracy ▁▅▃▃▄▄▄▅▅▃▅▅▆▅▆▅▆▆▆▅▆▇▆▇▇▇▅▆▇▇████▇▇█▆██
wandb:     train_loss ▂▂▂▃▂▂▂▂▂▂▂▃▂▁▁█▁▁▁▁▂▁▁▁▁▁▅▁▁▁▁▁▁▁▁▁▁▆▁▁
wandb:   val_accuracy ▅▅▁▇▃▃▄▅▂▄▅▃▃▃▃▃▃▄▅▅█▇▆█▅▇▆█▇█▇▇██▇██▆██
wandb:       val_loss ▂▂▂▂▁▂▂▄▅▃▂▄▅▄▄▁▂▁▂▁▄▆▅▆▁▁▄▄▃█▁▂▁▄▂▁▅▂▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 66
wandb:  learning_rate 0.00013
wandb: train_accuracy 0.95394
wandb:     train_loss 0.00485
wandb:   val_accuracy 0.47111
wandb:       val_loss 4.78322
wandb: 
wandb: 🚀 View run fancy-shadow-2677 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qr87ebka
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_161806-qr87ebka/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_163640-fvprcw3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-river-2678
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fvprcw3i
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:28:56, 17.91s/it]  0%|          | 2/500 [00:33<2:15:36, 16.34s/it]  1%|          | 3/500 [00:48<2:11:16, 15.85s/it]  1%|          | 4/500 [01:03<2:07:01, 15.36s/it]  1%|          | 5/500 [01:17<2:04:31, 15.09s/it]  1%|          | 6/500 [01:32<2:02:45, 14.91s/it]  1%|▏         | 7/500 [01:47<2:02:16, 14.88s/it]  2%|▏         | 8/500 [02:01<2:01:56, 14.87s/it]  2%|▏         | 9/500 [02:16<2:01:24, 14.84s/it]  2%|▏         | 10/500 [02:36<2:13:06, 16.30s/it]  2%|▏         | 11/500 [02:55<2:21:32, 17.37s/it]  2%|▏         | 12/500 [03:15<2:25:34, 17.90s/it]  3%|▎         | 13/500 [03:34<2:29:23, 18.40s/it]  3%|▎         | 14/500 [03:49<2:19:58, 17.28s/it]  3%|▎         | 15/500 [04:04<2:13:23, 16.50s/it]  3%|▎         | 16/500 [04:18<2:08:40, 15.95s/it]  3%|▎         | 17/500 [04:33<2:05:17, 15.56s/it]  4%|▎         | 18/500 [04:48<2:03:20, 15.35s/it]  4%|▍         | 19/500 [05:03<2:02:31, 15.28s/it]  4%|▍         | 20/500 [05:18<2:01:43, 15.22s/it]  4%|▍         | 21/500 [05:33<2:00:30, 15.10s/it]  4%|▍         | 22/500 [05:48<1:59:38, 15.02s/it]  5%|▍         | 23/500 [06:02<1:58:16, 14.88s/it]  5%|▍         | 24/500 [06:17<1:58:08, 14.89s/it]  5%|▌         | 25/500 [06:32<1:57:49, 14.88s/it]  5%|▌         | 26/500 [06:47<1:57:09, 14.83s/it]  5%|▌         | 27/500 [07:01<1:56:28, 14.77s/it]  6%|▌         | 28/500 [07:16<1:56:09, 14.77s/it]  6%|▌         | 29/500 [07:31<1:55:55, 14.77s/it]  6%|▌         | 30/500 [07:46<1:55:42, 14.77s/it]  6%|▌         | 31/500 [08:00<1:55:37, 14.79s/it]  6%|▋         | 32/500 [08:15<1:54:54, 14.73s/it]  7%|▋         | 33/500 [08:30<1:55:04, 14.78s/it]  7%|▋         | 34/500 [08:46<1:58:14, 15.22s/it]  7%|▋         | 35/500 [09:01<1:56:56, 15.09s/it]  7%|▋         | 36/500 [09:16<1:56:17, 15.04s/it]  7%|▋         | 37/500 [09:31<1:55:54, 15.02s/it]  8%|▊         | 38/500 [09:45<1:54:41, 14.89s/it]  8%|▊         | 39/500 [10:00<1:54:02, 14.84s/it]  8%|▊         | 40/500 [10:15<1:53:06, 14.75s/it]  8%|▊         | 41/500 [10:29<1:52:26, 14.70s/it]  8%|▊         | 42/500 [10:44<1:51:44, 14.64s/it]  9%|▊         | 43/500 [10:59<1:52:18, 14.75s/it]  9%|▉         | 44/500 [11:14<1:52:29, 14.80s/it]  9%|▉         | 45/500 [11:28<1:51:59, 14.77s/it]  9%|▉         | 46/500 [11:43<1:51:18, 14.71s/it]  9%|▉         | 47/500 [11:58<1:51:24, 14.76s/it] 10%|▉         | 48/500 [12:12<1:50:43, 14.70s/it] 10%|▉         | 49/500 [12:27<1:50:50, 14.75s/it] 10%|█         | 50/500 [12:42<1:50:40, 14.76s/it] 10%|█         | 51/500 [12:56<1:49:45, 14.67s/it] 10%|█         | 52/500 [13:11<1:49:43, 14.69s/it] 11%|█         | 53/500 [13:26<1:49:35, 14.71s/it] 11%|█         | 54/500 [13:42<1:51:45, 15.03s/it] 11%|█         | 55/500 [13:57<1:51:11, 14.99s/it] 11%|█         | 56/500 [14:11<1:49:40, 14.82s/it] 11%|█▏        | 57/500 [14:26<1:49:20, 14.81s/it] 12%|█▏        | 58/500 [14:41<1:48:50, 14.77s/it] 12%|█▏        | 59/500 [14:55<1:48:15, 14.73s/it] 12%|█▏        | 60/500 [15:10<1:48:04, 14.74s/it] 12%|█▏        | 61/500 [15:25<1:47:51, 14.74s/it] 12%|█▏        | 62/500 [15:39<1:47:31, 14.73s/it] 13%|█▎        | 63/500 [15:56<1:51:56, 15.37s/it] 13%|█▎        | 64/500 [16:11<1:50:44, 15.24s/it] 13%|█▎        | 65/500 [16:26<1:49:17, 15.07s/it] 13%|█▎        | 65/500 [16:26<1:50:01, 15.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.314 MB uploadedwandb: - 0.170 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ██████▆▆▆▆▆▆▅▅▅▅▅▅▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁
wandb: train_accuracy ▁▂▁▇▇▅▁▇█▇▆█████▆█▇██▇██▇██▇█▇▇█▇█▇██▇██
wandb:     train_loss ▄▄█▁▂▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▄▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▃▂▃▆▆▁▂▇▆▇▇▆▆▆▆▇▆█▄██▇██▇█▇▆▇█████▇▇▇█▇▇
wandb:       val_loss ▁▁▂▂▁▃▁▂▄▃▁▂▄▃▆▁▂▂▂▂▂▂▁▂▁▅▁▂▆▃▅▁▂▁▂▂▁▃▇█
wandb: 
wandb: Run summary:
wandb:          epoch 64
wandb:  learning_rate 0.00026
wandb: train_accuracy 0.98068
wandb:     train_loss 0.12807
wandb:   val_accuracy 0.52222
wandb:       val_loss 20.79018
wandb: 
wandb: 🚀 View run legendary-river-2678 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fvprcw3i
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_163640-fvprcw3i/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_165356-ustr0nno
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-glade-2679
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ustr0nno
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:30:06, 18.05s/it]  0%|          | 2/500 [00:33<2:18:11, 16.65s/it]  1%|          | 3/500 [00:49<2:13:44, 16.15s/it]  1%|          | 4/500 [01:04<2:09:42, 15.69s/it]  1%|          | 5/500 [01:19<2:07:01, 15.40s/it]  1%|          | 6/500 [01:33<2:04:44, 15.15s/it]  1%|▏         | 7/500 [01:48<2:03:27, 15.02s/it]  2%|▏         | 8/500 [02:03<2:02:33, 14.95s/it]  2%|▏         | 9/500 [02:17<2:01:15, 14.82s/it]  2%|▏         | 10/500 [02:32<2:00:35, 14.77s/it]  2%|▏         | 11/500 [02:47<2:00:17, 14.76s/it]  2%|▏         | 12/500 [03:02<2:00:01, 14.76s/it]  3%|▎         | 13/500 [03:16<1:59:50, 14.77s/it]  3%|▎         | 14/500 [03:33<2:04:26, 15.36s/it]  3%|▎         | 15/500 [03:48<2:02:47, 15.19s/it]  3%|▎         | 16/500 [04:02<2:01:09, 15.02s/it]  3%|▎         | 17/500 [04:18<2:02:09, 15.18s/it]  4%|▎         | 18/500 [04:33<2:00:14, 14.97s/it]  4%|▍         | 19/500 [04:47<1:59:04, 14.85s/it]  4%|▍         | 20/500 [05:02<1:58:32, 14.82s/it]  4%|▍         | 21/500 [05:16<1:57:52, 14.76s/it]  4%|▍         | 22/500 [05:36<2:09:11, 16.22s/it]  5%|▍         | 23/500 [05:51<2:05:04, 15.73s/it]  5%|▍         | 24/500 [06:05<2:02:38, 15.46s/it]  5%|▌         | 25/500 [06:20<2:00:40, 15.24s/it]  5%|▌         | 26/500 [06:35<1:59:12, 15.09s/it]  5%|▌         | 27/500 [06:50<1:57:52, 14.95s/it]  6%|▌         | 28/500 [07:04<1:56:58, 14.87s/it]  6%|▌         | 29/500 [07:19<1:56:48, 14.88s/it]  6%|▌         | 30/500 [07:34<1:55:56, 14.80s/it]  6%|▌         | 31/500 [07:48<1:54:57, 14.71s/it]  6%|▋         | 32/500 [08:03<1:54:20, 14.66s/it]  7%|▋         | 33/500 [08:17<1:53:53, 14.63s/it]  7%|▋         | 34/500 [08:32<1:53:24, 14.60s/it]  7%|▋         | 35/500 [08:49<1:57:59, 15.23s/it]  7%|▋         | 36/500 [09:03<1:56:26, 15.06s/it]  7%|▋         | 37/500 [09:18<1:55:18, 14.94s/it]  8%|▊         | 38/500 [09:33<1:54:22, 14.85s/it]  8%|▊         | 39/500 [09:52<2:04:48, 16.24s/it]  8%|▊         | 40/500 [10:07<2:00:59, 15.78s/it]  8%|▊         | 40/500 [10:07<1:56:24, 15.18s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.316 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.232 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate █████████▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▁▄▄▄▅▅▆▆▆▆▇▇▇▇▇▅█▇██▇▇▇███▇█████▇▇▇▄▅█▇
wandb:     train_loss ▅▅▄▃▄▄▃▄▄▃▄▃▃▃▄▂▃▄▃▂▃▂▄▄▃▁▅▂▂▁▁▁▁▃▂▂▇█▃▂
wandb:   val_accuracy ▇▇▇▅▂▃▄▃▄▄▁▅▂▃▃▁▅▃▄▅▄▃▃▃▄▅▅▆▄▅▄▅▅▇▇▇▇▇▇█
wandb:       val_loss ▃▃▃▃▂▃▃▃▅▅▄▄▂▅▄▇▃▄▃▃█▄▇▁▃▂▅▅▄▅▄▃▅▅█▅▃▄▂▂
wandb: 
wandb: Run summary:
wandb:          epoch 39
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.70728
wandb:     train_loss 0.50826
wandb:   val_accuracy 0.38667
wandb:       val_loss 0.97307
wandb: 
wandb: 🚀 View run wild-glade-2679 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ustr0nno
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_165356-ustr0nno/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_170453-ats17nt8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-wood-2680
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ats17nt8
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:39:31, 19.18s/it]  0%|          | 2/500 [00:34<2:17:55, 16.62s/it]  1%|          | 3/500 [00:49<2:11:36, 15.89s/it]  1%|          | 4/500 [01:03<2:06:47, 15.34s/it]  1%|          | 5/500 [01:18<2:04:02, 15.03s/it]  1%|          | 6/500 [01:32<2:02:14, 14.85s/it]  1%|▏         | 7/500 [01:47<2:01:07, 14.74s/it]  2%|▏         | 8/500 [02:01<1:59:42, 14.60s/it]  2%|▏         | 9/500 [02:15<1:58:29, 14.48s/it]  2%|▏         | 10/500 [02:29<1:57:48, 14.43s/it]  2%|▏         | 11/500 [02:44<1:57:28, 14.41s/it]  2%|▏         | 12/500 [03:03<2:08:12, 15.76s/it]  3%|▎         | 13/500 [03:17<2:05:23, 15.45s/it]  3%|▎         | 14/500 [03:32<2:02:50, 15.17s/it]  3%|▎         | 15/500 [03:51<2:11:47, 16.30s/it]  3%|▎         | 16/500 [04:10<2:17:33, 17.05s/it]  3%|▎         | 17/500 [04:28<2:21:44, 17.61s/it]  4%|▎         | 18/500 [04:47<2:24:31, 17.99s/it]  4%|▍         | 19/500 [05:06<2:26:26, 18.27s/it]  4%|▍         | 20/500 [05:25<2:27:40, 18.46s/it]  4%|▍         | 21/500 [05:39<2:17:24, 17.21s/it]  4%|▍         | 22/500 [05:54<2:10:19, 16.36s/it]  5%|▍         | 23/500 [06:08<2:05:01, 15.73s/it]  5%|▍         | 24/500 [06:23<2:01:41, 15.34s/it]  5%|▌         | 25/500 [06:37<1:59:20, 15.07s/it]  5%|▌         | 26/500 [06:52<1:57:50, 14.92s/it]  5%|▌         | 27/500 [07:06<1:55:59, 14.71s/it]  6%|▌         | 28/500 [07:20<1:55:17, 14.66s/it]  6%|▌         | 29/500 [07:35<1:55:11, 14.67s/it]  6%|▌         | 30/500 [07:49<1:54:08, 14.57s/it]  6%|▌         | 31/500 [08:04<1:53:19, 14.50s/it]  6%|▋         | 32/500 [08:18<1:52:54, 14.48s/it]  7%|▋         | 33/500 [08:32<1:52:33, 14.46s/it]  7%|▋         | 34/500 [08:47<1:52:05, 14.43s/it]  7%|▋         | 35/500 [09:02<1:52:34, 14.53s/it]  7%|▋         | 36/500 [09:16<1:52:44, 14.58s/it]  7%|▋         | 37/500 [09:31<1:52:48, 14.62s/it]  8%|▊         | 38/500 [09:46<1:53:04, 14.68s/it]  8%|▊         | 39/500 [10:00<1:52:06, 14.59s/it]  8%|▊         | 40/500 [10:15<1:51:52, 14.59s/it]  8%|▊         | 41/500 [10:30<1:51:55, 14.63s/it]  8%|▊         | 42/500 [10:44<1:51:03, 14.55s/it]  9%|▊         | 43/500 [10:59<1:51:14, 14.61s/it]  9%|▉         | 44/500 [11:13<1:51:14, 14.64s/it]  9%|▉         | 45/500 [11:28<1:50:58, 14.63s/it]  9%|▉         | 46/500 [11:43<1:50:50, 14.65s/it]  9%|▉         | 47/500 [11:57<1:50:18, 14.61s/it] 10%|▉         | 48/500 [12:11<1:49:22, 14.52s/it] 10%|▉         | 49/500 [12:26<1:48:46, 14.47s/it] 10%|█         | 50/500 [12:40<1:48:38, 14.49s/it] 10%|█         | 51/500 [12:55<1:48:24, 14.49s/it] 10%|█         | 52/500 [13:09<1:47:27, 14.39s/it] 11%|█         | 53/500 [13:24<1:47:35, 14.44s/it] 11%|█         | 54/500 [13:43<1:57:38, 15.83s/it] 11%|█         | 55/500 [13:57<1:54:04, 15.38s/it] 11%|█         | 56/500 [14:11<1:51:41, 15.09s/it] 11%|█▏        | 57/500 [14:26<1:50:53, 15.02s/it] 12%|█▏        | 58/500 [14:40<1:48:52, 14.78s/it] 12%|█▏        | 59/500 [14:59<1:57:34, 16.00s/it] 12%|█▏        | 59/500 [15:04<1:52:38, 15.33s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.317 MB uploadedwandb: / 0.020 MB of 0.317 MB uploadedwandb: - 0.233 MB of 0.317 MB uploadedwandb: \ 0.233 MB of 0.317 MB uploadedwandb: | 0.317 MB of 0.317 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:  learning_rate ███████▆▆▆▆▆▆▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁
wandb: train_accuracy ▂▁▂▂▁▂▂▃▄▁▆▂▅▃▇▅▇▅▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇
wandb:     train_loss ▃▃▃▂▇▇▆▂▁▇▂▃█▁▁▃▂▃▁▁▁▃▃▃▂▃▁▁▁▁▁▁▁▁▁▁█▁▂▁
wandb:   val_accuracy ▁▃▁▅▃▂▃▃▆▃█▆▇▇█▅▆▅▅▃▄▄▅▅▄▆▅▆▅▆▅▆▆▆▆▆▆▆▆▆
wandb:       val_loss ▂▂▂▂▂▂▃▂▃▅▄▂▃▄▂▇▅▁▃▆▂▂▃▃▃▃▁▂██▂▄▄█▁▃▁▂▁▄
wandb: 
wandb: Run summary:
wandb:          epoch 58
wandb:  learning_rate 0.00016
wandb: train_accuracy 0.86627
wandb:     train_loss 0.00414
wandb:   val_accuracy 0.46889
wandb:       val_loss 3.68651
wandb: 
wandb: 🚀 View run still-wood-2680 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ats17nt8
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_170453-ats17nt8/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_172044-f3ur0gqy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-vortex-2681
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/f3ur0gqy
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:19<2:39:37, 19.19s/it]  0%|          | 2/500 [00:33<2:17:53, 16.61s/it]  1%|          | 3/500 [00:49<2:12:06, 15.95s/it]  1%|          | 4/500 [01:03<2:07:05, 15.37s/it]  1%|          | 5/500 [01:18<2:04:22, 15.08s/it]  1%|          | 6/500 [01:32<2:01:51, 14.80s/it]  1%|▏         | 7/500 [01:46<2:00:30, 14.67s/it]  2%|▏         | 8/500 [02:01<1:59:25, 14.56s/it]  2%|▏         | 9/500 [02:15<1:58:24, 14.47s/it]  2%|▏         | 10/500 [02:30<1:58:56, 14.56s/it]  2%|▏         | 11/500 [02:44<1:57:56, 14.47s/it]  2%|▏         | 12/500 [02:58<1:57:17, 14.42s/it]  3%|▎         | 13/500 [03:17<2:06:41, 15.61s/it]  3%|▎         | 14/500 [03:31<2:03:15, 15.22s/it]  3%|▎         | 15/500 [03:45<1:59:59, 14.85s/it]  3%|▎         | 16/500 [03:59<1:58:32, 14.69s/it]  3%|▎         | 17/500 [04:14<1:57:32, 14.60s/it]  4%|▎         | 18/500 [04:28<1:56:20, 14.48s/it]  4%|▍         | 19/500 [04:42<1:55:54, 14.46s/it]  4%|▍         | 20/500 [04:57<1:55:07, 14.39s/it]  4%|▍         | 21/500 [05:11<1:54:40, 14.37s/it]  4%|▍         | 22/500 [05:25<1:54:00, 14.31s/it]  5%|▍         | 23/500 [05:41<1:57:21, 14.76s/it]  5%|▍         | 24/500 [05:55<1:56:05, 14.63s/it]  5%|▌         | 25/500 [06:09<1:54:52, 14.51s/it]  5%|▌         | 26/500 [06:24<1:53:57, 14.43s/it]  5%|▌         | 27/500 [06:38<1:52:34, 14.28s/it]  6%|▌         | 28/500 [06:52<1:51:58, 14.23s/it]  6%|▌         | 29/500 [07:06<1:52:19, 14.31s/it]  6%|▌         | 30/500 [07:20<1:50:45, 14.14s/it]  6%|▌         | 31/500 [07:34<1:50:10, 14.09s/it]  6%|▋         | 32/500 [07:48<1:49:30, 14.04s/it]  7%|▋         | 33/500 [08:02<1:49:31, 14.07s/it]  7%|▋         | 34/500 [08:16<1:49:49, 14.14s/it]  7%|▋         | 35/500 [08:30<1:49:35, 14.14s/it]  7%|▋         | 36/500 [08:45<1:49:24, 14.15s/it]  7%|▋         | 37/500 [08:59<1:49:47, 14.23s/it]  8%|▊         | 38/500 [09:13<1:49:38, 14.24s/it]  8%|▊         | 39/500 [09:27<1:49:02, 14.19s/it]  8%|▊         | 40/500 [09:41<1:48:43, 14.18s/it]  8%|▊         | 41/500 [09:56<1:48:15, 14.15s/it]  8%|▊         | 42/500 [10:10<1:48:04, 14.16s/it]  8%|▊         | 42/500 [10:10<1:50:54, 14.53s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.316 MB uploadedwandb: / 0.020 MB of 0.316 MB uploadedwandb: - 0.029 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb: | 0.316 MB of 0.316 MB uploadedwandb: / 0.316 MB of 0.316 MB uploadedwandb: - 0.316 MB of 0.316 MB uploadedwandb: \ 0.316 MB of 0.316 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁
wandb: train_accuracy ▁▄▃▅▅▃█▅▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:     train_loss ▂▁▂▁▂▁▁▁▁▁▁▁▃▁▁▄▃▃▁▃▄▃▁▁▃▁▃▃▃▃▃▃▄█▅▃▃▁▄▁
wandb:   val_accuracy ▅▁▃▄▃▁▃█▄▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅
wandb:       val_loss ▂▂▂▂▂▂▃▁▅▃▂▃▂█▃▃▃▅▂▂▂▄▆▂▁▂▃▃▂▄▂▃▂▃▄▃▄▂▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 41
wandb:  learning_rate 0.00041
wandb: train_accuracy 0.35364
wandb:     train_loss 0.01867
wandb:   val_accuracy 0.33111
wandb:       val_loss 4.35866
wandb: 
wandb: 🚀 View run kind-vortex-2681 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/f3ur0gqy
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_172044-f3ur0gqy/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_173144-7c90yp6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-jazz-2682
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/7c90yp6t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:18<2:35:56, 18.75s/it]  0%|          | 2/500 [00:33<2:15:26, 16.32s/it]  1%|          | 3/500 [00:47<2:07:58, 15.45s/it]  1%|          | 4/500 [01:01<2:02:40, 14.84s/it]  1%|          | 5/500 [01:16<2:00:53, 14.65s/it]  1%|          | 6/500 [01:30<1:59:15, 14.49s/it]  1%|▏         | 7/500 [01:44<1:57:34, 14.31s/it]  2%|▏         | 8/500 [01:58<1:56:30, 14.21s/it]  2%|▏         | 9/500 [02:11<1:55:04, 14.06s/it]  2%|▏         | 10/500 [02:25<1:54:19, 14.00s/it]  2%|▏         | 11/500 [02:39<1:54:42, 14.08s/it]  2%|▏         | 12/500 [02:55<1:57:32, 14.45s/it]  3%|▎         | 13/500 [03:09<1:56:03, 14.30s/it]  3%|▎         | 14/500 [03:23<1:54:37, 14.15s/it]  3%|▎         | 15/500 [03:37<1:54:11, 14.13s/it]  3%|▎         | 16/500 [03:51<1:53:42, 14.10s/it]  3%|▎         | 17/500 [04:05<1:53:33, 14.11s/it]  4%|▎         | 18/500 [04:19<1:54:05, 14.20s/it]  4%|▍         | 19/500 [04:33<1:53:49, 14.20s/it]  4%|▍         | 20/500 [04:47<1:52:59, 14.12s/it]  4%|▍         | 21/500 [05:01<1:52:23, 14.08s/it]  4%|▍         | 22/500 [05:17<1:56:36, 14.64s/it]  5%|▍         | 23/500 [05:32<1:56:03, 14.60s/it]  5%|▍         | 24/500 [05:46<1:54:30, 14.43s/it]  5%|▌         | 25/500 [05:59<1:52:27, 14.21s/it]  5%|▌         | 26/500 [06:13<1:51:17, 14.09s/it]  5%|▌         | 27/500 [06:27<1:50:44, 14.05s/it]  6%|▌         | 28/500 [06:41<1:50:20, 14.03s/it]  6%|▌         | 29/500 [06:55<1:50:27, 14.07s/it]  6%|▌         | 30/500 [07:09<1:50:15, 14.08s/it]  6%|▌         | 31/500 [07:24<1:50:24, 14.12s/it]  6%|▋         | 32/500 [07:38<1:49:46, 14.07s/it]  7%|▋         | 33/500 [07:52<1:49:18, 14.04s/it]  7%|▋         | 34/500 [08:06<1:48:59, 14.03s/it]  7%|▋         | 34/500 [08:06<1:51:03, 14.30s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.021 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁
wandb: train_accuracy ▁▁▂▁▆▁▅▁▁▇▁▁▃▁▁▄▁▁▃▁▁▅▃█▁▁▁▄▁▁▄▂▃▁
wandb:     train_loss ▂▂▁▁▁▁▁▂▁▁█▅▁▂▃▁▂▁▂▁▂▁▁▁▂▁▃▁▃▄▂▁▁▁
wandb:   val_accuracy ▆▆▆▅▅▅▃▆▅▇▅▅▂▆▆▂▅▅▆▆▆▆▂█▅▅▆▁▆▅▁▄▁▅
wandb:       val_loss ▁▁▂▁▁▁▂▂▃▂█▃▂▃▃▂▁▁▁▃▂▂▁▂▂▂▃▂▄▃▁▃▂▄
wandb: 
wandb: Run summary:
wandb:          epoch 33
wandb:  learning_rate 5e-05
wandb: train_accuracy 0.33581
wandb:     train_loss 0.0
wandb:   val_accuracy 0.32222
wandb:       val_loss 5.86338
wandb: 
wandb: 🚀 View run summer-jazz-2682 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/7c90yp6t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_173144-7c90yp6t/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_174038-36dd601t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-salad-2683
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/36dd601t
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:17<2:29:41, 18.00s/it]  0%|          | 2/500 [00:33<2:19:29, 16.81s/it]  1%|          | 3/500 [00:48<2:12:08, 15.95s/it]  1%|          | 4/500 [01:03<2:07:24, 15.41s/it]  1%|          | 5/500 [01:17<2:04:20, 15.07s/it]  1%|          | 6/500 [01:37<2:16:02, 16.52s/it]  1%|▏         | 7/500 [01:56<2:22:37, 17.36s/it]  2%|▏         | 8/500 [02:10<2:14:36, 16.42s/it]  2%|▏         | 9/500 [02:25<2:08:58, 15.76s/it]  2%|▏         | 10/500 [02:44<2:17:01, 16.78s/it]  2%|▏         | 11/500 [03:03<2:21:58, 17.42s/it]  2%|▏         | 12/500 [03:17<2:13:51, 16.46s/it]  3%|▎         | 13/500 [03:36<2:19:23, 17.17s/it]  3%|▎         | 14/500 [03:50<2:12:23, 16.34s/it]  3%|▎         | 15/500 [04:04<2:07:27, 15.77s/it]  3%|▎         | 16/500 [04:19<2:04:10, 15.39s/it]  3%|▎         | 17/500 [04:34<2:01:48, 15.13s/it]  4%|▎         | 18/500 [04:48<1:59:46, 14.91s/it]  4%|▍         | 19/500 [05:02<1:58:33, 14.79s/it]  4%|▍         | 20/500 [05:17<1:56:40, 14.58s/it]  4%|▍         | 21/500 [05:31<1:55:31, 14.47s/it]  4%|▍         | 22/500 [05:45<1:54:55, 14.43s/it]  5%|▍         | 23/500 [05:59<1:54:29, 14.40s/it]  5%|▍         | 24/500 [06:14<1:54:35, 14.44s/it]  5%|▌         | 25/500 [06:28<1:54:15, 14.43s/it]  5%|▌         | 26/500 [06:43<1:54:02, 14.44s/it]  5%|▌         | 27/500 [06:57<1:53:18, 14.37s/it]  6%|▌         | 28/500 [07:11<1:53:02, 14.37s/it]  6%|▌         | 29/500 [07:26<1:52:46, 14.37s/it]  6%|▌         | 30/500 [07:40<1:53:02, 14.43s/it]  6%|▌         | 31/500 [07:54<1:52:10, 14.35s/it]  6%|▋         | 32/500 [08:09<1:51:20, 14.27s/it]  7%|▋         | 33/500 [08:23<1:50:53, 14.25s/it]  7%|▋         | 34/500 [08:37<1:50:58, 14.29s/it]  7%|▋         | 35/500 [08:52<1:51:33, 14.40s/it]  7%|▋         | 36/500 [09:06<1:51:46, 14.45s/it]  7%|▋         | 37/500 [09:21<1:51:37, 14.47s/it]  8%|▊         | 38/500 [09:35<1:51:01, 14.42s/it]  8%|▊         | 39/500 [09:49<1:50:31, 14.39s/it]  8%|▊         | 40/500 [10:04<1:50:43, 14.44s/it]  8%|▊         | 41/500 [10:19<1:50:53, 14.49s/it]  8%|▊         | 42/500 [10:33<1:50:52, 14.53s/it]  8%|▊         | 42/500 [10:33<1:55:11, 15.09s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.138 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██
wandb:  learning_rate █████████▆▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▂▁▁
wandb: train_accuracy ▄▄▇█▃▁▄▃▅▁▇▆▄▁▅▅▂█▂▃▄▃▅▆▄▄▄▄▄▄▅▃▇▃▄▃▃▅▃▄
wandb:     train_loss ▃▃▃▂▃▅▂▃▂▃▁▂▇▂▁▃▂▃▂▃▆▇▁▂▄▁▃▄▄▂▇█▃█▇▆█▁▆▁
wandb:   val_accuracy ▄▅▁▂▅▅▅▄▆▃█▅▅▅▆▆▅▆▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▆▅▅
wandb:       val_loss ▂▂▂▂▂▂▁▂▄▃▁▃▁▅▃▃▃▄▂▂▄▇█▃▁▃▅▄▃▅▂▃▄▃▅▅▄▂▃▄
wandb: 
wandb: Run summary:
wandb:          epoch 41
wandb:  learning_rate 0.0002
wandb: train_accuracy 0.38187
wandb:     train_loss 0.08888
wandb:   val_accuracy 0.41556
wandb:       val_loss 2.56861
wandb: 
wandb: 🚀 View run flowing-salad-2683 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/36dd601t
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_174038-36dd601t/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_175158-jhxq4jps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-cloud-2684
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jhxq4jps
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:37:34, 26.16s/it]  0%|          | 2/500 [00:48<3:20:30, 24.16s/it]  1%|          | 3/500 [01:11<3:14:18, 23.46s/it]  1%|          | 4/500 [01:35<3:14:02, 23.47s/it]  1%|          | 5/500 [02:05<3:33:38, 25.90s/it]  1%|          | 6/500 [02:27<3:24:11, 24.80s/it]  1%|▏         | 7/500 [02:59<3:42:09, 27.04s/it]  2%|▏         | 8/500 [03:22<3:30:17, 25.65s/it]  2%|▏         | 9/500 [03:51<3:38:01, 26.64s/it]  2%|▏         | 10/500 [04:15<3:31:24, 25.89s/it]  2%|▏         | 11/500 [04:39<3:27:43, 25.49s/it]  2%|▏         | 12/500 [05:04<3:24:03, 25.09s/it]  3%|▎         | 13/500 [05:26<3:18:29, 24.45s/it]  3%|▎         | 14/500 [05:51<3:18:17, 24.48s/it]  3%|▎         | 15/500 [06:15<3:17:07, 24.39s/it]  3%|▎         | 16/500 [06:38<3:12:09, 23.82s/it]  3%|▎         | 17/500 [07:05<3:19:06, 24.73s/it]  4%|▎         | 18/500 [07:31<3:23:52, 25.38s/it]  4%|▍         | 19/500 [07:55<3:18:30, 24.76s/it]  4%|▍         | 20/500 [08:21<3:20:43, 25.09s/it]  4%|▍         | 21/500 [08:45<3:19:18, 24.97s/it]  4%|▍         | 22/500 [09:10<3:17:21, 24.77s/it]  5%|▍         | 23/500 [09:34<3:16:10, 24.68s/it]  5%|▍         | 24/500 [10:06<3:32:21, 26.77s/it]  5%|▌         | 25/500 [10:36<3:39:28, 27.72s/it]  5%|▌         | 26/500 [11:06<3:44:23, 28.40s/it]  5%|▌         | 27/500 [11:36<3:48:05, 28.93s/it]  6%|▌         | 28/500 [12:09<3:56:54, 30.12s/it]  6%|▌         | 29/500 [12:41<4:01:33, 30.77s/it]  6%|▌         | 30/500 [13:11<3:59:02, 30.52s/it]  6%|▌         | 31/500 [13:36<3:46:36, 28.99s/it]  6%|▋         | 32/500 [14:03<3:41:35, 28.41s/it]  7%|▋         | 33/500 [14:26<3:27:45, 26.69s/it]  7%|▋         | 34/500 [14:51<3:22:24, 26.06s/it]  7%|▋         | 35/500 [15:15<3:18:07, 25.57s/it]  7%|▋         | 36/500 [15:38<3:10:41, 24.66s/it]  7%|▋         | 37/500 [16:08<3:22:56, 26.30s/it]  7%|▋         | 37/500 [16:19<3:24:12, 26.46s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.309 MB uploadedwandb: \ 0.010 MB of 0.309 MB uploadedwandb: | 0.231 MB of 0.309 MB uploadedwandb: / 0.309 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb: \ 0.309 MB of 0.309 MB uploadedwandb: | 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▃▄▅▅▃▄▇▇▇▅▇▇█▇▅█▇█▇▇████████████████
wandb:     train_loss ▃▂▃▂▂▅█▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁
wandb:   val_accuracy ▆▆▆▁▂▁▁███▃▆▅▅▅▄▇▅▆▄▄▅▅▅▆▅▆▅▄▄▅▄▄▆▅▄▆
wandb:       val_loss ▂▂▃▂▂▃▆▇▄▄▃▄▃▅█▄▁▂▃▆▁▆▆▇▄▅▆▃█▂▅▅▃▅▅▄▁
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 0.00051
wandb: train_accuracy 1.0
wandb:     train_loss 0.00122
wandb:   val_accuracy 0.36
wandb:       val_loss 0.2802
wandb: 
wandb: 🚀 View run copper-cloud-2684 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/jhxq4jps
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_175158-jhxq4jps/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_180902-pr3e5u5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sound-2685
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/pr3e5u5j
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:11:15, 37.43s/it]  0%|          | 2/500 [01:01<4:03:14, 29.31s/it]  1%|          | 3/500 [01:24<3:40:47, 26.66s/it]  1%|          | 4/500 [01:47<3:29:38, 25.36s/it]  1%|          | 5/500 [02:21<3:52:29, 28.18s/it]  1%|          | 6/500 [02:44<3:38:31, 26.54s/it]  1%|▏         | 7/500 [03:13<3:43:37, 27.22s/it]  2%|▏         | 8/500 [03:51<4:11:58, 30.73s/it]  2%|▏         | 9/500 [04:14<3:52:25, 28.40s/it]  2%|▏         | 10/500 [04:38<3:39:23, 26.86s/it]  2%|▏         | 11/500 [05:09<3:50:13, 28.25s/it]  2%|▏         | 12/500 [05:41<3:58:15, 29.29s/it]  3%|▎         | 13/500 [06:12<4:02:21, 29.86s/it]  3%|▎         | 14/500 [06:46<4:11:47, 31.09s/it]  3%|▎         | 15/500 [07:11<3:57:15, 29.35s/it]  3%|▎         | 16/500 [07:44<4:05:51, 30.48s/it]  3%|▎         | 17/500 [08:13<4:01:16, 29.97s/it]  4%|▎         | 18/500 [08:49<4:14:34, 31.69s/it]  4%|▍         | 19/500 [09:12<3:54:22, 29.24s/it]  4%|▍         | 20/500 [09:45<4:02:47, 30.35s/it]  4%|▍         | 21/500 [10:09<3:47:09, 28.45s/it]  4%|▍         | 22/500 [10:38<3:47:33, 28.56s/it]  5%|▍         | 23/500 [11:10<3:54:27, 29.49s/it]  5%|▍         | 24/500 [11:37<3:49:34, 28.94s/it]  5%|▌         | 25/500 [12:03<3:41:51, 28.03s/it]  5%|▌         | 26/500 [12:27<3:32:06, 26.85s/it]  5%|▌         | 27/500 [12:52<3:26:45, 26.23s/it]  6%|▌         | 28/500 [13:16<3:21:54, 25.67s/it]  6%|▌         | 29/500 [13:49<3:38:09, 27.79s/it]  6%|▌         | 30/500 [14:13<3:27:25, 26.48s/it]  6%|▌         | 31/500 [14:50<3:51:38, 29.63s/it]  6%|▋         | 32/500 [15:13<3:36:42, 27.78s/it]  7%|▋         | 33/500 [15:45<3:45:49, 29.01s/it]  7%|▋         | 34/500 [16:16<3:49:20, 29.53s/it]  7%|▋         | 35/500 [16:42<3:41:44, 28.61s/it]  7%|▋         | 36/500 [17:07<3:32:42, 27.51s/it]  7%|▋         | 37/500 [17:38<3:41:12, 28.67s/it]  8%|▊         | 38/500 [18:03<3:31:26, 27.46s/it]  8%|▊         | 39/500 [18:28<3:24:21, 26.60s/it]  8%|▊         | 40/500 [18:52<3:19:07, 25.97s/it]  8%|▊         | 41/500 [19:15<3:11:45, 25.07s/it]  8%|▊         | 42/500 [19:44<3:19:06, 26.08s/it]  9%|▊         | 43/500 [20:08<3:14:13, 25.50s/it]  9%|▉         | 44/500 [20:40<3:29:57, 27.63s/it]  9%|▉         | 45/500 [21:12<3:37:53, 28.73s/it]  9%|▉         | 46/500 [21:43<3:43:31, 29.54s/it]  9%|▉         | 47/500 [22:14<3:47:16, 30.10s/it]  9%|▉         | 47/500 [22:20<3:35:21, 28.52s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.315 MB uploadedwandb: | 0.010 MB of 0.315 MB uploadedwandb: / 0.295 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▃▃▄▄▅▅▅▅▅▆▆▅▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇█▇████████
wandb:     train_loss ▆▅▅▄▅▅▅▅▅▅▅▄▅▅▄▅▄▃▂▂▂▂▄▃▅▃▁▁▂▃▃▂▄▃▃▄▂█▂▂
wandb:   val_accuracy ▇█▃▃▃▂▂▅▃▁▂▅▁▂▃▄▄▂▃▄▃▆▆▃▇▅▅▅▇▃▅▅▅▄▄▅▅▅▆▅
wandb:       val_loss ▃▃▃▂▂▂▂▃▃▂▄▂▄▃▂▂▃▂▅▅▃▅▅▅▃▃▁▃▂▂▃▂▄▇█▄▂▂▆▇
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.80981
wandb:     train_loss 0.30848
wandb:   val_accuracy 0.29333
wandb:       val_loss 3.23081
wandb: 
wandb: 🚀 View run exalted-sound-2685 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/pr3e5u5j
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_180902-pr3e5u5j/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_183212-i41yobn4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-snowball-2686
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/i41yobn4
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:14:57, 37.87s/it]  0%|          | 2/500 [01:00<4:01:40, 29.12s/it]  1%|          | 3/500 [01:38<4:33:17, 32.99s/it]  1%|          | 4/500 [02:01<3:58:48, 28.89s/it]  1%|          | 5/500 [02:23<3:40:05, 26.68s/it]  1%|          | 6/500 [02:51<3:43:35, 27.16s/it]  1%|▏         | 7/500 [03:24<3:58:39, 29.04s/it]  2%|▏         | 8/500 [03:54<4:00:51, 29.37s/it]  2%|▏         | 9/500 [04:24<4:01:19, 29.49s/it]  2%|▏         | 10/500 [04:55<4:03:10, 29.78s/it]  2%|▏         | 11/500 [05:22<3:56:08, 28.97s/it]  2%|▏         | 12/500 [05:47<3:46:56, 27.90s/it]  3%|▎         | 13/500 [06:10<3:34:48, 26.47s/it]  3%|▎         | 14/500 [06:35<3:29:15, 25.83s/it]  3%|▎         | 15/500 [07:00<3:26:56, 25.60s/it]  3%|▎         | 16/500 [07:25<3:25:28, 25.47s/it]  3%|▎         | 17/500 [08:05<3:59:15, 29.72s/it]  4%|▎         | 18/500 [08:35<4:00:18, 29.91s/it]  4%|▍         | 19/500 [08:58<3:43:08, 27.83s/it]  4%|▍         | 20/500 [09:24<3:38:07, 27.27s/it]  4%|▍         | 21/500 [09:50<3:34:53, 26.92s/it]  4%|▍         | 22/500 [10:14<3:27:01, 25.99s/it]  5%|▍         | 23/500 [10:38<3:22:45, 25.50s/it]  5%|▍         | 24/500 [11:08<3:32:55, 26.84s/it]  5%|▌         | 25/500 [11:36<3:35:31, 27.22s/it]  5%|▌         | 26/500 [12:06<3:40:16, 27.88s/it]  5%|▌         | 27/500 [12:31<3:34:29, 27.21s/it]  6%|▌         | 28/500 [12:55<3:25:49, 26.16s/it]  6%|▌         | 29/500 [13:20<3:22:52, 25.84s/it]  6%|▌         | 30/500 [13:43<3:15:58, 25.02s/it]  6%|▌         | 31/500 [14:10<3:19:41, 25.55s/it]  6%|▋         | 32/500 [14:34<3:14:34, 24.95s/it]  7%|▋         | 33/500 [14:57<3:11:29, 24.60s/it]  7%|▋         | 34/500 [15:24<3:16:27, 25.30s/it]  7%|▋         | 35/500 [15:51<3:18:30, 25.61s/it]  7%|▋         | 36/500 [16:14<3:13:27, 25.02s/it]  7%|▋         | 37/500 [16:41<3:17:49, 25.64s/it]  8%|▊         | 38/500 [17:04<3:10:47, 24.78s/it]  8%|▊         | 39/500 [17:34<3:21:18, 26.20s/it]  8%|▊         | 40/500 [17:58<3:17:32, 25.77s/it]  8%|▊         | 41/500 [18:26<3:20:44, 26.24s/it]  8%|▊         | 42/500 [18:48<3:12:02, 25.16s/it]  9%|▊         | 43/500 [19:19<3:24:34, 26.86s/it]  9%|▉         | 44/500 [19:42<3:14:17, 25.56s/it]  9%|▉         | 45/500 [20:11<3:23:13, 26.80s/it]  9%|▉         | 46/500 [20:37<3:19:31, 26.37s/it]  9%|▉         | 47/500 [21:00<3:12:12, 25.46s/it] 10%|▉         | 48/500 [21:24<3:08:46, 25.06s/it] 10%|▉         | 49/500 [21:48<3:06:37, 24.83s/it] 10%|█         | 50/500 [22:12<3:03:55, 24.52s/it] 10%|█         | 51/500 [22:35<2:59:44, 24.02s/it] 10%|█         | 51/500 [22:35<3:18:54, 26.58s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.312 MB uploadedwandb: \ 0.020 MB of 0.312 MB uploadedwandb: | 0.232 MB of 0.312 MB uploadedwandb: / 0.312 MB of 0.312 MB uploadedwandb: - 0.312 MB of 0.312 MB uploadedwandb: \ 0.312 MB of 0.312 MB uploadedwandb: | 0.312 MB of 0.312 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁
wandb: train_accuracy ▂▂▁▂▃▄▄▅▅▅▆▇▆▇▇█▇█████▇█████████████████
wandb:     train_loss ▄▄▄▄█▄▃▁▃▅▃▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▅▄▄▄▅▆▇▃▁▂▄▂▇▇▆▅▆▆▇▇▇█▇▇▅▇▆▇▇▇▇▇▇▇█▇▅▇▇
wandb:       val_loss ▂▂▂▂▃▂▃▂▂▄▂▄▃▁▁▃▁▆▂▄▃▅▁▃▁▃▁▁▃▅▇▆▂▁▁▅▇█▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 50
wandb:  learning_rate 0.00016
wandb: train_accuracy 1.0
wandb:     train_loss 0.02131
wandb:   val_accuracy 0.44222
wandb:       val_loss 3.98414
wandb: 
wandb: 🚀 View run frosty-snowball-2686 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/i41yobn4
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_183212-i41yobn4/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_185531-lol27mxq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-energy-2687
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lol27mxq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:31:09, 25.39s/it]  0%|          | 2/500 [00:48<3:21:12, 24.24s/it]  1%|          | 3/500 [01:12<3:16:56, 23.78s/it]  1%|          | 4/500 [01:37<3:21:36, 24.39s/it]  1%|          | 5/500 [02:02<3:24:41, 24.81s/it]  1%|          | 6/500 [02:27<3:23:17, 24.69s/it]  1%|▏         | 7/500 [02:51<3:21:48, 24.56s/it]  2%|▏         | 8/500 [03:14<3:17:32, 24.09s/it]  2%|▏         | 9/500 [03:41<3:24:55, 25.04s/it]  2%|▏         | 10/500 [04:15<3:45:55, 27.66s/it]  2%|▏         | 11/500 [04:45<3:52:29, 28.53s/it]  2%|▏         | 12/500 [05:25<4:18:32, 31.79s/it]  3%|▎         | 13/500 [05:48<3:57:14, 29.23s/it]  3%|▎         | 14/500 [06:20<4:03:21, 30.04s/it]  3%|▎         | 15/500 [06:44<3:49:14, 28.36s/it]  3%|▎         | 16/500 [07:09<3:38:37, 27.10s/it]  3%|▎         | 17/500 [07:33<3:31:31, 26.28s/it]  4%|▎         | 18/500 [07:59<3:30:49, 26.24s/it]  4%|▍         | 19/500 [08:23<3:24:06, 25.46s/it]  4%|▍         | 20/500 [08:48<3:22:52, 25.36s/it]  4%|▍         | 21/500 [09:11<3:17:01, 24.68s/it]  4%|▍         | 22/500 [09:38<3:23:01, 25.48s/it]  5%|▍         | 23/500 [10:01<3:16:47, 24.75s/it]  5%|▍         | 24/500 [10:25<3:13:52, 24.44s/it]  5%|▌         | 25/500 [10:52<3:20:31, 25.33s/it]  5%|▌         | 26/500 [11:16<3:16:45, 24.91s/it]  5%|▌         | 27/500 [11:43<3:20:14, 25.40s/it]  6%|▌         | 28/500 [12:17<3:39:30, 27.90s/it]  6%|▌         | 29/500 [12:48<3:47:17, 28.95s/it]  6%|▌         | 30/500 [13:19<3:52:22, 29.67s/it]  6%|▌         | 30/500 [13:27<3:30:47, 26.91s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.240 MB uploadedwandb: \ 0.020 MB of 0.240 MB uploadedwandb: | 0.240 MB of 0.240 MB uploadedwandb: / 0.240 MB of 0.240 MB uploadedwandb: - 0.240 MB of 0.240 MB uploadedwandb: \ 0.240 MB of 0.240 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁
wandb: train_accuracy ▃▅▇▅▄▂█▁▂▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇
wandb:     train_loss ▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▆▁▂▂▃▅█▇▄▃▁▄▆▅▄▄▆▄▆▄▆▇▆▅▅▆▆▆▆▆
wandb:       val_loss ▁▁▁▁▁▁▃█▁▁▁▁▁▁▂▁▂▁▁▂▁▃▂▂▁▂▂▂▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 29
wandb:  learning_rate 0.00051
wandb: train_accuracy 0.64636
wandb:     train_loss 0.01839
wandb:   val_accuracy 0.29111
wandb:       val_loss 0.56192
wandb: 
wandb: 🚀 View run vague-energy-2687 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/lol27mxq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_185531-lol27mxq/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_190940-sfpxpj29
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-cloud-2688
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sfpxpj29
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:11:03, 37.40s/it]  0%|          | 2/500 [01:01<4:04:07, 29.41s/it]  1%|          | 3/500 [01:24<3:40:53, 26.67s/it]  1%|          | 4/500 [01:48<3:29:53, 25.39s/it]  1%|          | 5/500 [02:27<4:10:58, 30.42s/it]  1%|          | 6/500 [02:50<3:50:31, 28.00s/it]  1%|▏         | 7/500 [03:16<3:44:31, 27.33s/it]  2%|▏         | 8/500 [03:40<3:34:51, 26.20s/it]  2%|▏         | 9/500 [04:12<3:49:20, 28.03s/it]  2%|▏         | 10/500 [04:45<4:01:00, 29.51s/it]  2%|▏         | 11/500 [05:16<4:05:07, 30.08s/it]  2%|▏         | 12/500 [05:48<4:07:59, 30.49s/it]  3%|▎         | 13/500 [06:19<4:09:18, 30.72s/it]  3%|▎         | 14/500 [06:51<4:11:17, 31.02s/it]  3%|▎         | 15/500 [07:19<4:04:11, 30.21s/it]  3%|▎         | 16/500 [07:44<3:50:12, 28.54s/it]  3%|▎         | 17/500 [08:20<4:07:51, 30.79s/it]  4%|▎         | 18/500 [08:43<3:50:09, 28.65s/it]  4%|▍         | 19/500 [09:13<3:53:27, 29.12s/it]  4%|▍         | 20/500 [09:40<3:47:24, 28.43s/it]  4%|▍         | 21/500 [10:13<3:58:08, 29.83s/it]  4%|▍         | 22/500 [10:42<3:54:38, 29.45s/it]  5%|▍         | 23/500 [11:14<3:59:35, 30.14s/it]  5%|▍         | 24/500 [11:42<3:55:11, 29.65s/it]  5%|▌         | 25/500 [12:07<3:42:09, 28.06s/it]  5%|▌         | 26/500 [12:39<3:52:15, 29.40s/it]  5%|▌         | 27/500 [13:10<3:55:31, 29.88s/it]  6%|▌         | 28/500 [13:41<3:58:17, 30.29s/it]  6%|▌         | 29/500 [14:12<3:59:10, 30.47s/it]  6%|▌         | 30/500 [14:44<4:02:14, 30.92s/it]  6%|▌         | 31/500 [15:27<4:29:04, 34.42s/it]  6%|▋         | 32/500 [15:50<4:02:11, 31.05s/it]  7%|▋         | 33/500 [16:21<4:02:30, 31.16s/it]  7%|▋         | 34/500 [16:53<4:02:03, 31.17s/it]  7%|▋         | 35/500 [17:21<3:55:20, 30.37s/it]  7%|▋         | 36/500 [17:52<3:57:03, 30.65s/it]  7%|▋         | 37/500 [18:24<3:58:59, 30.97s/it]  8%|▊         | 38/500 [18:53<3:52:50, 30.24s/it]  8%|▊         | 39/500 [19:24<3:55:48, 30.69s/it]  8%|▊         | 40/500 [19:58<4:02:43, 31.66s/it]  8%|▊         | 41/500 [20:25<3:49:56, 30.06s/it]  8%|▊         | 42/500 [20:50<3:37:40, 28.52s/it]  9%|▊         | 43/500 [21:14<3:28:54, 27.43s/it]  9%|▉         | 44/500 [21:39<3:22:25, 26.64s/it]  9%|▉         | 45/500 [22:02<3:13:48, 25.56s/it]  9%|▉         | 46/500 [22:28<3:13:40, 25.60s/it]  9%|▉         | 47/500 [22:53<3:11:50, 25.41s/it]  9%|▉         | 47/500 [22:53<3:40:37, 29.22s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.315 MB uploadedwandb: - 0.010 MB of 0.315 MB uploadedwandb: \ 0.020 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb: / 0.315 MB of 0.315 MB uploadedwandb: - 0.315 MB of 0.315 MB uploadedwandb: \ 0.315 MB of 0.315 MB uploadedwandb: | 0.315 MB of 0.315 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▃▄▄▄▅▅▆▆▅▆▆▆▆▅▆▇▇▇▇███▇██▇█████████████
wandb:     train_loss ▆▅▅▄▅▅▅▆▄▅▄▄▄▄▃▄▃▃▂▂▂▅▅▂▂▃▁▁▁▃▂▂▄▄▆▇▁█▃▂
wandb:   val_accuracy ▇▇▅▂▃▂▁▄▃▂▃▄▂▁█▅▅▅▆▄▅▅▅▁▃▄▅▃▄▃▃▃▄▄▃▄▄▄▄▅
wandb:       val_loss ▃▃▃▃▃▃▃▃▃▃▄▃▄▄▁▂▄▃▆▅▄▅▆▅▄▄▁▄▃▃▃▂▄██▃▂▃▆▇
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.76374
wandb:     train_loss 0.32771
wandb:   val_accuracy 0.28
wandb:       val_loss 2.66053
wandb: 
wandb: 🚀 View run dandy-cloud-2688 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/sfpxpj29
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_190940-sfpxpj29/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_193324-t9xjn9yv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-voice-2689
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t9xjn9yv
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:25<3:34:45, 25.82s/it]  0%|          | 2/500 [00:48<3:18:26, 23.91s/it]  1%|          | 3/500 [01:11<3:15:27, 23.60s/it]  1%|          | 4/500 [01:34<3:13:32, 23.41s/it]  1%|          | 5/500 [02:04<3:32:20, 25.74s/it]  1%|          | 6/500 [02:26<3:22:28, 24.59s/it]  1%|▏         | 7/500 [02:56<3:36:21, 26.33s/it]  2%|▏         | 8/500 [03:25<3:41:52, 27.06s/it]  2%|▏         | 9/500 [03:55<3:48:01, 27.87s/it]  2%|▏         | 10/500 [04:23<3:48:51, 28.02s/it]  2%|▏         | 11/500 [04:45<3:33:51, 26.24s/it]  2%|▏         | 12/500 [05:15<3:41:34, 27.24s/it]  3%|▎         | 13/500 [05:41<3:38:23, 26.91s/it]  3%|▎         | 14/500 [06:04<3:28:17, 25.72s/it]  3%|▎         | 15/500 [06:30<3:27:56, 25.72s/it]  3%|▎         | 16/500 [06:54<3:24:09, 25.31s/it]  3%|▎         | 17/500 [07:16<3:16:19, 24.39s/it]  4%|▎         | 18/500 [07:43<3:21:12, 25.05s/it]  4%|▍         | 19/500 [08:07<3:17:54, 24.69s/it]  4%|▍         | 20/500 [08:31<3:16:08, 24.52s/it]  4%|▍         | 21/500 [08:55<3:14:03, 24.31s/it]  4%|▍         | 22/500 [09:17<3:08:38, 23.68s/it]  5%|▍         | 23/500 [09:44<3:15:54, 24.64s/it]  5%|▍         | 24/500 [10:11<3:20:51, 25.32s/it]  5%|▌         | 25/500 [10:34<3:14:53, 24.62s/it]  5%|▌         | 26/500 [11:01<3:20:38, 25.40s/it]  5%|▌         | 27/500 [11:25<3:17:27, 25.05s/it]  6%|▌         | 28/500 [11:49<3:14:48, 24.76s/it]  6%|▌         | 29/500 [12:12<3:10:44, 24.30s/it]  6%|▌         | 30/500 [12:36<3:08:55, 24.12s/it]  6%|▌         | 31/500 [12:59<3:06:50, 23.90s/it]  6%|▋         | 32/500 [13:32<3:25:39, 26.37s/it]  7%|▋         | 33/500 [13:59<3:28:26, 26.78s/it]  7%|▋         | 34/500 [14:36<3:50:23, 29.66s/it]  7%|▋         | 35/500 [14:59<3:34:13, 27.64s/it]  7%|▋         | 36/500 [15:28<3:37:03, 28.07s/it]  7%|▋         | 37/500 [15:51<3:24:36, 26.52s/it]  8%|▊         | 38/500 [16:15<3:19:30, 25.91s/it]  8%|▊         | 39/500 [16:39<3:15:25, 25.44s/it]  8%|▊         | 40/500 [17:10<3:27:21, 27.05s/it]  8%|▊         | 41/500 [17:32<3:15:44, 25.59s/it]  8%|▊         | 42/500 [18:01<3:22:56, 26.59s/it]  9%|▊         | 43/500 [18:34<3:35:44, 28.33s/it]  9%|▉         | 44/500 [19:04<3:40:04, 28.96s/it]  9%|▉         | 45/500 [19:32<3:36:22, 28.53s/it]  9%|▉         | 46/500 [19:54<3:22:34, 26.77s/it]  9%|▉         | 47/500 [20:21<3:21:50, 26.73s/it] 10%|▉         | 48/500 [20:44<3:12:25, 25.54s/it] 10%|▉         | 49/500 [21:11<3:16:58, 26.20s/it] 10%|█         | 50/500 [21:35<3:10:16, 25.37s/it] 10%|█         | 50/500 [21:35<3:14:18, 25.91s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.311 MB uploadedwandb: / 0.010 MB of 0.311 MB uploadedwandb: - 0.138 MB of 0.311 MB uploadedwandb: \ 0.138 MB of 0.311 MB uploadedwandb: | 0.311 MB of 0.311 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁
wandb: train_accuracy ▁▂▂▁▂▅▄▅▇▅▄▇▇▄▇▇█▇▇▆▅██▆██████▇█████████
wandb:     train_loss ▂▃▂▃▃▃▂▁▁▃▁▁▁▃▁▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▄▂▄▅▃▁▃▆▅▆▆▇▃▇▇███▆▇▆▆▁▇▆▃▃▇▆▅▆▆▆▆▅▅▆▄▅▆
wandb:       val_loss ▂▂▂▂▂▂▂▂▃▁▃▁▂▁▁▁▂▇▅▁▃▆▅▁▁▃▄▁▃▂▂▇▇▃▁▂▃█▅▃
wandb: 
wandb: Run summary:
wandb:          epoch 49
wandb:  learning_rate 0.00016
wandb: train_accuracy 1.0
wandb:     train_loss 0.00014
wandb:   val_accuracy 0.42667
wandb:       val_loss 3.96067
wandb: 
wandb: 🚀 View run spring-voice-2689 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/t9xjn9yv
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_193324-t9xjn9yv/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_195541-8lg3j47o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-oath-2690
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8lg3j47o
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:24<3:26:09, 24.79s/it]  0%|          | 2/500 [00:48<3:18:41, 23.94s/it]  1%|          | 3/500 [01:10<3:14:04, 23.43s/it]  1%|          | 4/500 [01:34<3:13:12, 23.37s/it]  1%|          | 5/500 [02:01<3:25:26, 24.90s/it]  1%|          | 6/500 [02:25<3:21:52, 24.52s/it]  1%|▏         | 7/500 [02:50<3:21:12, 24.49s/it]  2%|▏         | 8/500 [03:21<3:39:02, 26.71s/it]  2%|▏         | 9/500 [03:44<3:28:31, 25.48s/it]  2%|▏         | 10/500 [04:13<3:38:29, 26.75s/it]  2%|▏         | 11/500 [04:36<3:27:17, 25.43s/it]  2%|▏         | 12/500 [05:06<3:39:24, 26.98s/it]  3%|▎         | 13/500 [05:40<3:54:25, 28.88s/it]  3%|▎         | 14/500 [06:07<3:51:29, 28.58s/it]  3%|▎         | 15/500 [06:37<3:53:36, 28.90s/it]  3%|▎         | 16/500 [07:05<3:50:36, 28.59s/it]  3%|▎         | 17/500 [07:35<3:54:17, 29.10s/it]  4%|▎         | 18/500 [08:07<3:59:40, 29.83s/it]  4%|▍         | 19/500 [08:39<4:04:23, 30.48s/it]  4%|▍         | 20/500 [09:12<4:10:17, 31.29s/it]  4%|▍         | 21/500 [09:46<4:16:48, 32.17s/it]  4%|▍         | 22/500 [10:09<3:53:17, 29.28s/it]  5%|▍         | 23/500 [10:39<3:54:29, 29.50s/it]  5%|▍         | 24/500 [11:09<3:54:53, 29.61s/it]  5%|▌         | 25/500 [11:39<3:55:42, 29.77s/it]  5%|▌         | 26/500 [12:09<3:57:20, 30.04s/it]  5%|▌         | 27/500 [12:44<4:06:27, 31.26s/it]  6%|▌         | 28/500 [13:16<4:07:47, 31.50s/it]  6%|▌         | 29/500 [13:39<3:47:16, 28.95s/it]  6%|▌         | 30/500 [14:06<3:43:56, 28.59s/it]  6%|▌         | 31/500 [14:29<3:29:18, 26.78s/it]  6%|▋         | 32/500 [14:56<3:29:42, 26.89s/it]  7%|▋         | 33/500 [15:22<3:26:11, 26.49s/it]  7%|▋         | 34/500 [15:50<3:28:58, 26.91s/it]  7%|▋         | 35/500 [16:19<3:35:15, 27.77s/it]  7%|▋         | 36/500 [16:49<3:38:49, 28.30s/it]  7%|▋         | 37/500 [17:18<3:41:09, 28.66s/it]  7%|▋         | 37/500 [17:29<3:38:48, 28.36s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.313 MB uploadedwandb: / 0.010 MB of 0.313 MB uploadedwandb: - 0.138 MB of 0.313 MB uploadedwandb: \ 0.313 MB of 0.313 MB uploadedwandb: | 0.313 MB of 0.313 MB uploadedwandb: / 0.313 MB of 0.313 MB uploadedwandb: - 0.313 MB of 0.313 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate █████████▅▅▅▅▅▅▅▅▅▅▃▃▃▃▃▃▃▃▃▃▁▁▁▁▁▁▁▁
wandb: train_accuracy ▂▂▂▂▂▁▅▅▅▅▆▅▄▄▆▄▄▄█▅▇▇▆▆█▆▇▆▇▆████▆█▇
wandb:     train_loss ▃▃▃▃▃▃▃▂▁▁▂▂▁▁▂█▂▃▁▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▇▇▇▆▅▆▆▆▁▇▂▃▃▄▂▂▄▆▄▅▆▆▅█▆▄▆▆▄▇▇▇█▆█▆
wandb:       val_loss ▁▁▁▁▁▂▂▅▃▃▃▃▆▄▄▃▃▂▂▃▁▂▂▄▆▃█▁▅▁▁▃▂▃▃▂▁
wandb: 
wandb: Run summary:
wandb:          epoch 36
wandb:  learning_rate 0.00051
wandb: train_accuracy 0.92125
wandb:     train_loss 0.00215
wandb:   val_accuracy 0.38667
wandb:       val_loss 0.9831
wandb: 
wandb: 🚀 View run solar-oath-2690 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/8lg3j47o
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_195541-8lg3j47o/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_201353-efpiw4mt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-grass-2691
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/efpiw4mt
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:37<5:12:27, 37.57s/it]  0%|          | 2/500 [01:01<4:04:12, 29.42s/it]  1%|          | 3/500 [01:24<3:42:03, 26.81s/it]  1%|          | 4/500 [01:47<3:28:45, 25.25s/it]  1%|          | 5/500 [02:18<3:43:50, 27.13s/it]  1%|          | 6/500 [02:49<3:54:45, 28.51s/it]  1%|▏         | 7/500 [03:20<4:00:27, 29.26s/it]  2%|▏         | 8/500 [03:51<4:03:50, 29.74s/it]  2%|▏         | 9/500 [04:20<4:02:12, 29.60s/it]  2%|▏         | 10/500 [04:48<3:58:31, 29.21s/it]  2%|▏         | 11/500 [05:22<4:10:14, 30.70s/it]  2%|▏         | 12/500 [05:45<3:50:37, 28.36s/it]  3%|▎         | 13/500 [06:17<3:58:31, 29.39s/it]  3%|▎         | 14/500 [06:41<3:44:54, 27.77s/it]  3%|▎         | 15/500 [07:06<3:38:23, 27.02s/it]  3%|▎         | 16/500 [07:31<3:31:25, 26.21s/it]  3%|▎         | 17/500 [07:54<3:24:05, 25.35s/it]  4%|▎         | 18/500 [08:20<3:25:43, 25.61s/it]  4%|▍         | 19/500 [08:44<3:21:04, 25.08s/it]  4%|▍         | 20/500 [09:08<3:18:55, 24.86s/it]  4%|▍         | 21/500 [09:41<3:36:17, 27.09s/it]  4%|▍         | 22/500 [10:12<3:46:16, 28.40s/it]  5%|▍         | 23/500 [10:36<3:34:01, 26.92s/it]  5%|▍         | 24/500 [11:05<3:40:23, 27.78s/it]  5%|▌         | 25/500 [11:28<3:28:20, 26.32s/it]  5%|▌         | 26/500 [11:56<3:30:11, 26.61s/it]  5%|▌         | 27/500 [12:19<3:21:39, 25.58s/it]  6%|▌         | 28/500 [12:45<3:23:10, 25.83s/it]  6%|▌         | 29/500 [13:10<3:19:32, 25.42s/it]  6%|▌         | 30/500 [13:41<3:33:40, 27.28s/it]  6%|▌         | 31/500 [14:19<3:58:06, 30.46s/it]  6%|▋         | 32/500 [14:43<3:40:53, 28.32s/it]  7%|▋         | 33/500 [15:14<3:47:32, 29.24s/it]  7%|▋         | 34/500 [15:42<3:45:35, 29.05s/it]  7%|▋         | 35/500 [16:13<3:48:32, 29.49s/it]  7%|▋         | 36/500 [16:43<3:49:57, 29.74s/it]  7%|▋         | 37/500 [17:15<3:54:50, 30.43s/it]  8%|▊         | 38/500 [17:47<3:57:38, 30.86s/it]  8%|▊         | 39/500 [18:19<3:59:14, 31.14s/it]  8%|▊         | 40/500 [18:50<3:58:46, 31.14s/it]  8%|▊         | 41/500 [19:19<3:52:09, 30.35s/it]  8%|▊         | 42/500 [19:51<3:55:07, 30.80s/it]  9%|▊         | 43/500 [20:21<3:53:54, 30.71s/it]  9%|▉         | 44/500 [20:48<3:45:14, 29.64s/it]  9%|▉         | 45/500 [21:22<3:53:10, 30.75s/it]  9%|▉         | 46/500 [21:53<3:54:00, 30.93s/it]  9%|▉         | 47/500 [22:24<3:53:49, 30.97s/it]  9%|▉         | 47/500 [22:32<3:37:15, 28.78s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.314 MB uploadedwandb: | 0.020 MB of 0.314 MB uploadedwandb: / 0.314 MB of 0.314 MB uploadedwandb: - 0.314 MB of 0.314 MB uploadedwandb: \ 0.314 MB of 0.314 MB uploadedwandb: | 0.314 MB of 0.314 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:  learning_rate ████████▆▆▆▆▆▆▆▆▆▄▄▄▄▄▄▄▄▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁
wandb: train_accuracy ▁▁▁▂▂▃▃▄▄▄▄▃▄▄▅▄▅▆▆▆▇▇▇▇▇▇▇█▇▇▇█▇▇▇████▆
wandb:     train_loss ▅▄▇▅▄▄▄▇▆▄▄▅▂▃▄▃▃▃▄▃▄▄▅▄▃▃▁▂▁▃▄▁▅▁▃▄█▃▃▂
wandb:   val_accuracy ▇▆▆▇▆▆▆▆▆▆▆▆▇▆▆▆▆▅▄▅▅▅▃▃▃▃▂▂▃▃▄▁▃▃▃▃▃▄▃█
wandb:       val_loss ▃▂▆▂▂▂▃▂▃▃▃▃▃▃▂▃▄▃▃▂▄▄▅▃▃▄▁▄▂▃▁▂▄▅▅▃▃▅▄█
wandb: 
wandb: Run summary:
wandb:          epoch 46
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.60624
wandb:     train_loss 0.39832
wandb:   val_accuracy 0.38444
wandb:       val_loss 2.92541
wandb: 
wandb: 🚀 View run elated-grass-2691 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/efpiw4mt
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_201353-efpiw4mt/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_203709-ok8y6r34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-bush-2692
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ok8y6r34
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:26<3:36:30, 26.03s/it]  0%|          | 2/500 [00:50<3:26:04, 24.83s/it]  1%|          | 3/500 [01:13<3:20:14, 24.17s/it]  1%|          | 4/500 [01:44<3:43:33, 27.04s/it]  1%|          | 5/500 [02:08<3:31:39, 25.66s/it]  1%|          | 6/500 [02:40<3:49:45, 27.91s/it]  1%|▏         | 7/500 [03:03<3:35:14, 26.20s/it]  2%|▏         | 8/500 [03:31<3:40:04, 26.84s/it]  2%|▏         | 9/500 [03:55<3:32:54, 26.02s/it]  2%|▏         | 10/500 [04:19<3:26:45, 25.32s/it]  2%|▏         | 11/500 [04:44<3:26:06, 25.29s/it]  2%|▏         | 12/500 [05:07<3:19:19, 24.51s/it]  3%|▎         | 13/500 [05:38<3:35:11, 26.51s/it]  3%|▎         | 14/500 [06:01<3:26:56, 25.55s/it]  3%|▎         | 15/500 [06:31<3:36:10, 26.74s/it]  3%|▎         | 16/500 [06:57<3:34:33, 26.60s/it]  3%|▎         | 17/500 [07:21<3:27:11, 25.74s/it]  4%|▎         | 18/500 [07:49<3:33:34, 26.59s/it]  4%|▍         | 19/500 [08:21<3:45:12, 28.09s/it]  4%|▍         | 20/500 [08:49<3:44:53, 28.11s/it]  4%|▍         | 21/500 [09:20<3:51:49, 29.04s/it]  4%|▍         | 22/500 [09:52<3:58:58, 30.00s/it]  5%|▍         | 23/500 [10:22<3:57:11, 29.84s/it]  5%|▍         | 24/500 [10:56<4:06:37, 31.09s/it]  5%|▌         | 25/500 [11:19<3:46:22, 28.59s/it]  5%|▌         | 26/500 [11:49<3:49:43, 29.08s/it]  5%|▌         | 27/500 [12:14<3:40:31, 27.97s/it]  6%|▌         | 28/500 [12:40<3:34:25, 27.26s/it]  6%|▌         | 29/500 [13:02<3:22:46, 25.83s/it]  6%|▌         | 29/500 [13:02<3:31:53, 26.99s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.309 MB uploadedwandb: / 0.010 MB of 0.309 MB uploadedwandb: - 0.231 MB of 0.309 MB uploadedwandb: \ 0.231 MB of 0.309 MB uploadedwandb: | 0.231 MB of 0.309 MB uploadedwandb: / 0.231 MB of 0.309 MB uploadedwandb: - 0.309 MB of 0.309 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ▁▁▁▂▂▂▃▃▃▃▃▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇██
wandb:  learning_rate █████████▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁
wandb: train_accuracy ▁▁▂▃▃▄▅▅▅▃▆▅▆▆▆▅▅▃▅▅▅▆▅▇▇▇▆▇█
wandb:     train_loss ▂▂▂▂▂▂▂▁▃▂▁▁▂▂▁▂▂▃▂▁▁█▁▁▁▁▁▁▁
wandb:   val_accuracy ▅▅▄▃▄▂▂▁▃▃▄▅▄▄▄▄▄▃▅▅▅▅▄▅▆▇▅▅█
wandb:       val_loss ▂▂▂▂▂▂▄▆▂▄▃▅▁▇▇▆▁▆▄▂▂▃▄█▄▃▃▄▄
wandb: 
wandb: Run summary:
wandb:          epoch 28
wandb:  learning_rate 0.00032
wandb: train_accuracy 0.96285
wandb:     train_loss 0.00148
wandb:   val_accuracy 0.40889
wandb:       val_loss 2.16671
wandb: 
wandb: 🚀 View run fragrant-bush-2692 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ok8y6r34
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_203709-ok8y6r34/logs
Successfully processed 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205053-ou1whkgm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-armadillo-2693
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ou1whkgm
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.025 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run eager-armadillo-2693 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ou1whkgm
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205053-ou1whkgm/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205125-dww8ilaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-darkness-2694
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dww8ilaz
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.031 MB uploadedwandb: - 0.020 MB of 0.031 MB uploadedwandb: \ 0.021 MB of 0.031 MB uploadedwandb: | 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run ancient-darkness-2694 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/dww8ilaz
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205125-dww8ilaz/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205159-fddaakcu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sound-2695
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fddaakcu
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:00<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.026 MB of 0.031 MB uploadedwandb: 🚀 View run classic-sound-2695 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/fddaakcu
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205159-fddaakcu/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205229-ol3zwzhq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run revived-field-2696
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ol3zwzhq
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.031 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.027 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run revived-field-2696 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/ol3zwzhq
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205229-ol3zwzhq/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205303-qapw2g58
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-blaze-2697
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qapw2g58
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.025 MB of 0.031 MB uploadedwandb: - 0.027 MB of 0.031 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run cosmic-blaze-2697 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/qapw2g58
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205303-qapw2g58/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205336-eyvj9rsl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-pyramid-2698
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eyvj9rsl
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.025 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run good-pyramid-2698 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/eyvj9rsl
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205336-eyvj9rsl/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205406-e6phg79r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-resonance-2699
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/e6phg79r
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.011 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run brisk-resonance-2699 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/e6phg79r
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205406-e6phg79r/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205437-g0nb1xfx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-durian-2700
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/g0nb1xfx
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.031 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.025 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run ancient-durian-2700 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/g0nb1xfx
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205437-g0nb1xfx/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241004_205509-rfoinmwl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-haze-2701
wandb: ⭐️ View project at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: 🚀 View run at https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rfoinmwl
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: / 0.021 MB of 0.031 MB uploadedwandb: - 0.025 MB of 0.031 MB uploadedwandb: \ 0.025 MB of 0.031 MB uploadedwandb: | 0.031 MB of 0.031 MB uploadedwandb: 🚀 View run devout-haze-2701 at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch/runs/rfoinmwl
wandb: ⭐️ View project at: https://wandb.ai/for-graduate-anaiis/0917-seed-gridsearch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241004_205509-rfoinmwl/logs
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_grid_search_2.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 125, in train
    out = model(training_data)  # 前向传播
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 78, in forward
    x_theta = self.GAT_gamma(data['gamma'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 29, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.22 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.95 GiB is free. Including non-PyTorch memory, this process has 21.72 GiB memory in use. Of the allocated memory 17.58 GiB is allocated by PyTorch, and 3.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error processing 2_20140419
