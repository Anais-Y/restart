nohup: ÂøΩÁï•ËæìÂÖ•
Successfully processed 10_20151014
Successfully processed 11_20150916
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_224659-a75ac9bd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-shape-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/a75ac9bd
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_224700-n4xk6q68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-violet-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/n4xk6q68
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_224659-r5ly7det
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-paper-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/r5ly7det
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:02<?, ?it/s]
  0%|          | 0/500 [00:02<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.017 MB of 0.040 MB uploadedwandb: - 0.017 MB of 0.040 MB uploadedwandb: | 0.028 MB of 0.040 MB uploadedwandb: \ 0.028 MB of 0.040 MB uploadedwandb: / 0.035 MB of 0.040 MB uploadedwandb: - 0.040 MB of 0.040 MB uploadedwandb: | 0.040 MB of 0.040 MB uploadedwandb: üöÄ View run fallen-paper-2 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/r5ly7det
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_224659-r5ly7det/logs
wandb: / 0.040 MB of 0.040 MB uploadedwandb: - 0.040 MB of 0.040 MB uploadedwandb: üöÄ View run polar-violet-3 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/n4xk6q68
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_224700-n4xk6q68/logs
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 77, in forward
    x_beta = self.GAT_beta(data['beta'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 565.19 MiB is free. Process 883235 has 624.00 MiB memory in use. Process 883233 has 624.00 MiB memory in use. Process 883237 has 624.00 MiB memory in use. Process 892759 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Process 892761 has 490.00 MiB memory in use. Of the allocated memory 1.86 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 77, in forward
    x_beta = self.GAT_beta(data['beta'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 565.19 MiB is free. Process 883235 has 624.00 MiB memory in use. Process 883233 has 624.00 MiB memory in use. Process 883237 has 624.00 MiB memory in use. Process 892759 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 3.78 GiB memory in use. Process 892761 has 490.00 MiB memory in use. Of the allocated memory 1.86 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 567.19 MiB is free. Process 883235 has 624.00 MiB memory in use. Process 883233 has 624.00 MiB memory in use. Process 883237 has 624.00 MiB memory in use. Process 892759 has 17.02 GiB memory in use. Process 892763 has 3.78 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 567.19 MiB is free. Process 883235 has 624.00 MiB memory in use. Process 883233 has 624.00 MiB memory in use. Process 883237 has 624.00 MiB memory in use. Process 892759 has 17.02 GiB memory in use. Process 892763 has 3.78 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/500 [00:56<7:48:47, 56.37s/it]  0%|          | 2/500 [01:46<7:19:20, 52.93s/it]  1%|          | 3/500 [02:31<6:47:25, 49.19s/it]  1%|          | 4/500 [03:20<6:44:11, 48.90s/it]  1%|          | 5/500 [04:06<6:37:16, 48.15s/it]  1%|          | 6/500 [04:56<6:41:08, 48.72s/it]  1%|‚ñè         | 7/500 [05:45<6:40:40, 48.76s/it]  2%|‚ñè         | 8/500 [06:36<6:45:12, 49.42s/it]  2%|‚ñè         | 9/500 [07:23<6:37:27, 48.57s/it]  2%|‚ñè         | 10/500 [08:10<6:32:38, 48.08s/it]  2%|‚ñè         | 11/500 [08:52<6:16:47, 46.23s/it]  2%|‚ñè         | 12/500 [09:38<6:15:21, 46.15s/it]  3%|‚ñé         | 13/500 [10:25<6:17:06, 46.46s/it]  3%|‚ñé         | 14/500 [11:12<6:17:53, 46.65s/it]  3%|‚ñé         | 15/500 [12:00<6:21:45, 47.23s/it]  3%|‚ñé         | 16/500 [12:48<6:21:11, 47.26s/it]  3%|‚ñé         | 17/500 [13:34<6:17:32, 46.90s/it]  4%|‚ñé         | 18/500 [14:21<6:17:38, 47.01s/it]  4%|‚ñç         | 19/500 [15:10<6:20:29, 47.46s/it]  4%|‚ñç         | 20/500 [15:57<6:20:43, 47.59s/it]  4%|‚ñç         | 21/500 [16:44<6:16:15, 47.13s/it]  4%|‚ñç         | 22/500 [17:32<6:19:42, 47.66s/it]  5%|‚ñç         | 23/500 [18:20<6:19:49, 47.78s/it]  5%|‚ñç         | 24/500 [19:04<6:08:02, 46.39s/it]  5%|‚ñå         | 25/500 [19:43<5:50:34, 44.28s/it]  5%|‚ñå         | 26/500 [20:25<5:44:25, 43.60s/it]  5%|‚ñå         | 27/500 [21:07<5:39:51, 43.11s/it]  6%|‚ñå         | 28/500 [21:49<5:35:23, 42.64s/it]  6%|‚ñå         | 29/500 [22:26<5:23:04, 41.16s/it]  6%|‚ñå         | 30/500 [23:05<5:16:17, 40.38s/it]  6%|‚ñå         | 31/500 [23:43<5:11:16, 39.82s/it]  6%|‚ñã         | 32/500 [24:20<5:04:05, 38.99s/it]  7%|‚ñã         | 33/500 [24:57<4:58:19, 38.33s/it]  7%|‚ñã         | 34/500 [25:34<4:53:47, 37.83s/it]  7%|‚ñã         | 35/500 [26:10<4:49:52, 37.40s/it]  7%|‚ñã         | 36/500 [26:47<4:47:23, 37.16s/it]  7%|‚ñã         | 36/500 [26:47<5:45:16, 44.65s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.208 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: | 0.379 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: / 0.650 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: - 0.673 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: \ 0.673 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: | 0.673 MB of 0.673 MB uploaded (0.004 MB deduped)wandb: / 0.673 MB of 0.673 MB uploaded (0.004 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train_accuracy ‚ñÇ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÉ‚ñÜ‚ñá
wandb:     train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ
wandb:   val_accuracy ‚ñÉ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÉ‚ñÖ‚ñÖ
wandb:       val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:          epoch 35
wandb:  learning_rate 5e-05
wandb: train_accuracy 0.53923
wandb:     train_loss 0.9025
wandb:   val_accuracy 0.39648
wandb:       val_loss 1.08967
wandb: 
wandb: üöÄ View run vibrant-shape-1 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/a75ac9bd
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_224659-a75ac9bd/logs
Successfully processed 1_20160518
Successfully processed 12_20150725
Successfully processed 13_20151115
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_231631-yf12z80d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-jazz-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/yf12z80d
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_231631-0h7915yi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-moon-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/0h7915yi
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_231632-dffj1tew
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-haze-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/dffj1tew
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:02<?, ?it/s]
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:02<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.031 MB uploadedwandb: | 0.019 MB of 0.031 MB uploadedwandb: - 0.010 MB of 0.033 MB uploadedwandb: / 0.031 MB of 0.031 MB uploadedwandb: \ 0.010 MB of 0.033 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: üöÄ View run absurd-haze-6 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/dffj1tew
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_231632-dffj1tew/logs
wandb: | 0.021 MB of 0.033 MB uploadedwandb: / 0.033 MB of 0.033 MB uploadedwandb: üöÄ View run polar-moon-4 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/0h7915yi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_231631-0h7915yi/logs
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 612.38 MiB is free. Process 897800 has 624.00 MiB memory in use. Process 897794 has 624.00 MiB memory in use. Process 897798 has 624.00 MiB memory in use. Process 897796 has 624.00 MiB memory in use. Process 897804 has 624.00 MiB memory in use. Process 897802 has 624.00 MiB memory in use. Process 899220 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 2.13 GiB memory in use. Process 899218 has 254.00 MiB memory in use. Of the allocated memory 1.78 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 612.38 MiB is free. Process 897800 has 624.00 MiB memory in use. Process 897794 has 624.00 MiB memory in use. Process 897798 has 624.00 MiB memory in use. Process 897796 has 624.00 MiB memory in use. Process 897804 has 624.00 MiB memory in use. Process 897802 has 624.00 MiB memory in use. Process 899220 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 2.13 GiB memory in use. Process 899218 has 254.00 MiB memory in use. Of the allocated memory 1.78 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 376.38 MiB is free. Process 897800 has 624.00 MiB memory in use. Process 897794 has 624.00 MiB memory in use. Process 897798 has 624.00 MiB memory in use. Process 897796 has 624.00 MiB memory in use. Process 897804 has 624.00 MiB memory in use. Process 897802 has 624.00 MiB memory in use. Process 899220 has 17.02 GiB memory in use. Process 899222 has 2.13 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 376.38 MiB is free. Process 897800 has 624.00 MiB memory in use. Process 897794 has 624.00 MiB memory in use. Process 897798 has 624.00 MiB memory in use. Process 897796 has 624.00 MiB memory in use. Process 897804 has 624.00 MiB memory in use. Process 897802 has 624.00 MiB memory in use. Process 899220 has 17.02 GiB memory in use. Process 899222 has 2.13 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/500 [01:23<11:36:16, 83.72s/it]  0%|          | 2/500 [02:36<10:40:50, 77.21s/it]  1%|          | 3/500 [03:44<10:06:07, 73.17s/it]  1%|          | 4/500 [04:53<9:51:02, 71.50s/it]   1%|          | 5/500 [06:02<9:41:30, 70.48s/it]  1%|          | 6/500 [07:15<9:47:07, 71.31s/it]  1%|‚ñè         | 7/500 [08:27<9:47:14, 71.47s/it]  2%|‚ñè         | 8/500 [09:34<9:36:03, 70.25s/it]  2%|‚ñè         | 9/500 [10:45<9:35:51, 70.37s/it]  2%|‚ñè         | 10/500 [11:55<9:34:19, 70.32s/it]  2%|‚ñè         | 11/500 [12:52<9:00:04, 66.27s/it]  2%|‚ñè         | 12/500 [13:51<8:39:57, 63.93s/it]  3%|‚ñé         | 13/500 [14:51<8:31:09, 62.98s/it]  3%|‚ñé         | 14/500 [15:45<8:06:33, 60.07s/it]  3%|‚ñé         | 15/500 [16:37<7:46:19, 57.69s/it]  3%|‚ñé         | 16/500 [17:31<7:37:17, 56.69s/it]  3%|‚ñé         | 17/500 [18:09<6:49:37, 50.89s/it]  4%|‚ñé         | 18/500 [18:38<5:55:25, 44.24s/it]  4%|‚ñç         | 19/500 [19:06<5:16:01, 39.42s/it]  4%|‚ñç         | 20/500 [19:36<4:52:36, 36.58s/it]  4%|‚ñç         | 21/500 [20:04<4:32:17, 34.11s/it]  4%|‚ñç         | 22/500 [20:32<4:16:53, 32.25s/it]  5%|‚ñç         | 23/500 [21:02<4:10:37, 31.53s/it]  5%|‚ñç         | 24/500 [21:30<4:02:20, 30.55s/it]  5%|‚ñå         | 25/500 [22:01<4:03:19, 30.73s/it]  5%|‚ñå         | 26/500 [22:30<3:59:05, 30.27s/it]  5%|‚ñå         | 27/500 [23:00<3:56:12, 29.96s/it]  6%|‚ñå         | 28/500 [23:29<3:53:22, 29.67s/it]  6%|‚ñå         | 29/500 [23:58<3:52:53, 29.67s/it]  6%|‚ñå         | 30/500 [24:29<3:53:52, 29.86s/it]  6%|‚ñå         | 31/500 [24:57<3:50:36, 29.50s/it]  6%|‚ñã         | 32/500 [25:28<3:51:52, 29.73s/it]  7%|‚ñã         | 33/500 [25:56<3:48:25, 29.35s/it]  7%|‚ñã         | 34/500 [26:27<3:52:08, 29.89s/it]  7%|‚ñã         | 35/500 [26:55<3:47:57, 29.41s/it]  7%|‚ñã         | 36/500 [27:25<3:47:37, 29.43s/it]  7%|‚ñã         | 37/500 [27:54<3:46:11, 29.31s/it]  8%|‚ñä         | 38/500 [28:23<3:45:39, 29.31s/it]  8%|‚ñä         | 39/500 [28:52<3:42:49, 29.00s/it]  8%|‚ñä         | 40/500 [29:25<3:53:04, 30.40s/it]  8%|‚ñä         | 41/500 [30:09<4:23:13, 34.41s/it]  8%|‚ñä         | 42/500 [30:51<4:40:54, 36.80s/it]  9%|‚ñä         | 43/500 [31:36<4:57:18, 39.03s/it]  9%|‚ñâ         | 44/500 [32:19<5:06:44, 40.36s/it]  9%|‚ñâ         | 45/500 [32:59<5:06:03, 40.36s/it]  9%|‚ñâ         | 46/500 [33:40<5:05:25, 40.37s/it]  9%|‚ñâ         | 47/500 [34:22<5:09:15, 40.96s/it] 10%|‚ñâ         | 48/500 [35:04<5:09:56, 41.14s/it] 10%|‚ñâ         | 49/500 [35:48<5:15:19, 41.95s/it] 10%|‚ñà         | 50/500 [36:30<5:14:46, 41.97s/it] 10%|‚ñà         | 51/500 [37:12<5:15:35, 42.17s/it] 10%|‚ñà         | 52/500 [37:55<5:15:47, 42.29s/it] 11%|‚ñà         | 53/500 [38:39<5:19:19, 42.86s/it] 11%|‚ñà         | 54/500 [39:24<5:23:38, 43.54s/it] 11%|‚ñà         | 55/500 [40:07<5:21:51, 43.40s/it] 11%|‚ñà         | 56/500 [40:50<5:20:08, 43.26s/it] 11%|‚ñà         | 56/500 [40:50<5:23:49, 43.76s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.560 MB uploadedwandb: \ 0.010 MB of 0.560 MB uploadedwandb: | 0.306 MB of 0.560 MB uploadedwandb: / 0.560 MB of 0.560 MB uploadedwandb: - 0.560 MB of 0.560 MB uploadedwandb: \ 0.560 MB of 0.560 MB uploadedwandb: | 0.560 MB of 0.560 MB uploadedwandb: / 0.560 MB of 0.560 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train_accuracy ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     train_loss ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:   val_accuracy ‚ñÉ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÉ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:       val_loss ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÖ
wandb: 
wandb: Run summary:
wandb:          epoch 55
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.75691
wandb:     train_loss 0.64339
wandb:   val_accuracy 0.60352
wandb:       val_loss 1.6308
wandb: 
wandb: üöÄ View run clean-jazz-5 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/yf12z80d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_231631-yf12z80d/logs
Successfully processed 14_20151205
Successfully processed 15_20150508
Successfully processed 2_20150915
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_235950-jtn1e6q1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-wind-8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/jtn1e6q1
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_235950-155sqmuz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-bee-9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/155sqmuz
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241021_235949-9rd9rlvf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-totem-7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/9rd9rlvf
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:01<?, ?it/s]
  0%|          | 0/500 [00:01<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.027 MB uploadedwandb: | 0.010 MB of 0.033 MB uploadedwandb: / 0.027 MB of 0.031 MB uploadedwandb: / 0.011 MB of 0.033 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: - 0.033 MB of 0.033 MB uploadedwandb: \ 0.031 MB of 0.031 MB uploadedwandb: | 0.031 MB of 0.031 MB uploadedwandb: üöÄ View run glad-totem-7 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/9rd9rlvf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_235949-9rd9rlvf/logs
wandb: \ 0.033 MB of 0.033 MB uploadedwandb: üöÄ View run divine-wind-8 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/jtn1e6q1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_235950-jtn1e6q1/logs
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.04 GiB is free. Process 903089 has 624.00 MiB memory in use. Process 903093 has 624.00 MiB memory in use. Process 903091 has 624.00 MiB memory in use. Process 903087 has 624.00 MiB memory in use. Process 903095 has 624.00 MiB memory in use. Process 910171 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 2.13 GiB memory in use. Process 910173 has 432.00 MiB memory in use. Of the allocated memory 1.78 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.04 GiB is free. Process 903089 has 624.00 MiB memory in use. Process 903093 has 624.00 MiB memory in use. Process 903091 has 624.00 MiB memory in use. Process 903087 has 624.00 MiB memory in use. Process 903095 has 624.00 MiB memory in use. Process 910171 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 2.13 GiB memory in use. Process 910173 has 432.00 MiB memory in use. Of the allocated memory 1.78 GiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1005.31 MiB is free. Process 903089 has 624.00 MiB memory in use. Process 903093 has 624.00 MiB memory in use. Process 903091 has 624.00 MiB memory in use. Process 903087 has 624.00 MiB memory in use. Process 903095 has 624.00 MiB memory in use. Process 910171 has 17.02 GiB memory in use. Process 910169 has 2.13 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1005.31 MiB is free. Process 903089 has 624.00 MiB memory in use. Process 903093 has 624.00 MiB memory in use. Process 903091 has 624.00 MiB memory in use. Process 903087 has 624.00 MiB memory in use. Process 903095 has 624.00 MiB memory in use. Process 910171 has 17.02 GiB memory in use. Process 910169 has 2.13 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/500 [00:51<7:07:56, 51.46s/it]  0%|          | 2/500 [01:31<6:11:33, 44.77s/it]  1%|          | 3/500 [02:11<5:51:17, 42.41s/it]  1%|          | 4/500 [02:48<5:35:27, 40.58s/it]  1%|          | 5/500 [03:30<5:37:05, 40.86s/it]  1%|          | 6/500 [04:06<5:22:27, 39.16s/it]  1%|‚ñè         | 7/500 [04:47<5:28:49, 40.02s/it]  2%|‚ñè         | 8/500 [05:20<5:08:24, 37.61s/it]  2%|‚ñè         | 9/500 [05:48<4:44:28, 34.76s/it]  2%|‚ñè         | 10/500 [06:20<4:36:18, 33.83s/it]  2%|‚ñè         | 11/500 [07:33<6:13:31, 45.83s/it]  2%|‚ñè         | 12/500 [08:44<7:14:39, 53.44s/it]  3%|‚ñé         | 13/500 [09:44<7:28:50, 55.30s/it]  3%|‚ñé         | 14/500 [10:40<7:31:44, 55.77s/it]  3%|‚ñé         | 15/500 [11:24<7:01:56, 52.20s/it]  3%|‚ñé         | 16/500 [12:05<6:32:27, 48.65s/it]  3%|‚ñé         | 17/500 [12:59<6:45:39, 50.39s/it]  4%|‚ñé         | 18/500 [13:48<6:40:53, 49.90s/it]  4%|‚ñç         | 19/500 [14:35<6:32:11, 48.92s/it]  4%|‚ñç         | 20/500 [15:22<6:28:13, 48.53s/it]  4%|‚ñç         | 21/500 [16:51<8:02:46, 60.47s/it]  4%|‚ñç         | 22/500 [18:03<8:31:20, 64.18s/it]  5%|‚ñç         | 23/500 [19:21<9:02:03, 68.18s/it]  5%|‚ñç         | 24/500 [20:52<9:56:19, 75.17s/it]  5%|‚ñå         | 25/500 [22:12<10:05:42, 76.51s/it]  5%|‚ñå         | 26/500 [23:13<9:28:03, 71.91s/it]   5%|‚ñå         | 27/500 [24:26<9:29:48, 72.28s/it]  6%|‚ñå         | 28/500 [25:22<8:50:24, 67.42s/it]  6%|‚ñå         | 29/500 [26:11<8:04:50, 61.76s/it]  6%|‚ñå         | 30/500 [26:57<7:26:53, 57.05s/it]  6%|‚ñå         | 31/500 [27:42<6:58:07, 53.49s/it]  6%|‚ñã         | 32/500 [28:18<6:16:02, 48.21s/it]  7%|‚ñã         | 33/500 [29:02<6:05:23, 46.94s/it]  7%|‚ñã         | 34/500 [29:43<5:50:11, 45.09s/it]  7%|‚ñã         | 35/500 [30:22<5:36:41, 43.44s/it]  7%|‚ñã         | 36/500 [31:03<5:30:13, 42.70s/it]  7%|‚ñã         | 37/500 [31:39<5:14:07, 40.71s/it]  8%|‚ñä         | 38/500 [32:21<5:14:17, 40.82s/it]  8%|‚ñä         | 39/500 [32:59<5:07:55, 40.08s/it]  8%|‚ñä         | 40/500 [33:49<5:30:10, 43.07s/it]  8%|‚ñä         | 41/500 [34:46<6:00:23, 47.11s/it]  8%|‚ñä         | 41/500 [34:46<6:29:13, 50.88s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.497 MB uploadedwandb: | 0.019 MB of 0.497 MB uploadedwandb: / 0.485 MB of 0.497 MB uploadedwandb: - 0.485 MB of 0.497 MB uploadedwandb: \ 0.497 MB of 0.497 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: train_accuracy ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÖ‚ñà
wandb:     train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   val_accuracy ‚ñÑ‚ñÑ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá
wandb:       val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:          epoch 40
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.61105
wandb:     train_loss 1.1782
wandb:   val_accuracy 0.47137
wandb:       val_loss 1.28421
wandb: 
wandb: üöÄ View run fast-bee-9 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/155sqmuz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241021_235950-155sqmuz/logs
Successfully processed 3_20150919
Successfully processed 4_20151111
Successfully processed 5_20160406
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_003713-alivmaby
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-valley-10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/alivmaby
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_003713-zjo1v1z6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-donkey-12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/zjo1v1z6
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_003713-k88yf6b0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-moon-11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/k88yf6b0
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:02<?, ?it/s]
  0%|          | 0/500 [00:02<?, ?it/s]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.033 MB uploadedwandb: | 0.010 MB of 0.033 MB uploadedwandb: \ 0.019 MB of 0.033 MB uploadedwandb: / 0.011 MB of 0.033 MB uploadedwandb: | 0.033 MB of 0.033 MB uploadedwandb: / 0.033 MB of 0.033 MB uploadedwandb: üöÄ View run cerulean-moon-11 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/k88yf6b0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_003713-k88yf6b0/logs
wandb: - 0.033 MB of 0.033 MB uploadedwandb: \ 0.033 MB of 0.033 MB uploadedwandb: üöÄ View run devoted-valley-10 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/alivmaby
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_003713-alivmaby/logs
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.55 GiB is free. Process 926098 has 624.00 MiB memory in use. Process 926108 has 624.00 MiB memory in use. Process 926102 has 624.00 MiB memory in use. Process 926100 has 624.00 MiB memory in use. Process 926106 has 624.00 MiB memory in use. Process 926104 has 624.00 MiB memory in use. Process 927924 has 17.02 GiB memory in use. Process 928662 has 476.00 MiB memory in use. Process 927922 has 490.00 MiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.55 GiB is free. Process 926098 has 624.00 MiB memory in use. Process 926108 has 624.00 MiB memory in use. Process 926102 has 624.00 MiB memory in use. Process 926100 has 624.00 MiB memory in use. Process 926106 has 624.00 MiB memory in use. Process 926104 has 624.00 MiB memory in use. Process 927924 has 17.02 GiB memory in use. Process 928662 has 476.00 MiB memory in use. Process 927922 has 490.00 MiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.61 GiB is free. Process 926098 has 624.00 MiB memory in use. Process 926108 has 624.00 MiB memory in use. Process 926102 has 624.00 MiB memory in use. Process 926100 has 624.00 MiB memory in use. Process 926106 has 624.00 MiB memory in use. Process 926104 has 624.00 MiB memory in use. Process 927924 has 17.02 GiB memory in use. Process 928662 has 476.00 MiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Process 927926 has 432.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.61 GiB is free. Process 926098 has 624.00 MiB memory in use. Process 926108 has 624.00 MiB memory in use. Process 926102 has 624.00 MiB memory in use. Process 926100 has 624.00 MiB memory in use. Process 926106 has 624.00 MiB memory in use. Process 926104 has 624.00 MiB memory in use. Process 927924 has 17.02 GiB memory in use. Process 928662 has 476.00 MiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Process 927926 has 432.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/500 [01:14<10:21:36, 74.74s/it]  0%|          | 2/500 [02:08<8:35:51, 62.15s/it]   1%|          | 3/500 [03:06<8:22:27, 60.66s/it]  1%|          | 4/500 [04:02<8:04:24, 58.60s/it]  1%|          | 5/500 [04:57<7:54:29, 57.51s/it]  1%|          | 6/500 [06:08<8:30:52, 62.05s/it]  1%|‚ñè         | 7/500 [07:05<8:15:54, 60.35s/it]  2%|‚ñè         | 8/500 [08:08<8:20:54, 61.09s/it]  2%|‚ñè         | 9/500 [09:03<8:05:19, 59.31s/it]  2%|‚ñè         | 10/500 [10:10<8:22:09, 61.49s/it]  2%|‚ñè         | 11/500 [11:06<8:09:13, 60.03s/it]  2%|‚ñè         | 12/500 [12:05<8:04:09, 59.53s/it]  3%|‚ñé         | 13/500 [12:53<7:35:56, 56.17s/it]  3%|‚ñé         | 14/500 [13:29<6:44:59, 50.00s/it]  3%|‚ñé         | 15/500 [14:16<6:38:06, 49.25s/it]  3%|‚ñé         | 16/500 [15:02<6:29:14, 48.25s/it]  3%|‚ñé         | 17/500 [15:51<6:28:55, 48.31s/it]  4%|‚ñé         | 18/500 [16:45<6:42:29, 50.10s/it]  4%|‚ñç         | 19/500 [17:27<6:21:58, 47.65s/it]  4%|‚ñç         | 20/500 [18:15<6:22:37, 47.83s/it]  4%|‚ñç         | 21/500 [19:01<6:17:10, 47.24s/it]  4%|‚ñç         | 22/500 [19:39<5:53:34, 44.38s/it]  5%|‚ñç         | 23/500 [20:26<6:00:29, 45.35s/it]  5%|‚ñç         | 24/500 [21:09<5:52:29, 44.43s/it]  5%|‚ñå         | 25/500 [21:53<5:50:28, 44.27s/it]  5%|‚ñå         | 26/500 [22:40<5:56:56, 45.18s/it]  5%|‚ñå         | 27/500 [23:21<5:46:25, 43.94s/it]  6%|‚ñå         | 28/500 [24:08<5:53:31, 44.94s/it]  6%|‚ñå         | 29/500 [24:48<5:40:43, 43.41s/it]  6%|‚ñå         | 30/500 [25:32<5:40:48, 43.51s/it]  6%|‚ñå         | 31/500 [26:16<5:42:02, 43.76s/it]  6%|‚ñã         | 32/500 [26:52<5:23:28, 41.47s/it]  7%|‚ñã         | 33/500 [27:36<5:28:54, 42.26s/it]  7%|‚ñã         | 34/500 [28:16<5:20:56, 41.32s/it]  7%|‚ñã         | 35/500 [29:00<5:27:19, 42.24s/it]  7%|‚ñã         | 36/500 [29:38<5:16:03, 40.87s/it]  7%|‚ñã         | 37/500 [30:19<5:16:46, 41.05s/it]  8%|‚ñä         | 38/500 [30:57<5:09:19, 40.17s/it]  8%|‚ñä         | 39/500 [31:27<4:44:44, 37.06s/it]  8%|‚ñä         | 40/500 [32:05<4:46:51, 37.42s/it]  8%|‚ñä         | 41/500 [32:44<4:50:04, 37.92s/it]  8%|‚ñä         | 42/500 [33:29<5:04:08, 39.84s/it]  9%|‚ñä         | 43/500 [34:09<5:03:56, 39.90s/it]  9%|‚ñâ         | 44/500 [34:53<5:14:17, 41.35s/it]  9%|‚ñâ         | 45/500 [35:32<5:06:56, 40.48s/it]  9%|‚ñâ         | 46/500 [36:08<4:56:04, 39.13s/it]  9%|‚ñâ         | 47/500 [36:52<5:06:14, 40.56s/it] 10%|‚ñâ         | 48/500 [37:33<5:07:18, 40.79s/it] 10%|‚ñâ         | 49/500 [38:10<4:57:37, 39.59s/it] 10%|‚ñâ         | 49/500 [38:10<5:51:21, 46.74s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.535 MB uploadedwandb: - 0.019 MB of 0.535 MB uploadedwandb: \ 0.535 MB of 0.535 MB uploadedwandb: | 0.535 MB of 0.535 MB uploadedwandb: / 0.535 MB of 0.535 MB uploadedwandb: - 0.535 MB of 0.535 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train_accuracy ‚ñÇ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     train_loss ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ
wandb:   val_accuracy ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb:       val_loss ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñá‚ñÇ‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñá‚ñÑ‚ñá‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ
wandb: 
wandb: Run summary:
wandb:          epoch 48
wandb:  learning_rate 4e-05
wandb: train_accuracy 0.57569
wandb:     train_loss 0.9902
wandb:   val_accuracy 0.57269
wandb:       val_loss 0.5882
wandb: 
wandb: üöÄ View run playful-donkey-12 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/zjo1v1z6
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_003713-zjo1v1z6/logs
Successfully processed 6_20150507
Successfully processed 7_20150715
Successfully processed 8_20151103
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: anaiis (for-graduate-anaiis). Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_011757-3aehvsxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-cloud-15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/3aehvsxi
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_011757-5expl50z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-snowball-14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/5expl50z
wandb: wandb version 0.18.5 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /data/Anaiis/anti_overfit/wandb/run-20241022_011757-3s1dqx9e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-dew-13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: üöÄ View run at https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/3s1dqx9e
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 0/500 [00:02<?, ?it/s]
/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
  0%|          | 0/500 [00:00<?, ?it/s]wandb: - 0.010 MB of 0.010 MB uploaded  0%|          | 0/500 [00:01<?, ?it/s]
wandb: \ 0.010 MB of 0.031 MB uploadedwandb: | 0.010 MB of 0.031 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: / 0.031 MB of 0.031 MB uploadedwandb: - 0.031 MB of 0.031 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: üöÄ View run winter-dew-13 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/3s1dqx9e
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_011757-3s1dqx9e/logs
wandb: | 0.010 MB of 0.032 MB uploadedwandb: / 0.025 MB of 0.032 MB uploadedTraceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 77, in forward
    x_beta = self.GAT_beta(data['beta'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.22 GiB is free. Process 938676 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 5.43 GiB memory in use. Of the allocated memory 3.51 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 77, in forward
    x_beta = self.GAT_beta(data['beta'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 547, in propagate
    out = self.message(**msg_kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 386, in message
    return alpha.unsqueeze(-1) * x_j
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 1.22 GiB is free. Process 938676 has 17.02 GiB memory in use. Including non-PyTorch memory, this process has 5.43 GiB memory in use. Of the allocated memory 3.51 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
wandb: - 0.032 MB of 0.032 MB uploadedwandb: \ 0.032 MB of 0.032 MB uploadedwandb: üöÄ View run celestial-snowball-14 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/5expl50z
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_011757-5expl50z/logs
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 756.00 MiB is free. Process 938676 has 17.02 GiB memory in use. Process 938672 has 5.43 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "watch_PE_cp.py", line 109, in <module>
    train(model, tr_loader, optimizer, scheduler, criterion, device, args.max_grad_norm)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 126, in train
    out = model(training_data)  # ÂâçÂêë‰º†Êí≠
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 76, in forward
    x_alpha = self.GAT_alpha(data['alpha'])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/data/Anaiis/anti_overfit/model_gat_seed.py", line 30, in forward
    x = self.conv1(x, edge_index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/gat_conv.py", line 341, in forward
    out = self.propagate(edge_index, x=x, alpha=alpha, size=size)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 538, in propagate
    coll_dict = self._collect(self._user_args, edge_index,
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 400, in _collect
    data = self._lift(data, edge_index, dim)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 360, in _lift
    return self._index_select(src, edge_index[dim])
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 306, in _index_select
    return self._index_select_safe(src, index)
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 329, in _index_select_safe
    raise e
  File "/home/micro/anaconda3/envs/bob_env1/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py", line 310, in _index_select_safe
    return src.index_select(self.node_dim, index)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.65 GiB. GPU 1 has a total capacity of 23.69 GiB of which 756.00 MiB is free. Process 938676 has 17.02 GiB memory in use. Process 938672 has 5.43 GiB memory in use. Including non-PyTorch memory, this process has 490.00 MiB memory in use. Of the allocated memory 131.48 MiB is allocated by PyTorch, and 52.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
  0%|          | 1/500 [00:37<5:11:16, 37.43s/it]  0%|          | 2/500 [01:06<4:31:19, 32.69s/it]  1%|          | 3/500 [01:47<5:02:23, 36.51s/it]  1%|          | 4/500 [02:31<5:24:07, 39.21s/it]  1%|          | 5/500 [03:03<5:03:06, 36.74s/it]  1%|          | 6/500 [04:03<6:07:16, 44.61s/it]  1%|‚ñè         | 7/500 [05:28<7:56:23, 57.98s/it]  2%|‚ñè         | 8/500 [07:02<9:29:08, 69.41s/it]  2%|‚ñè         | 9/500 [08:16<9:39:05, 70.76s/it]  2%|‚ñè         | 10/500 [09:16<9:09:54, 67.34s/it]  2%|‚ñè         | 11/500 [10:49<10:13:38, 75.29s/it]  2%|‚ñè         | 12/500 [12:27<11:08:12, 82.16s/it]  3%|‚ñé         | 13/500 [18:04<21:32:49, 159.28s/it]  3%|‚ñé         | 14/500 [19:35<18:42:55, 138.63s/it]  3%|‚ñé         | 15/500 [20:23<15:00:06, 111.35s/it]  3%|‚ñé         | 16/500 [21:26<13:01:42, 96.91s/it]   3%|‚ñé         | 17/500 [22:31<11:41:44, 87.17s/it]  4%|‚ñé         | 18/500 [23:45<11:08:15, 83.19s/it]  4%|‚ñç         | 19/500 [24:46<10:15:36, 76.79s/it]  4%|‚ñç         | 20/500 [26:24<11:04:41, 83.09s/it]  4%|‚ñç         | 21/500 [27:11<9:36:07, 72.17s/it]   4%|‚ñç         | 22/500 [28:30<9:51:25, 74.24s/it]  5%|‚ñç         | 23/500 [30:06<10:41:36, 80.71s/it]  5%|‚ñç         | 24/500 [31:24<10:33:45, 79.88s/it]  5%|‚ñå         | 25/500 [32:20<9:35:17, 72.67s/it]   5%|‚ñå         | 26/500 [35:34<14:22:58, 109.24s/it]  5%|‚ñå         | 27/500 [36:19<11:48:12, 89.84s/it]   6%|‚ñå         | 28/500 [37:24<10:49:07, 82.52s/it]  6%|‚ñå         | 29/500 [38:11<9:23:10, 71.74s/it]   6%|‚ñå         | 30/500 [39:25<9:27:11, 72.41s/it]  6%|‚ñå         | 31/500 [40:11<8:25:03, 64.61s/it]  6%|‚ñã         | 32/500 [41:13<8:17:51, 63.83s/it]  7%|‚ñã         | 33/500 [42:27<8:40:54, 66.93s/it]  7%|‚ñã         | 34/500 [43:28<8:25:49, 65.13s/it]  7%|‚ñã         | 35/500 [44:56<9:17:51, 71.98s/it]  7%|‚ñã         | 36/500 [46:01<9:00:24, 69.88s/it]  7%|‚ñã         | 37/500 [46:44<7:55:57, 61.68s/it]  8%|‚ñä         | 38/500 [47:54<8:13:46, 64.13s/it]  8%|‚ñä         | 39/500 [48:41<7:35:01, 59.22s/it]  8%|‚ñä         | 40/500 [49:16<6:38:03, 51.92s/it]  8%|‚ñä         | 41/500 [50:08<6:37:31, 51.96s/it]  8%|‚ñä         | 42/500 [50:43<5:56:54, 46.76s/it]  9%|‚ñä         | 43/500 [51:31<5:59:41, 47.23s/it]  9%|‚ñâ         | 44/500 [52:08<5:34:49, 44.06s/it]  9%|‚ñâ         | 45/500 [52:42<5:11:53, 41.13s/it]  9%|‚ñâ         | 46/500 [53:27<5:19:17, 42.20s/it]  9%|‚ñâ         | 47/500 [54:07<5:14:19, 41.63s/it] 10%|‚ñâ         | 48/500 [55:23<6:30:42, 51.86s/it] 10%|‚ñâ         | 49/500 [56:10<6:19:03, 50.43s/it] 10%|‚ñà         | 50/500 [56:43<5:39:25, 45.26s/it] 10%|‚ñà         | 51/500 [57:21<5:22:12, 43.06s/it] 10%|‚ñà         | 52/500 [57:59<5:09:25, 41.44s/it] 11%|‚ñà         | 53/500 [58:37<5:01:38, 40.49s/it] 11%|‚ñà         | 54/500 [59:16<4:58:07, 40.11s/it] 11%|‚ñà         | 55/500 [59:59<5:03:59, 40.99s/it] 11%|‚ñà         | 56/500 [1:00:35<4:51:26, 39.38s/it] 11%|‚ñà‚ñè        | 57/500 [1:01:14<4:49:31, 39.21s/it] 11%|‚ñà‚ñè        | 57/500 [1:01:14<7:55:55, 64.46s/it]
wandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.010 MB uploadedwandb: - 0.010 MB of 0.010 MB uploadedwandb: \ 0.010 MB of 0.010 MB uploadedwandb: | 0.010 MB of 0.010 MB uploadedwandb: / 0.010 MB of 0.562 MB uploadedwandb: - 0.010 MB of 0.562 MB uploadedwandb: \ 0.431 MB of 0.562 MB uploadedwandb: | 0.431 MB of 0.562 MB uploadedwandb: / 0.431 MB of 0.562 MB uploadedwandb: - 0.431 MB of 0.562 MB uploadedwandb: \ 0.562 MB of 0.562 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:          epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  learning_rate ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train_accuracy ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     train_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:   val_accuracy ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÅ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:       val_loss ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:          epoch 56
wandb:  learning_rate 3e-05
wandb: train_accuracy 0.70718
wandb:     train_loss 0.53598
wandb:   val_accuracy 0.49339
wandb:       val_loss 1.27948
wandb: 
wandb: üöÄ View run eager-cloud-15 at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds/runs/3aehvsxi
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/for-graduate-anaiis/seed_iv_lds
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241022_011757-3aehvsxi/logs
Successfully processed 9_20151028
run_all_seed.sh: Ë°å 27: Êï∞Âô®ÔºöÊú™ÊâæÂà∞ÂëΩ‰ª§
run_all_seed.sh: Ë°å 28: Êú™È¢ÑÊúüÁöÑÁ¨¶Âè∑‚Äúdone‚ÄùÈôÑËøëÊúâËØ≠Ê≥ïÈîôËØØ
run_all_seed.sh: Ë°å 28: `done'
